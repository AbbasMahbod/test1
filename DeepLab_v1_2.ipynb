{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DeepLab_v1.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5tla+SLBpEv5ggyJAvjjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbbasMahbod/test1/blob/main/DeepLab_v1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIOfa4xZuvcL",
        "outputId": "37588974-1792-466d-b3a5-2b418b1db324"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 54603, done.\u001b[K\n",
            "remote: Total 54603 (delta 0), reused 0 (delta 0), pack-reused 54603\u001b[K\n",
            "Receiving objects: 100% (54603/54603), 570.02 MiB | 31.09 MiB/s, done.\n",
            "Resolving deltas: 100% (37580/37580), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqYnUVZcHEYH",
        "outputId": "dd9865d1-4331-402d-f907-174b8810e8e3"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install pillow\n",
        "!pip install tqdm numpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 36.2MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (54.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=6e42b1dd7d3c98c8407c80ba11f08138f4d8399cac646d237d11ecd243a08b14\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqpfsdA4JWDj",
        "outputId": "2bbe5571-8a0f-487a-a04d-14ca960456d4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print (tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW9-3pTLNtwl",
        "outputId": "40b898f4-f7d0-40bf-a980-eb216838957e"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PqWwtR1OpjP"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] = \"/content/models/research\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "segg_RnxAIBh"
      },
      "source": [
        " # set PYTHONPATH=...\\python\\models\\research;...\\python\\models\\research\\slim"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kD9LkbSWFtY",
        "outputId": "a8e61fde-cbae-4424-86a2-18867fdcc126"
      },
      "source": [
        "pip install --upgrade tf_slim"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 20.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 10.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyhc2GpQWKRX"
      },
      "source": [
        "import tf_slim as slim"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8HmouPhJ_i7",
        "outputId": "b6799674-1a9f-4d05-afb4-79bb79414b5e"
      },
      "source": [
        "!python deeplab/model_test.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n",
            "Running tests under Python 3.7.10: /usr/bin/python3\n",
            "[ RUN      ] DeeplabModelTest.testBuildDeepLabWithDensePredictionCell\n",
            "WARNING:tensorflow:From /usr/lib/python3.7/contextlib.py:82: TensorFlowTestCase.test_session (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `self.session()` or `self.cached_session()` instead.\n",
            "W0325 16:10:13.280469 140068975540096 deprecation.py:323] From /usr/lib/python3.7/contextlib.py:82: TensorFlowTestCase.test_session (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `self.session()` or `self.cached_session()` instead.\n",
            "2021-03-25 16:10:13.284124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-25 16:10:13.347110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:13.348378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:10:13.364076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:13.577192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:10:13.672913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:10:13.697245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:10:13.898261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:10:14.024968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:10:14.454983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:10:14.455230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.456513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.457529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:10:14.462929: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-03-25 16:10:14.470756: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-03-25 16:10:14.471006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c3026a7100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-25 16:10:14.471042: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-25 16:10:14.603284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.604577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c3026a72c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-25 16:10:14.604610: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-03-25 16:10:14.604875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.607105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:10:14.607237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:14.607288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:10:14.607332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:10:14.607375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:10:14.607418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:10:14.607460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:10:14.607503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:10:14.607601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.608686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.609624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:10:14.609755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:14.613233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:10:14.613278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:10:14.613304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:10:14.613479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.614668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:14.615572: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-25 16:10:14.615630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From deeplab/model_test.py:134: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0325 16:10:14.616715 140068975540096 module_wrapper.py:139] From deeplab/model_test.py:134: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0325 16:10:14.625472 140068975540096 module_wrapper.py:139] From /content/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0325 16:10:14.625943 140068975540096 deprecation.py:323] From /content/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0325 16:10:14.630339 140068975540096 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/model.py:410: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0325 16:10:16.389066 140068975540096 module_wrapper.py:139] From /content/models/research/deeplab/model.py:410: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Using dense prediction cell config.\n",
            "I0325 16:10:16.389477 140068975540096 model.py:410] Using dense prediction cell config.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/dense_prediction_cell.py:214: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0325 16:10:16.389791 140068975540096 module_wrapper.py:139] From /content/models/research/deeplab/core/dense_prediction_cell.py:214: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:{'kernel': 3, 'rate': [1, 6], 'op': 'conv', 'input': -1}\n",
            "I0325 16:10:16.390066 140068975540096 dense_prediction_cell.py:224] {'kernel': 3, 'rate': [1, 6], 'op': 'conv', 'input': -1}\n",
            "INFO:tensorflow:{'kernel': 3, 'rate': [18, 15], 'op': 'conv', 'input': 0}\n",
            "I0325 16:10:16.567887 140068975540096 dense_prediction_cell.py:224] {'kernel': 3, 'rate': [18, 15], 'op': 'conv', 'input': 0}\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "W0325 16:10:16.701373 140068975540096 module_wrapper.py:139] From /content/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "[       OK ] DeeplabModelTest.testBuildDeepLabWithDensePredictionCell\n",
            "[ RUN      ] DeeplabModelTest.testBuildDeepLabv2\n",
            "2021-03-25 16:10:16.704377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:16.705268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:10:16.705343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:16.705382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:10:16.705421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:10:16.705464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:10:16.705507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:10:16.705541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:10:16.705597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:10:16.705685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:16.706619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:16.707477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:10:16.707535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:10:16.707561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:10:16.707583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:10:16.707736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:16.708606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:16.709427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-03-25 16:10:21.619619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:21.620553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:10:21.620632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:21.620689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:10:21.620740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:10:21.620780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:10:21.620827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:10:21.620864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:10:21.620900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:10:21.620985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:21.622045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:21.622965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:10:21.623012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:10:21.623035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:10:21.623052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:10:21.623157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:21.624067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:21.624931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-03-25 16:10:28.713299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:28.714233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:10:28.714328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:28.714385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:10:28.714425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:10:28.714470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:10:28.714538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:10:28.714580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:10:28.714618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:10:28.714706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:28.715643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:28.716459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:10:28.716508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:10:28.716530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:10:28.716549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:10:28.716673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:28.717629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:28.718602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-03-25 16:10:30.614438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:30.615392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:10:30.615483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:30.615549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:10:30.615587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:10:30.615626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:10:30.615661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:10:30.615708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:10:30.615787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:10:30.615879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:30.616818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:30.617639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:10:30.617686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:10:30.617710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:10:30.617744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:10:30.617871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:30.618760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:30.619580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "[       OK ] DeeplabModelTest.testBuildDeepLabv2\n",
            "[ RUN      ] DeeplabModelTest.testForwardpassDeepLabv3plus\n",
            "2021-03-25 16:10:33.511259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:33.512242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:10:33.512357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:10:33.512399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:10:33.512453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:10:33.512503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:10:33.512543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:10:33.512585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:10:33.512629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:10:33.512738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:33.513599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:33.514468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:10:33.514518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:10:33.514544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:10:33.514563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:10:33.514687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:33.515564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:10:33.516395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From deeplab/model_test.py:104: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "W0325 16:10:35.608183 140068975540096 module_wrapper.py:139] From deeplab/model_test.py:104: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "[       OK ] DeeplabModelTest.testForwardpassDeepLabv3plus\n",
            "[ RUN      ] DeeplabModelTest.testWrongDeepLabVariant\n",
            "[       OK ] DeeplabModelTest.testWrongDeepLabVariant\n",
            "[ RUN      ] DeeplabModelTest.test_session\n",
            "[  SKIPPED ] DeeplabModelTest.test_session\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 23.067s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5WywhDhcH04",
        "outputId": "1c78bd81-ecee-44cc-b5ce-0c5fbac657d0"
      },
      "source": [
        "!python /content/models/research/deeplab/datasets/convert_rgb_to_index.py"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating folder:  /content/models/research/deeplab/datasets/PQR/SegmentationClassRaw/\n",
            "100% 72/72 [00:04<00:00, 15.75it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb3kqMg0fWG9",
        "outputId": "9ecfa7fe-1426-42fb-a2f8-71dcb1a61a8f"
      },
      "source": [
        "!python /content/models/research/deeplab/datasets/build_pqr_data.py"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/deeplab/datasets/build_pqr_data.py:156: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/datasets/build_pqr_data.py:150: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0325 16:11:15.283843 140564167899008 module_wrapper.py:139] From /content/models/research/deeplab/datasets/build_pqr_data.py:150: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/datasets/build_data.py:63: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0325 16:11:15.287312 140564167899008 module_wrapper.py:139] From /content/models/research/deeplab/datasets/build_data.py:63: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/datasets/build_data.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0325 16:11:15.288616 140564167899008 module_wrapper.py:139] From /content/models/research/deeplab/datasets/build_data.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2021-03-25 16:11:15.289636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-25 16:11:15.306079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.307029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:11:15.307409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:11:15.309022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:11:15.310199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:11:15.310571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:11:15.322074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:11:15.323480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:11:15.329726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:11:15.329902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.330946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.331852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:11:15.332321: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-03-25 16:11:15.342300: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-03-25 16:11:15.342530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5643624f0bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-25 16:11:15.342556: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-25 16:11:15.440323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.441625: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5643624f1640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-25 16:11:15.441697: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-03-25 16:11:15.441893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.442880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:11:15.442960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:11:15.443001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:11:15.443034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:11:15.443067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:11:15.443097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:11:15.443126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:11:15.443199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:11:15.443299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.444353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.445331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:11:15.445410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:11:15.447353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:11:15.447391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:11:15.447408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:11:15.447540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.448530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.449354: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-25 16:11:15.449410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2021-03-25 16:11:15.452677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.453523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-25 16:11:15.453579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-25 16:11:15.453616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-25 16:11:15.453653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-25 16:11:15.453693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-25 16:11:15.453745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-25 16:11:15.453804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-25 16:11:15.453841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-25 16:11:15.453921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.454767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.455549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-25 16:11:15.455585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-25 16:11:15.455613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-25 16:11:15.455630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-25 16:11:15.455744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.456610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-25 16:11:15.457428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/datasets/build_pqr_data.py:112: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0325 16:11:15.458300 140564167899008 module_wrapper.py:139] From /content/models/research/deeplab/datasets/build_pqr_data.py:112: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "Processing train\r>> Converting image 1/62 shard 0WARNING:tensorflow:From /content/models/research/deeplab/datasets/build_pqr_data.py:128: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0325 16:11:15.458795 140564167899008 module_wrapper.py:139] From /content/models/research/deeplab/datasets/build_pqr_data.py:128: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\\377\\363\\277\\\"\\002@\\016\\335\\310\\313$\\001\\002\\231\\312\\021'\n",
            "\t [[{{node DecodeJpeg}}]]\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/deeplab/datasets/build_pqr_data.py\", line 156, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/deeplab/datasets/build_pqr_data.py\", line 152, in main\n",
            "    _convert_dataset(dataset_split)\n",
            "  File \"/content/models/research/deeplab/datasets/build_pqr_data.py\", line 129, in _convert_dataset\n",
            "    height, width = image_reader.read_image_dims(image_data)\n",
            "  File \"/content/models/research/deeplab/datasets/build_data.py\", line 82, in read_image_dims\n",
            "    image = self.decode_image(image_data)\n",
            "  File \"/content/models/research/deeplab/datasets/build_data.py\", line 98, in decode_image\n",
            "    feed_dict={self._decode_data: image_data})\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\\377\\363\\277\\\"\\002@\\016\\335\\310\\313$\\001\\002\\231\\312\\021'\n",
            "\t [[node DecodeJpeg (defined at usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "\n",
            "Original stack trace for 'DecodeJpeg':\n",
            "  File \"content/models/research/deeplab/datasets/build_pqr_data.py\", line 156, in <module>\n",
            "    tf.app.run()\n",
            "  File \"usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"content/models/research/deeplab/datasets/build_pqr_data.py\", line 152, in main\n",
            "    _convert_dataset(dataset_split)\n",
            "  File \"content/models/research/deeplab/datasets/build_pqr_data.py\", line 105, in _convert_dataset\n",
            "    image_reader = build_data.ImageReader('jpeg', channels=3)\n",
            "  File \"content/models/research/deeplab/datasets/build_data.py\", line 68, in __init__\n",
            "    channels=channels)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_image_ops.py\", line 1211, in decode_jpeg\n",
            "    dct_method=dct_method, name=name)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
            "    attrs, op_def, compute_device)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHDnigO0iaND",
        "outputId": "3f325811-24e5-4d2a-acca-faa3742558fc"
      },
      "source": [
        "cd /content/models/research"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2WAsWlFKQLN",
        "outputId": "b3a01934-9a95-4c91-d514-e326ba757884"
      },
      "source": [
        "!python /content/models/research/deeplab/datasets/data_generator.py "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZIAdMLshXkM",
        "outputId": "43b1091e-9404-499c-c96b-4daa21703888"
      },
      "source": [
        "!python /content/models/research/deeplab/input_preprocess.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqamF2SLCxgm",
        "outputId": "b16d75ef-7242-4158-910e-a204d8311977"
      },
      "source": [
        "!sh /content/models/research/train-pqr.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:464: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0321 20:38:45.900663 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:274: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0321 20:38:45.900892 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:274: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0321 20:38:45.901156 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:289: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0321 20:38:45.901378 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:290: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Training on train set\n",
            "I0321 20:38:45.901528 140436091496320 train.py:290] Training on train set\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0321 20:38:45.902526 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:314: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/datasets/data_generator.py:361: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0321 20:38:45.907476 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/datasets/data_generator.py:361: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0321 20:38:46.046266 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0321 20:38:46.047312 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2021-03-21 20:38:46.446153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-21 20:38:46.450968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:38:46.451742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-21 20:38:46.452149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-21 20:38:46.453341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-21 20:38:46.454675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-21 20:38:46.455109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-21 20:38:46.457017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-21 20:38:46.458329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-21 20:38:46.462619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-21 20:38:46.462736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:38:46.463472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:38:46.464197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0321 20:38:46.962654 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0321 20:38:47.549034 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.lin_space is deprecated. Please use tf.linspace instead.\n",
            "\n",
            "W0321 20:38:47.549695 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.lin_space is deprecated. Please use tf.linspace instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "W0321 20:38:47.550076 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "W0321 20:38:47.756958 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.reverse_v2 is deprecated. Please use tf.reverse instead.\n",
            "\n",
            "W0321 20:38:50.217285 140436091496320 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.reverse_v2 is deprecated. Please use tf.reverse instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/datasets/data_generator.py:350: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0321 20:38:50.462222 140436091496320 deprecation.py:323] From /content/models/research/deeplab/datasets/data_generator.py:350: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0321 20:38:50.488461 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0321 20:38:50.489022 140436091496320 deprecation.py:323] From /content/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/xception.py:469: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0321 20:38:50.491556 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/core/xception.py:469: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0321 20:38:50.494151 140436091496320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "W0321 20:38:56.877837 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/utils/train_utils.py:158: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:326: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0321 20:38:56.878258 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:326: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:326: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0321 20:38:56.878488 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:326: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:332: The name tf.model_variables is deprecated. Please use tf.compat.v1.model_variables instead.\n",
            "\n",
            "W0321 20:38:56.879381 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:332: The name tf.model_variables is deprecated. Please use tf.compat.v1.model_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0321 20:38:56.879665 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:333: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0321 20:38:57.852045 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:361: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "INFO:tensorflow:Setting decay_steps to total training steps.\n",
            "I0321 20:38:57.856012 140436091496320 train_utils.py:328] Setting decay_steps to total training steps.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/utils/train_utils.py:338: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0321 20:38:57.856229 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/utils/train_utils.py:338: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/utils/train_utils.py:373: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0321 20:38:57.865600 140436091496320 deprecation.py:323] From /content/models/research/deeplab/utils/train_utils.py:373: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W0321 20:38:57.868528 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:380: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:398: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "W0321 20:39:00.869190 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:398: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0321 20:39:03.706712 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:424: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/train.py:427: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0321 20:39:03.723051 140436091496320 module_wrapper.py:139] From /content/models/research/deeplab/train.py:427: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "INFO:tensorflow:Ignoring initialization; other checkpoint exists\n",
            "I0321 20:39:03.725686 140436091496320 train_utils.py:204] Ignoring initialization; other checkpoint exists\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W0321 20:39:05.648475 140436091496320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2021-03-21 20:39:06.728608: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-03-21 20:39:06.733790: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-03-21 20:39:06.734053: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5571a0c959c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-21 20:39:06.734101: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-21 20:39:06.825556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:39:06.826996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5571a0c95800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-21 20:39:06.827049: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-03-21 20:39:06.827279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:39:06.828924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-21 20:39:06.829024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-21 20:39:06.829071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-21 20:39:06.829128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-21 20:39:06.829182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-21 20:39:06.829220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-21 20:39:06.829272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-21 20:39:06.829314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-21 20:39:06.829426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:39:06.830385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:39:06.831166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-21 20:39:06.831245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-21 20:39:06.832925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-21 20:39:06.832966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-21 20:39:06.832989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-21 20:39:06.833146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:39:06.834135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-21 20:39:06.834927: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-21 20:39:06.834998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11309 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt-105000\n",
            "I0321 20:39:06.838277 140436091496320 saver.py:1284] Restoring parameters from /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt-105000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0321 20:39:09.606500 140436091496320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0321 20:39:09.612222 140436091496320 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0321 20:39:09.907932 140436091496320 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I0321 20:39:18.016223 140436091496320 learning.py:754] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 20:39:18.300781 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I0321 20:39:18.300989 140436091496320 learning.py:768] Starting Queues.\n",
            "2021-03-21 20:39:20.755199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-21 20:39:25.067340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:Recording summary at step 105000.\n",
            "I0321 20:39:26.918654 140432184936192 supervisor.py:1050] Recording summary at step 105000.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I0321 20:39:29.128481 140432193328896 supervisor.py:1099] global_step/sec: 0\n",
            "INFO:tensorflow:global step 105010: loss = 0.4056 (0.779 sec/step)\n",
            "I0321 20:39:39.720110 140436091496320 learning.py:507] global step 105010: loss = 0.4056 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 105020: loss = 0.3945 (0.777 sec/step)\n",
            "I0321 20:39:47.589410 140436091496320 learning.py:507] global step 105020: loss = 0.3945 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 105030: loss = 0.3793 (0.783 sec/step)\n",
            "I0321 20:39:55.686057 140436091496320 learning.py:507] global step 105030: loss = 0.3793 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 105040: loss = 0.4347 (0.829 sec/step)\n",
            "I0321 20:40:03.592559 140436091496320 learning.py:507] global step 105040: loss = 0.4347 (0.829 sec/step)\n",
            "INFO:tensorflow:global step 105050: loss = 0.3889 (0.783 sec/step)\n",
            "I0321 20:40:11.472435 140436091496320 learning.py:507] global step 105050: loss = 0.3889 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 105060: loss = 0.3897 (0.785 sec/step)\n",
            "I0321 20:40:19.540395 140436091496320 learning.py:507] global step 105060: loss = 0.3897 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 105070: loss = 0.3795 (0.777 sec/step)\n",
            "I0321 20:40:27.532590 140436091496320 learning.py:507] global step 105070: loss = 0.3795 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 105080: loss = 0.4151 (0.789 sec/step)\n",
            "I0321 20:40:35.405513 140436091496320 learning.py:507] global step 105080: loss = 0.4151 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 105090: loss = 0.3792 (0.778 sec/step)\n",
            "I0321 20:40:43.406987 140436091496320 learning.py:507] global step 105090: loss = 0.3792 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105100: loss = 0.4616 (0.784 sec/step)\n",
            "I0321 20:40:51.501219 140436091496320 learning.py:507] global step 105100: loss = 0.4616 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 105110: loss = 0.3613 (0.780 sec/step)\n",
            "I0321 20:40:59.620953 140436091496320 learning.py:507] global step 105110: loss = 0.3613 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 105120: loss = 0.3682 (0.804 sec/step)\n",
            "I0321 20:41:07.723834 140436091496320 learning.py:507] global step 105120: loss = 0.3682 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 105130: loss = 0.4291 (0.806 sec/step)\n",
            "I0321 20:41:15.586931 140436091496320 learning.py:507] global step 105130: loss = 0.4291 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 105140: loss = 0.3765 (0.778 sec/step)\n",
            "I0321 20:41:23.495800 140436091496320 learning.py:507] global step 105140: loss = 0.3765 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105150: loss = 0.3603 (0.781 sec/step)\n",
            "I0321 20:41:31.382545 140436091496320 learning.py:507] global step 105150: loss = 0.3603 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 105160: loss = 0.3488 (0.834 sec/step)\n",
            "I0321 20:41:39.309194 140436091496320 learning.py:507] global step 105160: loss = 0.3488 (0.834 sec/step)\n",
            "INFO:tensorflow:global step 105170: loss = 0.3982 (0.791 sec/step)\n",
            "I0321 20:41:47.278190 140436091496320 learning.py:507] global step 105170: loss = 0.3982 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 105180: loss = 0.3749 (0.785 sec/step)\n",
            "I0321 20:41:55.134618 140436091496320 learning.py:507] global step 105180: loss = 0.3749 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 105190: loss = 0.4162 (0.792 sec/step)\n",
            "I0321 20:42:02.998496 140436091496320 learning.py:507] global step 105190: loss = 0.4162 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 105200: loss = 0.3943 (0.785 sec/step)\n",
            "I0321 20:42:10.988569 140436091496320 learning.py:507] global step 105200: loss = 0.3943 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 105210: loss = 0.3769 (0.789 sec/step)\n",
            "I0321 20:42:18.880433 140436091496320 learning.py:507] global step 105210: loss = 0.3769 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 105220: loss = 0.3691 (0.811 sec/step)\n",
            "I0321 20:42:26.789355 140436091496320 learning.py:507] global step 105220: loss = 0.3691 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 105230: loss = 0.3837 (0.802 sec/step)\n",
            "I0321 20:42:34.769794 140436091496320 learning.py:507] global step 105230: loss = 0.3837 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 105240: loss = 0.3758 (0.780 sec/step)\n",
            "I0321 20:42:42.694955 140436091496320 learning.py:507] global step 105240: loss = 0.3758 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 105250: loss = 0.3653 (0.813 sec/step)\n",
            "I0321 20:42:50.914544 140436091496320 learning.py:507] global step 105250: loss = 0.3653 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 105260: loss = 0.4189 (0.774 sec/step)\n",
            "I0321 20:42:58.918618 140436091496320 learning.py:507] global step 105260: loss = 0.4189 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 105270: loss = 0.3717 (0.793 sec/step)\n",
            "I0321 20:43:07.006917 140436091496320 learning.py:507] global step 105270: loss = 0.3717 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 105280: loss = 0.4231 (0.792 sec/step)\n",
            "I0321 20:43:14.906575 140436091496320 learning.py:507] global step 105280: loss = 0.4231 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 105290: loss = 0.3918 (0.785 sec/step)\n",
            "I0321 20:43:22.759929 140436091496320 learning.py:507] global step 105290: loss = 0.3918 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 105300: loss = 0.3922 (0.779 sec/step)\n",
            "I0321 20:43:30.721743 140436091496320 learning.py:507] global step 105300: loss = 0.3922 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 105310: loss = 0.4236 (0.796 sec/step)\n",
            "I0321 20:43:38.637631 140436091496320 learning.py:507] global step 105310: loss = 0.4236 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 105320: loss = 0.3782 (0.805 sec/step)\n",
            "I0321 20:43:46.507984 140436091496320 learning.py:507] global step 105320: loss = 0.3782 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 105330: loss = 0.3715 (0.795 sec/step)\n",
            "I0321 20:43:54.433124 140436091496320 learning.py:507] global step 105330: loss = 0.3715 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 105340: loss = 0.3753 (0.778 sec/step)\n",
            "I0321 20:44:02.310056 140436091496320 learning.py:507] global step 105340: loss = 0.3753 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105350: loss = 0.4072 (0.784 sec/step)\n",
            "I0321 20:44:10.277044 140436091496320 learning.py:507] global step 105350: loss = 0.4072 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 105360: loss = 0.3701 (0.778 sec/step)\n",
            "I0321 20:44:18.170161 140436091496320 learning.py:507] global step 105360: loss = 0.3701 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105370: loss = 0.3917 (0.784 sec/step)\n",
            "I0321 20:44:26.010581 140436091496320 learning.py:507] global step 105370: loss = 0.3917 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 105380: loss = 0.3642 (0.781 sec/step)\n",
            "I0321 20:44:33.885359 140436091496320 learning.py:507] global step 105380: loss = 0.3642 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 105390: loss = 0.3651 (0.782 sec/step)\n",
            "I0321 20:44:41.935802 140436091496320 learning.py:507] global step 105390: loss = 0.3651 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 105400: loss = 0.3768 (0.831 sec/step)\n",
            "I0321 20:44:49.862299 140436091496320 learning.py:507] global step 105400: loss = 0.3768 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 105410: loss = 0.3826 (0.786 sec/step)\n",
            "I0321 20:44:57.862879 140436091496320 learning.py:507] global step 105410: loss = 0.3826 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 105420: loss = 0.3849 (0.786 sec/step)\n",
            "I0321 20:45:05.700610 140436091496320 learning.py:507] global step 105420: loss = 0.3849 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 105430: loss = 0.3605 (0.965 sec/step)\n",
            "I0321 20:45:13.750212 140436091496320 learning.py:507] global step 105430: loss = 0.3605 (0.965 sec/step)\n",
            "INFO:tensorflow:global step 105440: loss = 0.4225 (0.777 sec/step)\n",
            "I0321 20:45:21.839044 140436091496320 learning.py:507] global step 105440: loss = 0.4225 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 105450: loss = 0.3794 (0.780 sec/step)\n",
            "I0321 20:45:29.696261 140436091496320 learning.py:507] global step 105450: loss = 0.3794 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 105460: loss = 0.3667 (0.802 sec/step)\n",
            "I0321 20:45:37.589113 140436091496320 learning.py:507] global step 105460: loss = 0.3667 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 105470: loss = 0.3921 (0.780 sec/step)\n",
            "I0321 20:45:45.529508 140436091496320 learning.py:507] global step 105470: loss = 0.3921 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 105480: loss = 0.3890 (0.783 sec/step)\n",
            "I0321 20:45:53.408816 140436091496320 learning.py:507] global step 105480: loss = 0.3890 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 105490: loss = 0.4149 (0.801 sec/step)\n",
            "I0321 20:46:01.486298 140436091496320 learning.py:507] global step 105490: loss = 0.4149 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 105500: loss = 0.3911 (0.779 sec/step)\n",
            "I0321 20:46:09.465707 140436091496320 learning.py:507] global step 105500: loss = 0.3911 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 105510: loss = 0.3880 (0.777 sec/step)\n",
            "I0321 20:46:17.497773 140436091496320 learning.py:507] global step 105510: loss = 0.3880 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 105520: loss = 0.3663 (0.822 sec/step)\n",
            "I0321 20:46:25.400078 140436091496320 learning.py:507] global step 105520: loss = 0.3663 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 105530: loss = 0.4157 (0.786 sec/step)\n",
            "I0321 20:46:33.336610 140436091496320 learning.py:507] global step 105530: loss = 0.4157 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 105540: loss = 0.3677 (0.783 sec/step)\n",
            "I0321 20:46:41.243574 140436091496320 learning.py:507] global step 105540: loss = 0.3677 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 105550: loss = 0.3761 (0.870 sec/step)\n",
            "I0321 20:46:49.255767 140436091496320 learning.py:507] global step 105550: loss = 0.3761 (0.870 sec/step)\n",
            "INFO:tensorflow:global step 105560: loss = 0.3946 (0.784 sec/step)\n",
            "I0321 20:46:57.268426 140436091496320 learning.py:507] global step 105560: loss = 0.3946 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 105570: loss = 0.3737 (0.787 sec/step)\n",
            "I0321 20:47:05.250477 140436091496320 learning.py:507] global step 105570: loss = 0.3737 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 105580: loss = 0.4017 (0.801 sec/step)\n",
            "I0321 20:47:13.333652 140436091496320 learning.py:507] global step 105580: loss = 0.4017 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 105590: loss = 0.4070 (0.788 sec/step)\n",
            "I0321 20:47:21.259318 140436091496320 learning.py:507] global step 105590: loss = 0.4070 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 105600: loss = 0.3793 (0.807 sec/step)\n",
            "I0321 20:47:29.199048 140436091496320 learning.py:507] global step 105600: loss = 0.3793 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 105610: loss = 0.3776 (0.799 sec/step)\n",
            "I0321 20:47:37.399830 140436091496320 learning.py:507] global step 105610: loss = 0.3776 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 105620: loss = 0.3616 (0.787 sec/step)\n",
            "I0321 20:47:45.339240 140436091496320 learning.py:507] global step 105620: loss = 0.3616 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 105630: loss = 0.3709 (0.778 sec/step)\n",
            "I0321 20:47:53.262326 140436091496320 learning.py:507] global step 105630: loss = 0.3709 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105640: loss = 0.3762 (0.792 sec/step)\n",
            "I0321 20:48:01.117519 140436091496320 learning.py:507] global step 105640: loss = 0.3762 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 105650: loss = 0.3841 (0.780 sec/step)\n",
            "I0321 20:48:08.959917 140436091496320 learning.py:507] global step 105650: loss = 0.3841 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 105660: loss = 0.4056 (0.779 sec/step)\n",
            "I0321 20:48:16.802144 140436091496320 learning.py:507] global step 105660: loss = 0.4056 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 105670: loss = 0.3697 (0.875 sec/step)\n",
            "I0321 20:48:25.031160 140436091496320 learning.py:507] global step 105670: loss = 0.3697 (0.875 sec/step)\n",
            "INFO:tensorflow:global step 105680: loss = 0.3772 (0.788 sec/step)\n",
            "I0321 20:48:32.979249 140436091496320 learning.py:507] global step 105680: loss = 0.3772 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 105690: loss = 0.4404 (0.784 sec/step)\n",
            "I0321 20:48:40.868925 140436091496320 learning.py:507] global step 105690: loss = 0.4404 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 105700: loss = 0.4690 (0.776 sec/step)\n",
            "I0321 20:48:48.904591 140436091496320 learning.py:507] global step 105700: loss = 0.4690 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 105710: loss = 0.3726 (0.775 sec/step)\n",
            "I0321 20:48:56.781087 140436091496320 learning.py:507] global step 105710: loss = 0.3726 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 105720: loss = 0.3623 (0.799 sec/step)\n",
            "I0321 20:49:04.890203 140436091496320 learning.py:507] global step 105720: loss = 0.3623 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 105730: loss = 0.3696 (0.786 sec/step)\n",
            "I0321 20:49:12.805771 140436091496320 learning.py:507] global step 105730: loss = 0.3696 (0.786 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 105737.\n",
            "I0321 20:49:19.810825 140432184936192 supervisor.py:1050] Recording summary at step 105737.\n",
            "INFO:tensorflow:global_step/sec: 1.24764\n",
            "I0321 20:49:20.647322 140432193328896 supervisor.py:1099] global_step/sec: 1.24764\n",
            "INFO:tensorflow:global step 105740: loss = 0.3739 (0.791 sec/step)\n",
            "I0321 20:49:22.089025 140436091496320 learning.py:507] global step 105740: loss = 0.3739 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 105750: loss = 0.3813 (0.799 sec/step)\n",
            "I0321 20:49:30.017348 140436091496320 learning.py:507] global step 105750: loss = 0.3813 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 105760: loss = 0.3885 (0.776 sec/step)\n",
            "I0321 20:49:38.059879 140436091496320 learning.py:507] global step 105760: loss = 0.3885 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 105770: loss = 0.3646 (0.782 sec/step)\n",
            "I0321 20:49:45.942922 140436091496320 learning.py:507] global step 105770: loss = 0.3646 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 105780: loss = 0.3649 (0.796 sec/step)\n",
            "I0321 20:49:53.911911 140436091496320 learning.py:507] global step 105780: loss = 0.3649 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 105790: loss = 0.3529 (0.783 sec/step)\n",
            "I0321 20:50:01.937874 140436091496320 learning.py:507] global step 105790: loss = 0.3529 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 105800: loss = 0.3879 (0.783 sec/step)\n",
            "I0321 20:50:09.853307 140436091496320 learning.py:507] global step 105800: loss = 0.3879 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 105810: loss = 0.4065 (1.011 sec/step)\n",
            "I0321 20:50:17.930809 140436091496320 learning.py:507] global step 105810: loss = 0.4065 (1.011 sec/step)\n",
            "INFO:tensorflow:global step 105820: loss = 0.3762 (0.785 sec/step)\n",
            "I0321 20:50:25.994971 140436091496320 learning.py:507] global step 105820: loss = 0.3762 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 105830: loss = 0.4158 (0.777 sec/step)\n",
            "I0321 20:50:33.833086 140436091496320 learning.py:507] global step 105830: loss = 0.4158 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 105840: loss = 0.3828 (0.806 sec/step)\n",
            "I0321 20:50:41.725195 140436091496320 learning.py:507] global step 105840: loss = 0.3828 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 105850: loss = 0.4107 (0.787 sec/step)\n",
            "I0321 20:50:49.653715 140436091496320 learning.py:507] global step 105850: loss = 0.4107 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 105860: loss = 0.3901 (0.797 sec/step)\n",
            "I0321 20:50:57.523501 140436091496320 learning.py:507] global step 105860: loss = 0.3901 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 105870: loss = 0.3780 (0.793 sec/step)\n",
            "I0321 20:51:05.453421 140436091496320 learning.py:507] global step 105870: loss = 0.3780 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 105880: loss = 0.3830 (0.780 sec/step)\n",
            "I0321 20:51:13.446473 140436091496320 learning.py:507] global step 105880: loss = 0.3830 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 105890: loss = 0.3678 (0.779 sec/step)\n",
            "I0321 20:51:21.295539 140436091496320 learning.py:507] global step 105890: loss = 0.3678 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 105900: loss = 0.3871 (0.812 sec/step)\n",
            "I0321 20:51:29.341527 140436091496320 learning.py:507] global step 105900: loss = 0.3871 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 105910: loss = 0.3517 (0.783 sec/step)\n",
            "I0321 20:51:37.291973 140436091496320 learning.py:507] global step 105910: loss = 0.3517 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 105920: loss = 0.3679 (0.778 sec/step)\n",
            "I0321 20:51:45.267837 140436091496320 learning.py:507] global step 105920: loss = 0.3679 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105930: loss = 0.3606 (0.786 sec/step)\n",
            "I0321 20:51:53.268381 140436091496320 learning.py:507] global step 105930: loss = 0.3606 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 105940: loss = 0.4497 (0.778 sec/step)\n",
            "I0321 20:52:01.101707 140436091496320 learning.py:507] global step 105940: loss = 0.4497 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105950: loss = 0.4148 (0.803 sec/step)\n",
            "I0321 20:52:08.994619 140436091496320 learning.py:507] global step 105950: loss = 0.4148 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 105960: loss = 0.3831 (0.778 sec/step)\n",
            "I0321 20:52:16.962425 140436091496320 learning.py:507] global step 105960: loss = 0.3831 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105970: loss = 0.3750 (0.793 sec/step)\n",
            "I0321 20:52:25.096631 140436091496320 learning.py:507] global step 105970: loss = 0.3750 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 105980: loss = 0.3776 (0.778 sec/step)\n",
            "I0321 20:52:33.025770 140436091496320 learning.py:507] global step 105980: loss = 0.3776 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 105990: loss = 0.3646 (0.776 sec/step)\n",
            "I0321 20:52:40.861023 140436091496320 learning.py:507] global step 105990: loss = 0.3646 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 106000: loss = 0.3783 (0.789 sec/step)\n",
            "I0321 20:52:48.789669 140436091496320 learning.py:507] global step 106000: loss = 0.3783 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 106010: loss = 0.3711 (0.789 sec/step)\n",
            "I0321 20:52:56.678628 140436091496320 learning.py:507] global step 106010: loss = 0.3711 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 106020: loss = 0.3855 (0.784 sec/step)\n",
            "I0321 20:53:04.656646 140436091496320 learning.py:507] global step 106020: loss = 0.3855 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 106030: loss = 0.3766 (0.781 sec/step)\n",
            "I0321 20:53:12.531759 140436091496320 learning.py:507] global step 106030: loss = 0.3766 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106040: loss = 0.3624 (0.779 sec/step)\n",
            "I0321 20:53:20.551196 140436091496320 learning.py:507] global step 106040: loss = 0.3624 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106050: loss = 0.3713 (0.950 sec/step)\n",
            "I0321 20:53:28.606285 140436091496320 learning.py:507] global step 106050: loss = 0.3713 (0.950 sec/step)\n",
            "INFO:tensorflow:global step 106060: loss = 0.3864 (0.793 sec/step)\n",
            "I0321 20:53:36.731477 140436091496320 learning.py:507] global step 106060: loss = 0.3864 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 106070: loss = 0.3741 (0.775 sec/step)\n",
            "I0321 20:53:44.646007 140436091496320 learning.py:507] global step 106070: loss = 0.3741 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 106080: loss = 0.3550 (0.874 sec/step)\n",
            "I0321 20:53:52.921816 140436091496320 learning.py:507] global step 106080: loss = 0.3550 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 106090: loss = 0.3721 (0.783 sec/step)\n",
            "I0321 20:54:00.886528 140436091496320 learning.py:507] global step 106090: loss = 0.3721 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 106100: loss = 0.3929 (0.775 sec/step)\n",
            "I0321 20:54:08.731327 140436091496320 learning.py:507] global step 106100: loss = 0.3929 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 106110: loss = 0.3847 (0.814 sec/step)\n",
            "I0321 20:54:16.668005 140436091496320 learning.py:507] global step 106110: loss = 0.3847 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 106120: loss = 0.3852 (0.781 sec/step)\n",
            "I0321 20:54:24.705527 140436091496320 learning.py:507] global step 106120: loss = 0.3852 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106130: loss = 0.3536 (0.783 sec/step)\n",
            "I0321 20:54:32.581785 140436091496320 learning.py:507] global step 106130: loss = 0.3536 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 106140: loss = 0.3967 (0.807 sec/step)\n",
            "I0321 20:54:40.705137 140436091496320 learning.py:507] global step 106140: loss = 0.3967 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 106150: loss = 0.3753 (0.778 sec/step)\n",
            "I0321 20:54:48.659795 140436091496320 learning.py:507] global step 106150: loss = 0.3753 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 106160: loss = 0.4372 (0.779 sec/step)\n",
            "I0321 20:54:56.732666 140436091496320 learning.py:507] global step 106160: loss = 0.4372 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106170: loss = 0.3841 (0.792 sec/step)\n",
            "I0321 20:55:04.601776 140436091496320 learning.py:507] global step 106170: loss = 0.3841 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 106180: loss = 0.3717 (0.784 sec/step)\n",
            "I0321 20:55:12.509916 140436091496320 learning.py:507] global step 106180: loss = 0.3717 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 106190: loss = 0.3720 (0.784 sec/step)\n",
            "I0321 20:55:20.424916 140436091496320 learning.py:507] global step 106190: loss = 0.3720 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 106200: loss = 0.3701 (0.792 sec/step)\n",
            "I0321 20:55:28.357029 140436091496320 learning.py:507] global step 106200: loss = 0.3701 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 106210: loss = 0.3632 (0.777 sec/step)\n",
            "I0321 20:55:36.187381 140436091496320 learning.py:507] global step 106210: loss = 0.3632 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 106220: loss = 0.3617 (0.777 sec/step)\n",
            "I0321 20:55:44.213214 140436091496320 learning.py:507] global step 106220: loss = 0.3617 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 106230: loss = 0.3735 (0.787 sec/step)\n",
            "I0321 20:55:52.549739 140436091496320 learning.py:507] global step 106230: loss = 0.3735 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 106240: loss = 0.4626 (0.782 sec/step)\n",
            "I0321 20:56:00.428483 140436091496320 learning.py:507] global step 106240: loss = 0.4626 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 106250: loss = 0.3538 (0.780 sec/step)\n",
            "I0321 20:56:08.624458 140436091496320 learning.py:507] global step 106250: loss = 0.3538 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 106260: loss = 0.4000 (0.779 sec/step)\n",
            "I0321 20:56:16.602689 140436091496320 learning.py:507] global step 106260: loss = 0.4000 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106270: loss = 0.3946 (0.789 sec/step)\n",
            "I0321 20:56:24.491273 140436091496320 learning.py:507] global step 106270: loss = 0.3946 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 106280: loss = 0.3588 (0.779 sec/step)\n",
            "I0321 20:56:32.382807 140436091496320 learning.py:507] global step 106280: loss = 0.3588 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106290: loss = 0.4129 (0.791 sec/step)\n",
            "I0321 20:56:40.264968 140436091496320 learning.py:507] global step 106290: loss = 0.4129 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 106300: loss = 0.3604 (0.778 sec/step)\n",
            "I0321 20:56:48.105255 140436091496320 learning.py:507] global step 106300: loss = 0.3604 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 106310: loss = 0.3630 (0.794 sec/step)\n",
            "I0321 20:56:56.478448 140436091496320 learning.py:507] global step 106310: loss = 0.3630 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 106320: loss = 0.4075 (0.775 sec/step)\n",
            "I0321 20:57:04.452964 140436091496320 learning.py:507] global step 106320: loss = 0.4075 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 106330: loss = 0.3585 (0.781 sec/step)\n",
            "I0321 20:57:12.335718 140436091496320 learning.py:507] global step 106330: loss = 0.3585 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106340: loss = 0.4218 (0.781 sec/step)\n",
            "I0321 20:57:20.282723 140436091496320 learning.py:507] global step 106340: loss = 0.4218 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106350: loss = 0.3632 (0.805 sec/step)\n",
            "I0321 20:57:28.230898 140436091496320 learning.py:507] global step 106350: loss = 0.3632 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 106360: loss = 0.3840 (0.775 sec/step)\n",
            "I0321 20:57:36.095460 140436091496320 learning.py:507] global step 106360: loss = 0.3840 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 106370: loss = 0.3786 (0.779 sec/step)\n",
            "I0321 20:57:44.000054 140436091496320 learning.py:507] global step 106370: loss = 0.3786 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106380: loss = 0.3747 (0.782 sec/step)\n",
            "I0321 20:57:51.860440 140436091496320 learning.py:507] global step 106380: loss = 0.3747 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 106390: loss = 0.4106 (0.810 sec/step)\n",
            "I0321 20:57:59.867294 140436091496320 learning.py:507] global step 106390: loss = 0.4106 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 106400: loss = 0.3746 (0.780 sec/step)\n",
            "I0321 20:58:07.734546 140436091496320 learning.py:507] global step 106400: loss = 0.3746 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 106410: loss = 0.3591 (0.800 sec/step)\n",
            "I0321 20:58:15.787243 140436091496320 learning.py:507] global step 106410: loss = 0.3591 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 106420: loss = 0.3691 (0.785 sec/step)\n",
            "I0321 20:58:23.820652 140436091496320 learning.py:507] global step 106420: loss = 0.3691 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 106430: loss = 0.3789 (0.776 sec/step)\n",
            "I0321 20:58:31.710494 140436091496320 learning.py:507] global step 106430: loss = 0.3789 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 106440: loss = 0.3619 (0.947 sec/step)\n",
            "I0321 20:58:39.859246 140436091496320 learning.py:507] global step 106440: loss = 0.3619 (0.947 sec/step)\n",
            "INFO:tensorflow:global step 106450: loss = 0.3693 (0.776 sec/step)\n",
            "I0321 20:58:47.734461 140436091496320 learning.py:507] global step 106450: loss = 0.3693 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 106460: loss = 0.4021 (0.780 sec/step)\n",
            "I0321 20:58:55.629217 140436091496320 learning.py:507] global step 106460: loss = 0.4021 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 106470: loss = 0.3946 (0.786 sec/step)\n",
            "I0321 20:59:03.512184 140436091496320 learning.py:507] global step 106470: loss = 0.3946 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 106480: loss = 0.3678 (0.777 sec/step)\n",
            "I0321 20:59:11.416088 140436091496320 learning.py:507] global step 106480: loss = 0.3678 (0.777 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 20:59:18.302169 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0321 20:59:20.447393 140432201721600 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:global_step/sec: 1.25112\n",
            "I0321 20:59:20.909136 140432193328896 supervisor.py:1099] global_step/sec: 1.25112\n",
            "INFO:tensorflow:Recording summary at step 106489.\n",
            "I0321 20:59:20.948873 140432184936192 supervisor.py:1050] Recording summary at step 106489.\n",
            "INFO:tensorflow:global step 106490: loss = 0.3845 (1.236 sec/step)\n",
            "I0321 20:59:21.757964 140436091496320 learning.py:507] global step 106490: loss = 0.3845 (1.236 sec/step)\n",
            "INFO:tensorflow:global step 106500: loss = 0.3671 (0.781 sec/step)\n",
            "I0321 20:59:29.725543 140436091496320 learning.py:507] global step 106500: loss = 0.3671 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106510: loss = 0.3652 (0.791 sec/step)\n",
            "I0321 20:59:37.583326 140436091496320 learning.py:507] global step 106510: loss = 0.3652 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 106520: loss = 0.3636 (0.795 sec/step)\n",
            "I0321 20:59:45.664299 140436091496320 learning.py:507] global step 106520: loss = 0.3636 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 106530: loss = 0.3750 (0.785 sec/step)\n",
            "I0321 20:59:53.656488 140436091496320 learning.py:507] global step 106530: loss = 0.3750 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 106540: loss = 0.3855 (0.777 sec/step)\n",
            "I0321 21:00:01.538507 140436091496320 learning.py:507] global step 106540: loss = 0.3855 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 106550: loss = 0.3821 (0.929 sec/step)\n",
            "I0321 21:00:09.550859 140436091496320 learning.py:507] global step 106550: loss = 0.3821 (0.929 sec/step)\n",
            "INFO:tensorflow:global step 106560: loss = 0.3838 (0.776 sec/step)\n",
            "I0321 21:00:17.666836 140436091496320 learning.py:507] global step 106560: loss = 0.3838 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 106570: loss = 0.3488 (0.783 sec/step)\n",
            "I0321 21:00:25.533673 140436091496320 learning.py:507] global step 106570: loss = 0.3488 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 106580: loss = 0.3524 (0.779 sec/step)\n",
            "I0321 21:00:33.507498 140436091496320 learning.py:507] global step 106580: loss = 0.3524 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106590: loss = 0.3700 (0.785 sec/step)\n",
            "I0321 21:00:41.588719 140436091496320 learning.py:507] global step 106590: loss = 0.3700 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 106600: loss = 0.3656 (0.784 sec/step)\n",
            "I0321 21:00:49.570443 140436091496320 learning.py:507] global step 106600: loss = 0.3656 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 106610: loss = 0.3449 (0.973 sec/step)\n",
            "I0321 21:00:57.805717 140436091496320 learning.py:507] global step 106610: loss = 0.3449 (0.973 sec/step)\n",
            "INFO:tensorflow:global step 106620: loss = 0.3738 (0.783 sec/step)\n",
            "I0321 21:01:05.780686 140436091496320 learning.py:507] global step 106620: loss = 0.3738 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 106630: loss = 0.3656 (0.781 sec/step)\n",
            "I0321 21:01:13.664428 140436091496320 learning.py:507] global step 106630: loss = 0.3656 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106640: loss = 0.3824 (0.778 sec/step)\n",
            "I0321 21:01:21.694490 140436091496320 learning.py:507] global step 106640: loss = 0.3824 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 106650: loss = 0.4144 (0.784 sec/step)\n",
            "I0321 21:01:29.577359 140436091496320 learning.py:507] global step 106650: loss = 0.4144 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 106660: loss = 0.3932 (0.806 sec/step)\n",
            "I0321 21:01:37.597586 140436091496320 learning.py:507] global step 106660: loss = 0.3932 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 106670: loss = 0.3681 (0.919 sec/step)\n",
            "I0321 21:01:45.770294 140436091496320 learning.py:507] global step 106670: loss = 0.3681 (0.919 sec/step)\n",
            "INFO:tensorflow:global step 106680: loss = 0.3577 (0.779 sec/step)\n",
            "I0321 21:01:53.973443 140436091496320 learning.py:507] global step 106680: loss = 0.3577 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106690: loss = 0.3700 (0.796 sec/step)\n",
            "I0321 21:02:01.951947 140436091496320 learning.py:507] global step 106690: loss = 0.3700 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 106700: loss = 0.3719 (0.791 sec/step)\n",
            "I0321 21:02:10.016311 140436091496320 learning.py:507] global step 106700: loss = 0.3719 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 106710: loss = 0.3673 (0.786 sec/step)\n",
            "I0321 21:02:17.886754 140436091496320 learning.py:507] global step 106710: loss = 0.3673 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 106720: loss = 0.3807 (0.786 sec/step)\n",
            "I0321 21:02:25.833099 140436091496320 learning.py:507] global step 106720: loss = 0.3807 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 106730: loss = 0.3515 (0.932 sec/step)\n",
            "I0321 21:02:33.888654 140436091496320 learning.py:507] global step 106730: loss = 0.3515 (0.932 sec/step)\n",
            "INFO:tensorflow:global step 106740: loss = 0.3726 (0.778 sec/step)\n",
            "I0321 21:02:41.868379 140436091496320 learning.py:507] global step 106740: loss = 0.3726 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 106750: loss = 0.3815 (0.803 sec/step)\n",
            "I0321 21:02:49.803927 140436091496320 learning.py:507] global step 106750: loss = 0.3815 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 106760: loss = 0.3903 (0.843 sec/step)\n",
            "I0321 21:02:57.813165 140436091496320 learning.py:507] global step 106760: loss = 0.3903 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 106770: loss = 0.4020 (0.803 sec/step)\n",
            "I0321 21:03:05.891441 140436091496320 learning.py:507] global step 106770: loss = 0.4020 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 106780: loss = 0.3602 (0.784 sec/step)\n",
            "I0321 21:03:13.840182 140436091496320 learning.py:507] global step 106780: loss = 0.3602 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 106790: loss = 0.3973 (0.791 sec/step)\n",
            "I0321 21:03:21.812864 140436091496320 learning.py:507] global step 106790: loss = 0.3973 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 106800: loss = 0.3662 (0.779 sec/step)\n",
            "I0321 21:03:29.810793 140436091496320 learning.py:507] global step 106800: loss = 0.3662 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 106810: loss = 0.3658 (0.781 sec/step)\n",
            "I0321 21:03:37.743597 140436091496320 learning.py:507] global step 106810: loss = 0.3658 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106820: loss = 0.3705 (0.799 sec/step)\n",
            "I0321 21:03:45.625653 140436091496320 learning.py:507] global step 106820: loss = 0.3705 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 106830: loss = 0.3820 (0.801 sec/step)\n",
            "I0321 21:03:53.686181 140436091496320 learning.py:507] global step 106830: loss = 0.3820 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 106840: loss = 0.3725 (0.780 sec/step)\n",
            "I0321 21:04:01.625407 140436091496320 learning.py:507] global step 106840: loss = 0.3725 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 106850: loss = 0.3865 (0.793 sec/step)\n",
            "I0321 21:04:09.494022 140436091496320 learning.py:507] global step 106850: loss = 0.3865 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 106860: loss = 0.3326 (0.786 sec/step)\n",
            "I0321 21:04:17.723987 140436091496320 learning.py:507] global step 106860: loss = 0.3326 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 106870: loss = 0.3720 (0.780 sec/step)\n",
            "I0321 21:04:25.615333 140436091496320 learning.py:507] global step 106870: loss = 0.3720 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 106880: loss = 0.3737 (0.788 sec/step)\n",
            "I0321 21:04:33.596674 140436091496320 learning.py:507] global step 106880: loss = 0.3737 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 106890: loss = 0.3915 (0.778 sec/step)\n",
            "I0321 21:04:41.777465 140436091496320 learning.py:507] global step 106890: loss = 0.3915 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 106900: loss = 0.3698 (0.778 sec/step)\n",
            "I0321 21:04:49.636487 140436091496320 learning.py:507] global step 106900: loss = 0.3698 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 106910: loss = 0.3899 (0.801 sec/step)\n",
            "I0321 21:04:57.529066 140436091496320 learning.py:507] global step 106910: loss = 0.3899 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 106920: loss = 0.3824 (0.776 sec/step)\n",
            "I0321 21:05:05.377025 140436091496320 learning.py:507] global step 106920: loss = 0.3824 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 106930: loss = 0.3778 (0.784 sec/step)\n",
            "I0321 21:05:13.296536 140436091496320 learning.py:507] global step 106930: loss = 0.3778 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 106940: loss = 0.4327 (0.895 sec/step)\n",
            "I0321 21:05:21.277603 140436091496320 learning.py:507] global step 106940: loss = 0.4327 (0.895 sec/step)\n",
            "INFO:tensorflow:global step 106950: loss = 0.4701 (0.783 sec/step)\n",
            "I0321 21:05:29.225415 140436091496320 learning.py:507] global step 106950: loss = 0.4701 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 106960: loss = 0.3632 (0.780 sec/step)\n",
            "I0321 21:05:37.202991 140436091496320 learning.py:507] global step 106960: loss = 0.3632 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 106970: loss = 0.3839 (0.951 sec/step)\n",
            "I0321 21:05:45.191866 140436091496320 learning.py:507] global step 106970: loss = 0.3839 (0.951 sec/step)\n",
            "INFO:tensorflow:global step 106980: loss = 0.3663 (0.781 sec/step)\n",
            "I0321 21:05:53.181308 140436091496320 learning.py:507] global step 106980: loss = 0.3663 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 106990: loss = 0.4007 (0.788 sec/step)\n",
            "I0321 21:06:01.065672 140436091496320 learning.py:507] global step 106990: loss = 0.4007 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 107000: loss = 0.3613 (0.777 sec/step)\n",
            "I0321 21:06:08.928049 140436091496320 learning.py:507] global step 107000: loss = 0.3613 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 107010: loss = 0.4444 (0.782 sec/step)\n",
            "I0321 21:06:16.901691 140436091496320 learning.py:507] global step 107010: loss = 0.4444 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 107020: loss = 0.3792 (0.784 sec/step)\n",
            "I0321 21:06:24.777596 140436091496320 learning.py:507] global step 107020: loss = 0.3792 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 107030: loss = 0.3616 (0.811 sec/step)\n",
            "I0321 21:06:32.780537 140436091496320 learning.py:507] global step 107030: loss = 0.3616 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 107040: loss = 0.4215 (0.780 sec/step)\n",
            "I0321 21:06:40.794978 140436091496320 learning.py:507] global step 107040: loss = 0.4215 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107050: loss = 0.3930 (0.777 sec/step)\n",
            "I0321 21:06:48.679824 140436091496320 learning.py:507] global step 107050: loss = 0.3930 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 107060: loss = 0.3676 (0.775 sec/step)\n",
            "I0321 21:06:56.595750 140436091496320 learning.py:507] global step 107060: loss = 0.3676 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 107070: loss = 0.3701 (0.779 sec/step)\n",
            "I0321 21:07:04.512373 140436091496320 learning.py:507] global step 107070: loss = 0.3701 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 107080: loss = 0.3755 (0.779 sec/step)\n",
            "I0321 21:07:12.515523 140436091496320 learning.py:507] global step 107080: loss = 0.3755 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 107090: loss = 0.3561 (0.924 sec/step)\n",
            "I0321 21:07:20.740346 140436091496320 learning.py:507] global step 107090: loss = 0.3561 (0.924 sec/step)\n",
            "INFO:tensorflow:global step 107100: loss = 0.3619 (0.789 sec/step)\n",
            "I0321 21:07:28.623919 140436091496320 learning.py:507] global step 107100: loss = 0.3619 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 107110: loss = 0.3641 (0.776 sec/step)\n",
            "I0321 21:07:36.505427 140436091496320 learning.py:507] global step 107110: loss = 0.3641 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 107120: loss = 0.3788 (0.788 sec/step)\n",
            "I0321 21:07:44.417339 140436091496320 learning.py:507] global step 107120: loss = 0.3788 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 107130: loss = 0.4553 (0.780 sec/step)\n",
            "I0321 21:07:52.487669 140436091496320 learning.py:507] global step 107130: loss = 0.4553 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107140: loss = 0.3790 (0.784 sec/step)\n",
            "I0321 21:08:00.487685 140436091496320 learning.py:507] global step 107140: loss = 0.3790 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 107150: loss = 0.3528 (0.797 sec/step)\n",
            "I0321 21:08:08.393283 140436091496320 learning.py:507] global step 107150: loss = 0.3528 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 107160: loss = 0.3800 (0.788 sec/step)\n",
            "I0321 21:08:16.439075 140436091496320 learning.py:507] global step 107160: loss = 0.3800 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 107170: loss = 0.3863 (0.777 sec/step)\n",
            "I0321 21:08:24.339041 140436091496320 learning.py:507] global step 107170: loss = 0.3863 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 107180: loss = 0.3722 (0.776 sec/step)\n",
            "I0321 21:08:32.218218 140436091496320 learning.py:507] global step 107180: loss = 0.3722 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 107190: loss = 0.3894 (0.779 sec/step)\n",
            "I0321 21:08:40.105274 140436091496320 learning.py:507] global step 107190: loss = 0.3894 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 107200: loss = 0.3813 (0.786 sec/step)\n",
            "I0321 21:08:48.075758 140436091496320 learning.py:507] global step 107200: loss = 0.3813 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 107210: loss = 0.3905 (0.803 sec/step)\n",
            "I0321 21:08:55.979449 140436091496320 learning.py:507] global step 107210: loss = 0.3905 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 107220: loss = 0.3779 (0.782 sec/step)\n",
            "I0321 21:09:03.963084 140436091496320 learning.py:507] global step 107220: loss = 0.3779 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 107230: loss = 0.3759 (0.797 sec/step)\n",
            "I0321 21:09:12.002791 140436091496320 learning.py:507] global step 107230: loss = 0.3759 (0.797 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 107238.\n",
            "I0321 21:09:20.083630 140432184936192 supervisor.py:1050] Recording summary at step 107238.\n",
            "INFO:tensorflow:global_step/sec: 1.24888\n",
            "I0321 21:09:20.647378 140432193328896 supervisor.py:1099] global_step/sec: 1.24888\n",
            "INFO:tensorflow:global step 107240: loss = 0.3871 (0.778 sec/step)\n",
            "I0321 21:09:21.560564 140436091496320 learning.py:507] global step 107240: loss = 0.3871 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107250: loss = 0.3701 (0.778 sec/step)\n",
            "I0321 21:09:29.467925 140436091496320 learning.py:507] global step 107250: loss = 0.3701 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107260: loss = 0.3840 (0.808 sec/step)\n",
            "I0321 21:09:37.386840 140436091496320 learning.py:507] global step 107260: loss = 0.3840 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 107270: loss = 0.3867 (0.780 sec/step)\n",
            "I0321 21:09:45.366416 140436091496320 learning.py:507] global step 107270: loss = 0.3867 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107280: loss = 0.3938 (0.779 sec/step)\n",
            "I0321 21:09:53.249474 140436091496320 learning.py:507] global step 107280: loss = 0.3938 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 107290: loss = 0.4080 (0.782 sec/step)\n",
            "I0321 21:10:01.246777 140436091496320 learning.py:507] global step 107290: loss = 0.4080 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 107300: loss = 0.3897 (0.778 sec/step)\n",
            "I0321 21:10:09.082381 140436091496320 learning.py:507] global step 107300: loss = 0.3897 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107310: loss = 0.3610 (0.777 sec/step)\n",
            "I0321 21:10:17.296915 140436091496320 learning.py:507] global step 107310: loss = 0.3610 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 107320: loss = 0.3623 (0.798 sec/step)\n",
            "I0321 21:10:25.162439 140436091496320 learning.py:507] global step 107320: loss = 0.3623 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 107330: loss = 0.3661 (0.802 sec/step)\n",
            "I0321 21:10:33.057926 140436091496320 learning.py:507] global step 107330: loss = 0.3661 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 107340: loss = 0.3893 (0.775 sec/step)\n",
            "I0321 21:10:41.051738 140436091496320 learning.py:507] global step 107340: loss = 0.3893 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 107350: loss = 0.3910 (0.798 sec/step)\n",
            "I0321 21:10:48.926863 140436091496320 learning.py:507] global step 107350: loss = 0.3910 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 107360: loss = 0.3646 (0.785 sec/step)\n",
            "I0321 21:10:56.909313 140436091496320 learning.py:507] global step 107360: loss = 0.3646 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 107370: loss = 0.3801 (0.778 sec/step)\n",
            "I0321 21:11:04.935202 140436091496320 learning.py:507] global step 107370: loss = 0.3801 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107380: loss = 0.3568 (0.788 sec/step)\n",
            "I0321 21:11:12.869815 140436091496320 learning.py:507] global step 107380: loss = 0.3568 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 107390: loss = 0.3749 (0.792 sec/step)\n",
            "I0321 21:11:20.839771 140436091496320 learning.py:507] global step 107390: loss = 0.3749 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 107400: loss = 0.4094 (0.781 sec/step)\n",
            "I0321 21:11:28.697158 140436091496320 learning.py:507] global step 107400: loss = 0.4094 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 107410: loss = 0.3637 (0.788 sec/step)\n",
            "I0321 21:11:36.600175 140436091496320 learning.py:507] global step 107410: loss = 0.3637 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 107420: loss = 0.3544 (0.776 sec/step)\n",
            "I0321 21:11:44.535378 140436091496320 learning.py:507] global step 107420: loss = 0.3544 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 107430: loss = 0.3628 (0.794 sec/step)\n",
            "I0321 21:11:52.560476 140436091496320 learning.py:507] global step 107430: loss = 0.3628 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 107440: loss = 0.3415 (0.785 sec/step)\n",
            "I0321 21:12:00.524602 140436091496320 learning.py:507] global step 107440: loss = 0.3415 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 107450: loss = 0.3690 (0.778 sec/step)\n",
            "I0321 21:12:08.558748 140436091496320 learning.py:507] global step 107450: loss = 0.3690 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107460: loss = 0.3525 (0.774 sec/step)\n",
            "I0321 21:12:16.377470 140436091496320 learning.py:507] global step 107460: loss = 0.3525 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 107470: loss = 0.3755 (0.798 sec/step)\n",
            "I0321 21:12:24.453628 140436091496320 learning.py:507] global step 107470: loss = 0.3755 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 107480: loss = 0.3783 (0.779 sec/step)\n",
            "I0321 21:12:32.417989 140436091496320 learning.py:507] global step 107480: loss = 0.3783 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 107490: loss = 0.3716 (0.777 sec/step)\n",
            "I0321 21:12:40.377706 140436091496320 learning.py:507] global step 107490: loss = 0.3716 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 107500: loss = 0.3779 (0.807 sec/step)\n",
            "I0321 21:12:48.500144 140436091496320 learning.py:507] global step 107500: loss = 0.3779 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 107510: loss = 0.4064 (0.776 sec/step)\n",
            "I0321 21:12:56.337293 140436091496320 learning.py:507] global step 107510: loss = 0.4064 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 107520: loss = 0.3579 (0.783 sec/step)\n",
            "I0321 21:13:04.228673 140436091496320 learning.py:507] global step 107520: loss = 0.3579 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 107530: loss = 0.3490 (0.793 sec/step)\n",
            "I0321 21:13:12.116648 140436091496320 learning.py:507] global step 107530: loss = 0.3490 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 107540: loss = 0.3670 (0.779 sec/step)\n",
            "I0321 21:13:20.223878 140436091496320 learning.py:507] global step 107540: loss = 0.3670 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 107550: loss = 0.3835 (0.793 sec/step)\n",
            "I0321 21:13:28.497050 140436091496320 learning.py:507] global step 107550: loss = 0.3835 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 107560: loss = 0.3960 (0.778 sec/step)\n",
            "I0321 21:13:36.416310 140436091496320 learning.py:507] global step 107560: loss = 0.3960 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107570: loss = 0.3700 (0.782 sec/step)\n",
            "I0321 21:13:44.472460 140436091496320 learning.py:507] global step 107570: loss = 0.3700 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 107580: loss = 0.3951 (0.780 sec/step)\n",
            "I0321 21:13:52.440911 140436091496320 learning.py:507] global step 107580: loss = 0.3951 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107590: loss = 0.3972 (0.791 sec/step)\n",
            "I0321 21:14:00.489969 140436091496320 learning.py:507] global step 107590: loss = 0.3972 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 107600: loss = 0.3803 (0.776 sec/step)\n",
            "I0321 21:14:08.374290 140436091496320 learning.py:507] global step 107600: loss = 0.3803 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 107610: loss = 0.3746 (0.791 sec/step)\n",
            "I0321 21:14:16.305648 140436091496320 learning.py:507] global step 107610: loss = 0.3746 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 107620: loss = 0.4529 (0.780 sec/step)\n",
            "I0321 21:14:24.194763 140436091496320 learning.py:507] global step 107620: loss = 0.4529 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107630: loss = 0.3827 (0.787 sec/step)\n",
            "I0321 21:14:32.065878 140436091496320 learning.py:507] global step 107630: loss = 0.3827 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 107640: loss = 0.4485 (0.779 sec/step)\n",
            "I0321 21:14:39.970808 140436091496320 learning.py:507] global step 107640: loss = 0.4485 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 107650: loss = 0.3807 (0.803 sec/step)\n",
            "I0321 21:14:47.910144 140436091496320 learning.py:507] global step 107650: loss = 0.3807 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 107660: loss = 0.3597 (0.783 sec/step)\n",
            "I0321 21:14:55.780029 140436091496320 learning.py:507] global step 107660: loss = 0.3597 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 107670: loss = 0.4461 (0.777 sec/step)\n",
            "I0321 21:15:03.608320 140436091496320 learning.py:507] global step 107670: loss = 0.4461 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 107680: loss = 0.3950 (0.791 sec/step)\n",
            "I0321 21:15:11.734498 140436091496320 learning.py:507] global step 107680: loss = 0.3950 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 107690: loss = 0.3806 (0.778 sec/step)\n",
            "I0321 21:15:19.571687 140436091496320 learning.py:507] global step 107690: loss = 0.3806 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107700: loss = 0.3462 (0.780 sec/step)\n",
            "I0321 21:15:27.534887 140436091496320 learning.py:507] global step 107700: loss = 0.3462 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107710: loss = 0.4049 (0.786 sec/step)\n",
            "I0321 21:15:35.562225 140436091496320 learning.py:507] global step 107710: loss = 0.4049 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 107720: loss = 0.3786 (0.782 sec/step)\n",
            "I0321 21:15:43.419026 140436091496320 learning.py:507] global step 107720: loss = 0.3786 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 107730: loss = 0.4697 (0.778 sec/step)\n",
            "I0321 21:15:51.412887 140436091496320 learning.py:507] global step 107730: loss = 0.4697 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107740: loss = 0.3712 (0.841 sec/step)\n",
            "I0321 21:15:59.417759 140436091496320 learning.py:507] global step 107740: loss = 0.3712 (0.841 sec/step)\n",
            "INFO:tensorflow:global step 107750: loss = 0.3799 (0.778 sec/step)\n",
            "I0321 21:16:07.561658 140436091496320 learning.py:507] global step 107750: loss = 0.3799 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 107760: loss = 0.3792 (0.791 sec/step)\n",
            "I0321 21:16:15.451388 140436091496320 learning.py:507] global step 107760: loss = 0.3792 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 107770: loss = 0.3801 (0.808 sec/step)\n",
            "I0321 21:16:23.704938 140436091496320 learning.py:507] global step 107770: loss = 0.3801 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 107780: loss = 0.3760 (0.783 sec/step)\n",
            "I0321 21:16:31.854479 140436091496320 learning.py:507] global step 107780: loss = 0.3760 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 107790: loss = 0.3481 (0.780 sec/step)\n",
            "I0321 21:16:39.764445 140436091496320 learning.py:507] global step 107790: loss = 0.3481 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107800: loss = 0.3583 (0.858 sec/step)\n",
            "I0321 21:16:47.663941 140436091496320 learning.py:507] global step 107800: loss = 0.3583 (0.858 sec/step)\n",
            "INFO:tensorflow:global step 107810: loss = 0.3661 (0.780 sec/step)\n",
            "I0321 21:16:55.570367 140436091496320 learning.py:507] global step 107810: loss = 0.3661 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107820: loss = 0.3980 (0.792 sec/step)\n",
            "I0321 21:17:03.460448 140436091496320 learning.py:507] global step 107820: loss = 0.3980 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 107830: loss = 0.3952 (0.950 sec/step)\n",
            "I0321 21:17:11.501270 140436091496320 learning.py:507] global step 107830: loss = 0.3952 (0.950 sec/step)\n",
            "INFO:tensorflow:global step 107840: loss = 0.3823 (0.792 sec/step)\n",
            "I0321 21:17:19.395125 140436091496320 learning.py:507] global step 107840: loss = 0.3823 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 107850: loss = 0.3631 (0.790 sec/step)\n",
            "I0321 21:17:27.460825 140436091496320 learning.py:507] global step 107850: loss = 0.3631 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 107860: loss = 0.3699 (0.777 sec/step)\n",
            "I0321 21:17:35.347404 140436091496320 learning.py:507] global step 107860: loss = 0.3699 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 107870: loss = 0.3805 (0.786 sec/step)\n",
            "I0321 21:17:43.218162 140436091496320 learning.py:507] global step 107870: loss = 0.3805 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 107880: loss = 0.3663 (0.775 sec/step)\n",
            "I0321 21:17:51.107753 140436091496320 learning.py:507] global step 107880: loss = 0.3663 (0.775 sec/step)\n",
            "INFO:tensorflow:global step 107890: loss = 0.3914 (0.790 sec/step)\n",
            "I0321 21:17:59.032288 140436091496320 learning.py:507] global step 107890: loss = 0.3914 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 107900: loss = 0.3518 (0.781 sec/step)\n",
            "I0321 21:18:06.955827 140436091496320 learning.py:507] global step 107900: loss = 0.3518 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 107910: loss = 0.3819 (0.782 sec/step)\n",
            "I0321 21:18:15.179621 140436091496320 learning.py:507] global step 107910: loss = 0.3819 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 107920: loss = 0.3907 (0.960 sec/step)\n",
            "I0321 21:18:23.357145 140436091496320 learning.py:507] global step 107920: loss = 0.3907 (0.960 sec/step)\n",
            "INFO:tensorflow:global step 107930: loss = 0.3915 (0.786 sec/step)\n",
            "I0321 21:18:31.266894 140436091496320 learning.py:507] global step 107930: loss = 0.3915 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 107940: loss = 0.3537 (0.780 sec/step)\n",
            "I0321 21:18:39.168536 140436091496320 learning.py:507] global step 107940: loss = 0.3537 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107950: loss = 0.3521 (0.794 sec/step)\n",
            "I0321 21:18:47.064612 140436091496320 learning.py:507] global step 107950: loss = 0.3521 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 107960: loss = 0.3608 (0.789 sec/step)\n",
            "I0321 21:18:54.934772 140436091496320 learning.py:507] global step 107960: loss = 0.3608 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 107970: loss = 0.3636 (0.780 sec/step)\n",
            "I0321 21:19:02.791619 140436091496320 learning.py:507] global step 107970: loss = 0.3636 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 107980: loss = 0.3759 (0.801 sec/step)\n",
            "I0321 21:19:10.684287 140436091496320 learning.py:507] global step 107980: loss = 0.3759 (0.801 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 21:19:18.301750 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 107990.\n",
            "I0321 21:19:20.595065 140432184936192 supervisor.py:1050] Recording summary at step 107990.\n",
            "INFO:tensorflow:global step 107990: loss = 0.3884 (2.600 sec/step)\n",
            "I0321 21:19:20.595487 140436091496320 learning.py:507] global step 107990: loss = 0.3884 (2.600 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.25299\n",
            "I0321 21:19:20.810454 140432193328896 supervisor.py:1099] global_step/sec: 1.25299\n",
            "INFO:tensorflow:global step 108000: loss = 0.3522 (0.804 sec/step)\n",
            "I0321 21:19:28.882084 140436091496320 learning.py:507] global step 108000: loss = 0.3522 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 108010: loss = 0.3717 (0.783 sec/step)\n",
            "I0321 21:19:36.986670 140436091496320 learning.py:507] global step 108010: loss = 0.3717 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 108020: loss = 0.3658 (0.787 sec/step)\n",
            "I0321 21:19:45.115526 140436091496320 learning.py:507] global step 108020: loss = 0.3658 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 108030: loss = 0.3563 (0.791 sec/step)\n",
            "I0321 21:19:53.226925 140436091496320 learning.py:507] global step 108030: loss = 0.3563 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 108040: loss = 0.3675 (0.782 sec/step)\n",
            "I0321 21:20:01.344334 140436091496320 learning.py:507] global step 108040: loss = 0.3675 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108050: loss = 0.3929 (0.789 sec/step)\n",
            "I0321 21:20:09.394291 140436091496320 learning.py:507] global step 108050: loss = 0.3929 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 108060: loss = 0.3679 (0.795 sec/step)\n",
            "I0321 21:20:17.283994 140436091496320 learning.py:507] global step 108060: loss = 0.3679 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 108070: loss = 0.3694 (0.785 sec/step)\n",
            "I0321 21:20:25.327795 140436091496320 learning.py:507] global step 108070: loss = 0.3694 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 108080: loss = 0.3736 (0.777 sec/step)\n",
            "I0321 21:20:33.175062 140436091496320 learning.py:507] global step 108080: loss = 0.3736 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108090: loss = 0.3652 (0.790 sec/step)\n",
            "I0321 21:20:41.071546 140436091496320 learning.py:507] global step 108090: loss = 0.3652 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 108100: loss = 0.3754 (0.792 sec/step)\n",
            "I0321 21:20:49.020723 140436091496320 learning.py:507] global step 108100: loss = 0.3754 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 108110: loss = 0.3740 (0.785 sec/step)\n",
            "I0321 21:20:57.073714 140436091496320 learning.py:507] global step 108110: loss = 0.3740 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 108120: loss = 0.3598 (0.785 sec/step)\n",
            "I0321 21:21:04.946317 140436091496320 learning.py:507] global step 108120: loss = 0.3598 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 108130: loss = 0.3620 (0.780 sec/step)\n",
            "I0321 21:21:12.814888 140436091496320 learning.py:507] global step 108130: loss = 0.3620 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108140: loss = 0.3759 (0.793 sec/step)\n",
            "I0321 21:21:20.713140 140436091496320 learning.py:507] global step 108140: loss = 0.3759 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 108150: loss = 0.3936 (0.926 sec/step)\n",
            "I0321 21:21:28.722621 140436091496320 learning.py:507] global step 108150: loss = 0.3936 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 108160: loss = 0.3617 (0.776 sec/step)\n",
            "I0321 21:21:36.796719 140436091496320 learning.py:507] global step 108160: loss = 0.3617 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 108170: loss = 0.3623 (0.778 sec/step)\n",
            "I0321 21:21:44.681395 140436091496320 learning.py:507] global step 108170: loss = 0.3623 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 108180: loss = 0.3770 (0.780 sec/step)\n",
            "I0321 21:21:52.647751 140436091496320 learning.py:507] global step 108180: loss = 0.3770 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108190: loss = 0.3837 (0.788 sec/step)\n",
            "I0321 21:22:00.761380 140436091496320 learning.py:507] global step 108190: loss = 0.3837 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 108200: loss = 0.3687 (0.782 sec/step)\n",
            "I0321 21:22:08.707287 140436091496320 learning.py:507] global step 108200: loss = 0.3687 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108210: loss = 0.3775 (0.793 sec/step)\n",
            "I0321 21:22:16.754978 140436091496320 learning.py:507] global step 108210: loss = 0.3775 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 108220: loss = 0.3810 (0.786 sec/step)\n",
            "I0321 21:22:24.638354 140436091496320 learning.py:507] global step 108220: loss = 0.3810 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 108230: loss = 0.3831 (0.777 sec/step)\n",
            "I0321 21:22:32.508383 140436091496320 learning.py:507] global step 108230: loss = 0.3831 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108240: loss = 0.4035 (0.782 sec/step)\n",
            "I0321 21:22:40.350649 140436091496320 learning.py:507] global step 108240: loss = 0.4035 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108250: loss = 0.4495 (0.779 sec/step)\n",
            "I0321 21:22:48.332200 140436091496320 learning.py:507] global step 108250: loss = 0.4495 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 108260: loss = 0.3558 (0.797 sec/step)\n",
            "I0321 21:22:56.459751 140436091496320 learning.py:507] global step 108260: loss = 0.3558 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 108270: loss = 0.3715 (0.777 sec/step)\n",
            "I0321 21:23:04.370443 140436091496320 learning.py:507] global step 108270: loss = 0.3715 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108280: loss = 0.3674 (0.779 sec/step)\n",
            "I0321 21:23:12.211974 140436091496320 learning.py:507] global step 108280: loss = 0.3674 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 108290: loss = 0.3658 (0.781 sec/step)\n",
            "I0321 21:23:20.257154 140436091496320 learning.py:507] global step 108290: loss = 0.3658 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 108300: loss = 0.3839 (0.781 sec/step)\n",
            "I0321 21:23:28.152878 140436091496320 learning.py:507] global step 108300: loss = 0.3839 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 108310: loss = 0.3803 (0.777 sec/step)\n",
            "I0321 21:23:36.091651 140436091496320 learning.py:507] global step 108310: loss = 0.3803 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108320: loss = 0.3808 (0.805 sec/step)\n",
            "I0321 21:23:44.086019 140436091496320 learning.py:507] global step 108320: loss = 0.3808 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 108330: loss = 0.3752 (0.791 sec/step)\n",
            "I0321 21:23:52.160863 140436091496320 learning.py:507] global step 108330: loss = 0.3752 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 108340: loss = 0.3833 (0.791 sec/step)\n",
            "I0321 21:24:00.137307 140436091496320 learning.py:507] global step 108340: loss = 0.3833 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 108350: loss = 0.3767 (0.784 sec/step)\n",
            "I0321 21:24:08.010723 140436091496320 learning.py:507] global step 108350: loss = 0.3767 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 108360: loss = 0.3771 (0.794 sec/step)\n",
            "I0321 21:24:16.034101 140436091496320 learning.py:507] global step 108360: loss = 0.3771 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 108370: loss = 0.3675 (0.783 sec/step)\n",
            "I0321 21:24:23.922922 140436091496320 learning.py:507] global step 108370: loss = 0.3675 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 108380: loss = 0.3568 (0.774 sec/step)\n",
            "I0321 21:24:31.930267 140436091496320 learning.py:507] global step 108380: loss = 0.3568 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 108390: loss = 0.3793 (0.833 sec/step)\n",
            "I0321 21:24:39.856213 140436091496320 learning.py:507] global step 108390: loss = 0.3793 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 108400: loss = 0.3990 (0.783 sec/step)\n",
            "I0321 21:24:47.831985 140436091496320 learning.py:507] global step 108400: loss = 0.3990 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 108410: loss = 0.3631 (0.790 sec/step)\n",
            "I0321 21:24:55.804879 140436091496320 learning.py:507] global step 108410: loss = 0.3631 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 108420: loss = 0.4794 (0.794 sec/step)\n",
            "I0321 21:25:03.841629 140436091496320 learning.py:507] global step 108420: loss = 0.4794 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 108430: loss = 0.3587 (0.777 sec/step)\n",
            "I0321 21:25:11.937181 140436091496320 learning.py:507] global step 108430: loss = 0.3587 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108440: loss = 0.4173 (0.780 sec/step)\n",
            "I0321 21:25:19.812275 140436091496320 learning.py:507] global step 108440: loss = 0.4173 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108450: loss = 0.3753 (0.908 sec/step)\n",
            "I0321 21:25:27.899025 140436091496320 learning.py:507] global step 108450: loss = 0.3753 (0.908 sec/step)\n",
            "INFO:tensorflow:global step 108460: loss = 0.3999 (0.777 sec/step)\n",
            "I0321 21:25:35.852927 140436091496320 learning.py:507] global step 108460: loss = 0.3999 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108470: loss = 0.3824 (0.780 sec/step)\n",
            "I0321 21:25:43.699922 140436091496320 learning.py:507] global step 108470: loss = 0.3824 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108480: loss = 0.3979 (0.792 sec/step)\n",
            "I0321 21:25:51.816848 140436091496320 learning.py:507] global step 108480: loss = 0.3979 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 108490: loss = 0.3958 (0.777 sec/step)\n",
            "I0321 21:25:59.887356 140436091496320 learning.py:507] global step 108490: loss = 0.3958 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108500: loss = 0.3725 (0.789 sec/step)\n",
            "I0321 21:26:07.927893 140436091496320 learning.py:507] global step 108500: loss = 0.3725 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 108510: loss = 0.3985 (0.797 sec/step)\n",
            "I0321 21:26:16.011281 140436091496320 learning.py:507] global step 108510: loss = 0.3985 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 108520: loss = 0.3359 (0.778 sec/step)\n",
            "I0321 21:26:23.923418 140436091496320 learning.py:507] global step 108520: loss = 0.3359 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 108530: loss = 0.4050 (0.790 sec/step)\n",
            "I0321 21:26:31.908978 140436091496320 learning.py:507] global step 108530: loss = 0.4050 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 108540: loss = 0.4264 (0.779 sec/step)\n",
            "I0321 21:26:39.771508 140436091496320 learning.py:507] global step 108540: loss = 0.4264 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 108550: loss = 0.3948 (0.787 sec/step)\n",
            "I0321 21:26:47.649225 140436091496320 learning.py:507] global step 108550: loss = 0.3948 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 108560: loss = 0.3754 (0.777 sec/step)\n",
            "I0321 21:26:55.618480 140436091496320 learning.py:507] global step 108560: loss = 0.3754 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 108570: loss = 0.3493 (0.851 sec/step)\n",
            "I0321 21:27:03.825232 140436091496320 learning.py:507] global step 108570: loss = 0.3493 (0.851 sec/step)\n",
            "INFO:tensorflow:global step 108580: loss = 0.3600 (0.788 sec/step)\n",
            "I0321 21:27:11.889556 140436091496320 learning.py:507] global step 108580: loss = 0.3600 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 108590: loss = 0.3751 (0.781 sec/step)\n",
            "I0321 21:27:19.931312 140436091496320 learning.py:507] global step 108590: loss = 0.3751 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 108600: loss = 0.3621 (0.792 sec/step)\n",
            "I0321 21:27:27.851280 140436091496320 learning.py:507] global step 108600: loss = 0.3621 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 108610: loss = 0.3888 (0.782 sec/step)\n",
            "I0321 21:27:36.050071 140436091496320 learning.py:507] global step 108610: loss = 0.3888 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108620: loss = 0.3771 (0.780 sec/step)\n",
            "I0321 21:27:43.983351 140436091496320 learning.py:507] global step 108620: loss = 0.3771 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108630: loss = 0.3679 (0.788 sec/step)\n",
            "I0321 21:27:52.065520 140436091496320 learning.py:507] global step 108630: loss = 0.3679 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 108640: loss = 0.4017 (0.789 sec/step)\n",
            "I0321 21:28:00.288560 140436091496320 learning.py:507] global step 108640: loss = 0.4017 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 108650: loss = 0.4040 (0.780 sec/step)\n",
            "I0321 21:28:08.319058 140436091496320 learning.py:507] global step 108650: loss = 0.4040 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108660: loss = 0.3945 (0.917 sec/step)\n",
            "I0321 21:28:16.517297 140436091496320 learning.py:507] global step 108660: loss = 0.3945 (0.917 sec/step)\n",
            "INFO:tensorflow:global step 108670: loss = 0.3549 (0.779 sec/step)\n",
            "I0321 21:28:24.690962 140436091496320 learning.py:507] global step 108670: loss = 0.3549 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 108680: loss = 0.4148 (0.781 sec/step)\n",
            "I0321 21:28:32.569503 140436091496320 learning.py:507] global step 108680: loss = 0.4148 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 108690: loss = 0.3802 (0.793 sec/step)\n",
            "I0321 21:28:40.461628 140436091496320 learning.py:507] global step 108690: loss = 0.3802 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 108700: loss = 0.3544 (0.789 sec/step)\n",
            "I0321 21:28:48.505471 140436091496320 learning.py:507] global step 108700: loss = 0.3544 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 108710: loss = 0.4515 (0.796 sec/step)\n",
            "I0321 21:28:56.378270 140436091496320 learning.py:507] global step 108710: loss = 0.4515 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 108720: loss = 0.3734 (0.781 sec/step)\n",
            "I0321 21:29:04.267761 140436091496320 learning.py:507] global step 108720: loss = 0.3734 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 108730: loss = 0.3771 (0.779 sec/step)\n",
            "I0321 21:29:12.135427 140436091496320 learning.py:507] global step 108730: loss = 0.3771 (0.779 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 108738.\n",
            "I0321 21:29:20.142338 140432184936192 supervisor.py:1050] Recording summary at step 108738.\n",
            "INFO:tensorflow:global_step/sec: 1.24701\n",
            "I0321 21:29:20.647353 140432193328896 supervisor.py:1099] global_step/sec: 1.24701\n",
            "INFO:tensorflow:global step 108740: loss = 0.3683 (0.795 sec/step)\n",
            "I0321 21:29:21.657329 140436091496320 learning.py:507] global step 108740: loss = 0.3683 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 108750: loss = 0.3750 (0.785 sec/step)\n",
            "I0321 21:29:29.513732 140436091496320 learning.py:507] global step 108750: loss = 0.3750 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 108760: loss = 0.3629 (0.782 sec/step)\n",
            "I0321 21:29:37.631226 140436091496320 learning.py:507] global step 108760: loss = 0.3629 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108770: loss = 0.3758 (0.802 sec/step)\n",
            "I0321 21:29:45.516418 140436091496320 learning.py:507] global step 108770: loss = 0.3758 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 108780: loss = 0.3766 (0.785 sec/step)\n",
            "I0321 21:29:53.491675 140436091496320 learning.py:507] global step 108780: loss = 0.3766 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 108790: loss = 0.3685 (0.787 sec/step)\n",
            "I0321 21:30:01.397995 140436091496320 learning.py:507] global step 108790: loss = 0.3685 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 108800: loss = 0.3586 (0.779 sec/step)\n",
            "I0321 21:30:09.292281 140436091496320 learning.py:507] global step 108800: loss = 0.3586 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 108810: loss = 0.3829 (0.782 sec/step)\n",
            "I0321 21:30:17.194065 140436091496320 learning.py:507] global step 108810: loss = 0.3829 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108820: loss = 0.3703 (0.781 sec/step)\n",
            "I0321 21:30:25.265818 140436091496320 learning.py:507] global step 108820: loss = 0.3703 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 108830: loss = 0.3610 (0.780 sec/step)\n",
            "I0321 21:30:33.160320 140436091496320 learning.py:507] global step 108830: loss = 0.3610 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108840: loss = 0.3826 (0.779 sec/step)\n",
            "I0321 21:30:41.042791 140436091496320 learning.py:507] global step 108840: loss = 0.3826 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 108850: loss = 0.3789 (0.791 sec/step)\n",
            "I0321 21:30:48.915222 140436091496320 learning.py:507] global step 108850: loss = 0.3789 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 108860: loss = 0.3642 (0.782 sec/step)\n",
            "I0321 21:30:56.962664 140436091496320 learning.py:507] global step 108860: loss = 0.3642 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108870: loss = 0.3558 (0.794 sec/step)\n",
            "I0321 21:31:05.079772 140436091496320 learning.py:507] global step 108870: loss = 0.3558 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 108880: loss = 0.3343 (0.789 sec/step)\n",
            "I0321 21:31:13.303707 140436091496320 learning.py:507] global step 108880: loss = 0.3343 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 108890: loss = 0.3582 (0.781 sec/step)\n",
            "I0321 21:31:21.188782 140436091496320 learning.py:507] global step 108890: loss = 0.3582 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 108900: loss = 0.4366 (0.793 sec/step)\n",
            "I0321 21:31:29.125975 140436091496320 learning.py:507] global step 108900: loss = 0.4366 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 108910: loss = 0.3666 (0.787 sec/step)\n",
            "I0321 21:31:37.290966 140436091496320 learning.py:507] global step 108910: loss = 0.3666 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 108920: loss = 0.3799 (0.783 sec/step)\n",
            "I0321 21:31:45.177366 140436091496320 learning.py:507] global step 108920: loss = 0.3799 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 108930: loss = 0.3763 (0.778 sec/step)\n",
            "I0321 21:31:53.247248 140436091496320 learning.py:507] global step 108930: loss = 0.3763 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 108940: loss = 0.3488 (0.782 sec/step)\n",
            "I0321 21:32:01.405313 140436091496320 learning.py:507] global step 108940: loss = 0.3488 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 108950: loss = 0.3508 (0.800 sec/step)\n",
            "I0321 21:32:09.467113 140436091496320 learning.py:507] global step 108950: loss = 0.3508 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 108960: loss = 0.3628 (0.779 sec/step)\n",
            "I0321 21:32:17.411896 140436091496320 learning.py:507] global step 108960: loss = 0.3628 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 108970: loss = 0.3652 (0.793 sec/step)\n",
            "I0321 21:32:25.615003 140436091496320 learning.py:507] global step 108970: loss = 0.3652 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 108980: loss = 0.3724 (0.780 sec/step)\n",
            "I0321 21:32:33.706717 140436091496320 learning.py:507] global step 108980: loss = 0.3724 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 108990: loss = 0.3925 (0.784 sec/step)\n",
            "I0321 21:32:41.701725 140436091496320 learning.py:507] global step 108990: loss = 0.3925 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 109000: loss = 0.3733 (0.783 sec/step)\n",
            "I0321 21:32:49.680230 140436091496320 learning.py:507] global step 109000: loss = 0.3733 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 109010: loss = 0.3915 (0.864 sec/step)\n",
            "I0321 21:32:57.622864 140436091496320 learning.py:507] global step 109010: loss = 0.3915 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 109020: loss = 0.3613 (0.791 sec/step)\n",
            "I0321 21:33:05.705339 140436091496320 learning.py:507] global step 109020: loss = 0.3613 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 109030: loss = 0.3664 (0.791 sec/step)\n",
            "I0321 21:33:13.588810 140436091496320 learning.py:507] global step 109030: loss = 0.3664 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 109040: loss = 0.3689 (0.977 sec/step)\n",
            "I0321 21:33:21.639365 140436091496320 learning.py:507] global step 109040: loss = 0.3689 (0.977 sec/step)\n",
            "INFO:tensorflow:global step 109050: loss = 0.3587 (0.784 sec/step)\n",
            "I0321 21:33:29.573007 140436091496320 learning.py:507] global step 109050: loss = 0.3587 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 109060: loss = 0.3622 (0.777 sec/step)\n",
            "I0321 21:33:37.764029 140436091496320 learning.py:507] global step 109060: loss = 0.3622 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 109070: loss = 0.3621 (0.786 sec/step)\n",
            "I0321 21:33:45.695724 140436091496320 learning.py:507] global step 109070: loss = 0.3621 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 109080: loss = 0.3860 (0.779 sec/step)\n",
            "I0321 21:33:53.751972 140436091496320 learning.py:507] global step 109080: loss = 0.3860 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 109090: loss = 0.3714 (0.807 sec/step)\n",
            "I0321 21:34:01.754483 140436091496320 learning.py:507] global step 109090: loss = 0.3714 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 109100: loss = 0.3857 (0.786 sec/step)\n",
            "I0321 21:34:09.716351 140436091496320 learning.py:507] global step 109100: loss = 0.3857 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 109110: loss = 0.3532 (0.781 sec/step)\n",
            "I0321 21:34:17.766676 140436091496320 learning.py:507] global step 109110: loss = 0.3532 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 109120: loss = 0.3614 (0.784 sec/step)\n",
            "I0321 21:34:25.848480 140436091496320 learning.py:507] global step 109120: loss = 0.3614 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 109130: loss = 0.3909 (0.822 sec/step)\n",
            "I0321 21:34:33.766393 140436091496320 learning.py:507] global step 109130: loss = 0.3909 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 109140: loss = 0.3650 (0.781 sec/step)\n",
            "I0321 21:34:41.759516 140436091496320 learning.py:507] global step 109140: loss = 0.3650 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 109150: loss = 0.3613 (0.789 sec/step)\n",
            "I0321 21:34:49.832608 140436091496320 learning.py:507] global step 109150: loss = 0.3613 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 109160: loss = 0.3654 (0.799 sec/step)\n",
            "I0321 21:34:57.715824 140436091496320 learning.py:507] global step 109160: loss = 0.3654 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 109170: loss = 0.4093 (0.793 sec/step)\n",
            "I0321 21:35:05.651521 140436091496320 learning.py:507] global step 109170: loss = 0.4093 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 109180: loss = 0.3589 (0.787 sec/step)\n",
            "I0321 21:35:13.627806 140436091496320 learning.py:507] global step 109180: loss = 0.3589 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 109190: loss = 0.3719 (0.779 sec/step)\n",
            "I0321 21:35:21.552161 140436091496320 learning.py:507] global step 109190: loss = 0.3719 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 109200: loss = 0.3857 (0.801 sec/step)\n",
            "I0321 21:35:29.429081 140436091496320 learning.py:507] global step 109200: loss = 0.3857 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 109210: loss = 0.3786 (0.779 sec/step)\n",
            "I0321 21:35:37.537940 140436091496320 learning.py:507] global step 109210: loss = 0.3786 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 109220: loss = 0.3518 (0.783 sec/step)\n",
            "I0321 21:35:45.537248 140436091496320 learning.py:507] global step 109220: loss = 0.3518 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 109230: loss = 0.3597 (0.809 sec/step)\n",
            "I0321 21:35:53.525809 140436091496320 learning.py:507] global step 109230: loss = 0.3597 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 109240: loss = 0.3503 (0.790 sec/step)\n",
            "I0321 21:36:01.434547 140436091496320 learning.py:507] global step 109240: loss = 0.3503 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 109250: loss = 0.3905 (0.804 sec/step)\n",
            "I0321 21:36:09.342525 140436091496320 learning.py:507] global step 109250: loss = 0.3905 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 109260: loss = 0.3784 (0.792 sec/step)\n",
            "I0321 21:36:17.477520 140436091496320 learning.py:507] global step 109260: loss = 0.3784 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 109270: loss = 0.3821 (0.784 sec/step)\n",
            "I0321 21:36:25.388258 140436091496320 learning.py:507] global step 109270: loss = 0.3821 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 109280: loss = 0.3933 (0.800 sec/step)\n",
            "I0321 21:36:33.304983 140436091496320 learning.py:507] global step 109280: loss = 0.3933 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 109290: loss = 0.3573 (0.780 sec/step)\n",
            "I0321 21:36:41.307861 140436091496320 learning.py:507] global step 109290: loss = 0.3573 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 109300: loss = 0.3600 (0.780 sec/step)\n",
            "I0321 21:36:49.204276 140436091496320 learning.py:507] global step 109300: loss = 0.3600 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 109310: loss = 0.3682 (0.798 sec/step)\n",
            "I0321 21:36:57.104960 140436091496320 learning.py:507] global step 109310: loss = 0.3682 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 109320: loss = 0.3688 (0.790 sec/step)\n",
            "I0321 21:37:05.205196 140436091496320 learning.py:507] global step 109320: loss = 0.3688 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 109330: loss = 0.3582 (0.781 sec/step)\n",
            "I0321 21:37:13.299611 140436091496320 learning.py:507] global step 109330: loss = 0.3582 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 109340: loss = 0.3635 (0.789 sec/step)\n",
            "I0321 21:37:21.422831 140436091496320 learning.py:507] global step 109340: loss = 0.3635 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 109350: loss = 0.3520 (0.784 sec/step)\n",
            "I0321 21:37:29.331447 140436091496320 learning.py:507] global step 109350: loss = 0.3520 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 109360: loss = 0.3903 (0.790 sec/step)\n",
            "I0321 21:37:37.504219 140436091496320 learning.py:507] global step 109360: loss = 0.3903 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 109370: loss = 0.4306 (0.816 sec/step)\n",
            "I0321 21:37:45.868242 140436091496320 learning.py:507] global step 109370: loss = 0.4306 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 109380: loss = 0.3599 (0.779 sec/step)\n",
            "I0321 21:37:53.749290 140436091496320 learning.py:507] global step 109380: loss = 0.3599 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 109390: loss = 0.3557 (0.785 sec/step)\n",
            "I0321 21:38:01.683349 140436091496320 learning.py:507] global step 109390: loss = 0.3557 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 109400: loss = 0.3559 (0.812 sec/step)\n",
            "I0321 21:38:09.641999 140436091496320 learning.py:507] global step 109400: loss = 0.3559 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 109410: loss = 0.3573 (0.782 sec/step)\n",
            "I0321 21:38:17.712197 140436091496320 learning.py:507] global step 109410: loss = 0.3573 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 109420: loss = 0.3619 (0.779 sec/step)\n",
            "I0321 21:38:25.770025 140436091496320 learning.py:507] global step 109420: loss = 0.3619 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 109430: loss = 0.3875 (0.790 sec/step)\n",
            "I0321 21:38:33.695372 140436091496320 learning.py:507] global step 109430: loss = 0.3875 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 109440: loss = 0.3627 (0.795 sec/step)\n",
            "I0321 21:38:41.610568 140436091496320 learning.py:507] global step 109440: loss = 0.3627 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 109450: loss = 0.3987 (0.804 sec/step)\n",
            "I0321 21:38:49.531605 140436091496320 learning.py:507] global step 109450: loss = 0.3987 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 109460: loss = 0.3825 (0.783 sec/step)\n",
            "I0321 21:38:57.399643 140436091496320 learning.py:507] global step 109460: loss = 0.3825 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 109470: loss = 0.3623 (0.812 sec/step)\n",
            "I0321 21:39:05.531739 140436091496320 learning.py:507] global step 109470: loss = 0.3623 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 109480: loss = 0.4256 (0.797 sec/step)\n",
            "I0321 21:39:13.488012 140436091496320 learning.py:507] global step 109480: loss = 0.4256 (0.797 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 21:39:18.301773 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 109487.\n",
            "I0321 21:39:20.949792 140432184936192 supervisor.py:1050] Recording summary at step 109487.\n",
            "INFO:tensorflow:global_step/sec: 1.24765\n",
            "I0321 21:39:20.977458 140432193328896 supervisor.py:1099] global_step/sec: 1.24765\n",
            "INFO:tensorflow:global step 109490: loss = 0.3582 (0.821 sec/step)\n",
            "I0321 21:39:23.479804 140436091496320 learning.py:507] global step 109490: loss = 0.3582 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 109500: loss = 0.3646 (0.798 sec/step)\n",
            "I0321 21:39:31.563386 140436091496320 learning.py:507] global step 109500: loss = 0.3646 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 109510: loss = 0.4534 (0.797 sec/step)\n",
            "I0321 21:39:39.455080 140436091496320 learning.py:507] global step 109510: loss = 0.4534 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 109520: loss = 0.3611 (0.779 sec/step)\n",
            "I0321 21:39:47.609730 140436091496320 learning.py:507] global step 109520: loss = 0.3611 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 109530: loss = 0.3959 (0.794 sec/step)\n",
            "I0321 21:39:55.709490 140436091496320 learning.py:507] global step 109530: loss = 0.3959 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 109540: loss = 0.3891 (0.803 sec/step)\n",
            "I0321 21:40:03.669450 140436091496320 learning.py:507] global step 109540: loss = 0.3891 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 109550: loss = 0.3809 (0.799 sec/step)\n",
            "I0321 21:40:11.613323 140436091496320 learning.py:507] global step 109550: loss = 0.3809 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 109560: loss = 0.3720 (0.782 sec/step)\n",
            "I0321 21:40:19.489672 140436091496320 learning.py:507] global step 109560: loss = 0.3720 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 109570: loss = 0.3629 (0.796 sec/step)\n",
            "I0321 21:40:27.442340 140436091496320 learning.py:507] global step 109570: loss = 0.3629 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 109580: loss = 0.3817 (0.790 sec/step)\n",
            "I0321 21:40:35.477126 140436091496320 learning.py:507] global step 109580: loss = 0.3817 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 109590: loss = 0.3702 (0.783 sec/step)\n",
            "I0321 21:40:43.764912 140436091496320 learning.py:507] global step 109590: loss = 0.3702 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 109600: loss = 0.3952 (0.783 sec/step)\n",
            "I0321 21:40:51.752498 140436091496320 learning.py:507] global step 109600: loss = 0.3952 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 109610: loss = 0.3755 (0.791 sec/step)\n",
            "I0321 21:40:59.672775 140436091496320 learning.py:507] global step 109610: loss = 0.3755 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 109620: loss = 0.3737 (0.792 sec/step)\n",
            "I0321 21:41:07.594733 140436091496320 learning.py:507] global step 109620: loss = 0.3737 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 109630: loss = 0.3877 (0.995 sec/step)\n",
            "I0321 21:41:15.828653 140436091496320 learning.py:507] global step 109630: loss = 0.3877 (0.995 sec/step)\n",
            "INFO:tensorflow:global step 109640: loss = 0.3611 (0.788 sec/step)\n",
            "I0321 21:41:23.952414 140436091496320 learning.py:507] global step 109640: loss = 0.3611 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 109650: loss = 0.3789 (0.803 sec/step)\n",
            "I0321 21:41:31.886590 140436091496320 learning.py:507] global step 109650: loss = 0.3789 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 109660: loss = 0.3911 (0.785 sec/step)\n",
            "I0321 21:41:39.973896 140436091496320 learning.py:507] global step 109660: loss = 0.3911 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 109670: loss = 0.3751 (0.801 sec/step)\n",
            "I0321 21:41:47.967037 140436091496320 learning.py:507] global step 109670: loss = 0.3751 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 109680: loss = 0.4131 (0.783 sec/step)\n",
            "I0321 21:41:56.170671 140436091496320 learning.py:507] global step 109680: loss = 0.4131 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 109690: loss = 0.3620 (0.787 sec/step)\n",
            "I0321 21:42:04.555702 140436091496320 learning.py:507] global step 109690: loss = 0.3620 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 109700: loss = 0.4214 (0.789 sec/step)\n",
            "I0321 21:42:12.468468 140436091496320 learning.py:507] global step 109700: loss = 0.4214 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 109710: loss = 0.3667 (0.787 sec/step)\n",
            "I0321 21:42:20.456840 140436091496320 learning.py:507] global step 109710: loss = 0.3667 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 109720: loss = 0.3530 (0.809 sec/step)\n",
            "I0321 21:42:28.377809 140436091496320 learning.py:507] global step 109720: loss = 0.3530 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 109730: loss = 0.3440 (0.785 sec/step)\n",
            "I0321 21:42:36.283503 140436091496320 learning.py:507] global step 109730: loss = 0.3440 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 109740: loss = 0.3655 (0.790 sec/step)\n",
            "I0321 21:42:44.251237 140436091496320 learning.py:507] global step 109740: loss = 0.3655 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 109750: loss = 0.3568 (0.792 sec/step)\n",
            "I0321 21:42:52.169136 140436091496320 learning.py:507] global step 109750: loss = 0.3568 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 109760: loss = 0.3559 (0.791 sec/step)\n",
            "I0321 21:43:00.157987 140436091496320 learning.py:507] global step 109760: loss = 0.3559 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 109770: loss = 0.4017 (0.779 sec/step)\n",
            "I0321 21:43:08.174890 140436091496320 learning.py:507] global step 109770: loss = 0.4017 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 109780: loss = 0.3838 (0.949 sec/step)\n",
            "I0321 21:43:16.290518 140436091496320 learning.py:507] global step 109780: loss = 0.3838 (0.949 sec/step)\n",
            "INFO:tensorflow:global step 109790: loss = 0.3723 (0.781 sec/step)\n",
            "I0321 21:43:24.171730 140436091496320 learning.py:507] global step 109790: loss = 0.3723 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 109800: loss = 0.3611 (0.780 sec/step)\n",
            "I0321 21:43:32.256447 140436091496320 learning.py:507] global step 109800: loss = 0.3611 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 109810: loss = 0.3588 (0.803 sec/step)\n",
            "I0321 21:43:40.212006 140436091496320 learning.py:507] global step 109810: loss = 0.3588 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 109820: loss = 0.4019 (0.781 sec/step)\n",
            "I0321 21:43:48.137228 140436091496320 learning.py:507] global step 109820: loss = 0.4019 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 109830: loss = 0.3642 (0.781 sec/step)\n",
            "I0321 21:43:56.056233 140436091496320 learning.py:507] global step 109830: loss = 0.3642 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 109840: loss = 0.4642 (0.789 sec/step)\n",
            "I0321 21:44:04.339132 140436091496320 learning.py:507] global step 109840: loss = 0.4642 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 109850: loss = 0.3741 (0.784 sec/step)\n",
            "I0321 21:44:12.280941 140436091496320 learning.py:507] global step 109850: loss = 0.3741 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 109860: loss = 0.3630 (0.786 sec/step)\n",
            "I0321 21:44:20.310897 140436091496320 learning.py:507] global step 109860: loss = 0.3630 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 109870: loss = 0.3998 (0.819 sec/step)\n",
            "I0321 21:44:28.355459 140436091496320 learning.py:507] global step 109870: loss = 0.3998 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 109880: loss = 0.3664 (0.806 sec/step)\n",
            "I0321 21:44:36.278623 140436091496320 learning.py:507] global step 109880: loss = 0.3664 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 109890: loss = 0.4139 (0.774 sec/step)\n",
            "I0321 21:44:44.246914 140436091496320 learning.py:507] global step 109890: loss = 0.4139 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 109900: loss = 0.3506 (0.788 sec/step)\n",
            "I0321 21:44:52.393098 140436091496320 learning.py:507] global step 109900: loss = 0.3506 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 109910: loss = 0.3714 (0.795 sec/step)\n",
            "I0321 21:45:00.589847 140436091496320 learning.py:507] global step 109910: loss = 0.3714 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 109920: loss = 0.3436 (0.787 sec/step)\n",
            "I0321 21:45:08.729968 140436091496320 learning.py:507] global step 109920: loss = 0.3436 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 109930: loss = 0.3551 (0.818 sec/step)\n",
            "I0321 21:45:16.841202 140436091496320 learning.py:507] global step 109930: loss = 0.3551 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 109940: loss = 0.3699 (0.786 sec/step)\n",
            "I0321 21:45:25.025352 140436091496320 learning.py:507] global step 109940: loss = 0.3699 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 109950: loss = 0.3611 (0.777 sec/step)\n",
            "I0321 21:45:33.086045 140436091496320 learning.py:507] global step 109950: loss = 0.3611 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 109960: loss = 0.4197 (0.789 sec/step)\n",
            "I0321 21:45:40.997140 140436091496320 learning.py:507] global step 109960: loss = 0.4197 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 109970: loss = 0.4002 (0.793 sec/step)\n",
            "I0321 21:45:48.899082 140436091496320 learning.py:507] global step 109970: loss = 0.4002 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 109980: loss = 0.3982 (0.816 sec/step)\n",
            "I0321 21:45:56.813360 140436091496320 learning.py:507] global step 109980: loss = 0.3982 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 109990: loss = 0.3777 (0.790 sec/step)\n",
            "I0321 21:46:04.786026 140436091496320 learning.py:507] global step 109990: loss = 0.3777 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 110000: loss = 0.3803 (0.787 sec/step)\n",
            "I0321 21:46:12.902534 140436091496320 learning.py:507] global step 110000: loss = 0.3803 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 110010: loss = 0.3515 (0.795 sec/step)\n",
            "I0321 21:46:20.835114 140436091496320 learning.py:507] global step 110010: loss = 0.3515 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 110020: loss = 0.3869 (0.808 sec/step)\n",
            "I0321 21:46:29.007755 140436091496320 learning.py:507] global step 110020: loss = 0.3869 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 110030: loss = 0.3655 (0.780 sec/step)\n",
            "I0321 21:46:37.166620 140436091496320 learning.py:507] global step 110030: loss = 0.3655 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 110040: loss = 0.3512 (0.797 sec/step)\n",
            "I0321 21:46:45.085065 140436091496320 learning.py:507] global step 110040: loss = 0.3512 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 110050: loss = 0.4027 (0.807 sec/step)\n",
            "I0321 21:46:53.347403 140436091496320 learning.py:507] global step 110050: loss = 0.4027 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 110060: loss = 0.3605 (0.784 sec/step)\n",
            "I0321 21:47:01.505647 140436091496320 learning.py:507] global step 110060: loss = 0.3605 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 110070: loss = 0.3653 (0.785 sec/step)\n",
            "I0321 21:47:09.372694 140436091496320 learning.py:507] global step 110070: loss = 0.3653 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110080: loss = 0.3785 (0.782 sec/step)\n",
            "I0321 21:47:17.286759 140436091496320 learning.py:507] global step 110080: loss = 0.3785 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110090: loss = 0.3540 (0.787 sec/step)\n",
            "I0321 21:47:25.422458 140436091496320 learning.py:507] global step 110090: loss = 0.3540 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 110100: loss = 0.3907 (0.782 sec/step)\n",
            "I0321 21:47:33.515096 140436091496320 learning.py:507] global step 110100: loss = 0.3907 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110110: loss = 0.3471 (0.789 sec/step)\n",
            "I0321 21:47:41.723468 140436091496320 learning.py:507] global step 110110: loss = 0.3471 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 110120: loss = 0.3689 (0.809 sec/step)\n",
            "I0321 21:47:49.968135 140436091496320 learning.py:507] global step 110120: loss = 0.3689 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 110130: loss = 0.4765 (0.796 sec/step)\n",
            "I0321 21:47:57.882933 140436091496320 learning.py:507] global step 110130: loss = 0.4765 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 110140: loss = 0.3723 (0.885 sec/step)\n",
            "I0321 21:48:05.857844 140436091496320 learning.py:507] global step 110140: loss = 0.3723 (0.885 sec/step)\n",
            "INFO:tensorflow:global step 110150: loss = 0.3766 (0.794 sec/step)\n",
            "I0321 21:48:14.008951 140436091496320 learning.py:507] global step 110150: loss = 0.3766 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 110160: loss = 0.4699 (0.783 sec/step)\n",
            "I0321 21:48:22.152290 140436091496320 learning.py:507] global step 110160: loss = 0.4699 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110170: loss = 0.3623 (0.802 sec/step)\n",
            "I0321 21:48:30.120682 140436091496320 learning.py:507] global step 110170: loss = 0.3623 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 110180: loss = 0.3459 (0.781 sec/step)\n",
            "I0321 21:48:38.010670 140436091496320 learning.py:507] global step 110180: loss = 0.3459 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 110190: loss = 0.3502 (0.799 sec/step)\n",
            "I0321 21:48:45.978909 140436091496320 learning.py:507] global step 110190: loss = 0.3502 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 110200: loss = 0.3646 (0.795 sec/step)\n",
            "I0321 21:48:53.895534 140436091496320 learning.py:507] global step 110200: loss = 0.3646 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 110210: loss = 0.3386 (0.791 sec/step)\n",
            "I0321 21:49:01.889508 140436091496320 learning.py:507] global step 110210: loss = 0.3386 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 110220: loss = 0.3547 (0.789 sec/step)\n",
            "I0321 21:49:09.833868 140436091496320 learning.py:507] global step 110220: loss = 0.3547 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 110230: loss = 0.3572 (0.874 sec/step)\n",
            "I0321 21:49:17.895398 140436091496320 learning.py:507] global step 110230: loss = 0.3572 (0.874 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 110231.\n",
            "I0321 21:49:20.419616 140432184936192 supervisor.py:1050] Recording summary at step 110231.\n",
            "INFO:tensorflow:global_step/sec: 1.24044\n",
            "I0321 21:49:20.763397 140432193328896 supervisor.py:1099] global_step/sec: 1.24044\n",
            "INFO:tensorflow:global step 110240: loss = 0.4508 (0.780 sec/step)\n",
            "I0321 21:49:27.321134 140436091496320 learning.py:507] global step 110240: loss = 0.4508 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 110250: loss = 0.3580 (0.789 sec/step)\n",
            "I0321 21:49:35.359632 140436091496320 learning.py:507] global step 110250: loss = 0.3580 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 110260: loss = 0.3743 (0.780 sec/step)\n",
            "I0321 21:49:43.281325 140436091496320 learning.py:507] global step 110260: loss = 0.3743 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 110270: loss = 0.4121 (0.783 sec/step)\n",
            "I0321 21:49:51.171227 140436091496320 learning.py:507] global step 110270: loss = 0.4121 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110280: loss = 0.4250 (0.790 sec/step)\n",
            "I0321 21:49:59.098912 140436091496320 learning.py:507] global step 110280: loss = 0.4250 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 110290: loss = 0.3802 (0.783 sec/step)\n",
            "I0321 21:50:06.962521 140436091496320 learning.py:507] global step 110290: loss = 0.3802 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110300: loss = 0.3664 (0.798 sec/step)\n",
            "I0321 21:50:14.926997 140436091496320 learning.py:507] global step 110300: loss = 0.3664 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 110310: loss = 0.3480 (0.803 sec/step)\n",
            "I0321 21:50:22.846395 140436091496320 learning.py:507] global step 110310: loss = 0.3480 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 110320: loss = 0.3679 (0.786 sec/step)\n",
            "I0321 21:50:30.963872 140436091496320 learning.py:507] global step 110320: loss = 0.3679 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 110330: loss = 0.3830 (0.787 sec/step)\n",
            "I0321 21:50:38.864632 140436091496320 learning.py:507] global step 110330: loss = 0.3830 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 110340: loss = 0.3599 (0.945 sec/step)\n",
            "I0321 21:50:47.092456 140436091496320 learning.py:507] global step 110340: loss = 0.3599 (0.945 sec/step)\n",
            "INFO:tensorflow:global step 110350: loss = 0.3770 (0.802 sec/step)\n",
            "I0321 21:50:55.065772 140436091496320 learning.py:507] global step 110350: loss = 0.3770 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 110360: loss = 0.3270 (0.801 sec/step)\n",
            "I0321 21:51:03.013524 140436091496320 learning.py:507] global step 110360: loss = 0.3270 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 110370: loss = 0.3689 (0.790 sec/step)\n",
            "I0321 21:51:10.929597 140436091496320 learning.py:507] global step 110370: loss = 0.3689 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 110380: loss = 0.3707 (0.786 sec/step)\n",
            "I0321 21:51:18.797117 140436091496320 learning.py:507] global step 110380: loss = 0.3707 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 110390: loss = 0.3993 (0.781 sec/step)\n",
            "I0321 21:51:26.784110 140436091496320 learning.py:507] global step 110390: loss = 0.3993 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 110400: loss = 0.3785 (0.821 sec/step)\n",
            "I0321 21:51:35.226525 140436091496320 learning.py:507] global step 110400: loss = 0.3785 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 110410: loss = 0.3707 (0.781 sec/step)\n",
            "I0321 21:51:43.147812 140436091496320 learning.py:507] global step 110410: loss = 0.3707 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 110420: loss = 0.3593 (0.782 sec/step)\n",
            "I0321 21:51:51.313386 140436091496320 learning.py:507] global step 110420: loss = 0.3593 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110430: loss = 0.3508 (0.948 sec/step)\n",
            "I0321 21:51:59.486518 140436091496320 learning.py:507] global step 110430: loss = 0.3508 (0.948 sec/step)\n",
            "INFO:tensorflow:global step 110440: loss = 0.3669 (0.783 sec/step)\n",
            "I0321 21:52:07.441893 140436091496320 learning.py:507] global step 110440: loss = 0.3669 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110450: loss = 0.4391 (0.786 sec/step)\n",
            "I0321 21:52:15.552489 140436091496320 learning.py:507] global step 110450: loss = 0.4391 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 110460: loss = 0.3471 (0.952 sec/step)\n",
            "I0321 21:52:23.897216 140436091496320 learning.py:507] global step 110460: loss = 0.3471 (0.952 sec/step)\n",
            "INFO:tensorflow:global step 110470: loss = 0.3957 (0.780 sec/step)\n",
            "I0321 21:52:32.019136 140436091496320 learning.py:507] global step 110470: loss = 0.3957 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 110480: loss = 0.3719 (0.790 sec/step)\n",
            "I0321 21:52:40.277506 140436091496320 learning.py:507] global step 110480: loss = 0.3719 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 110490: loss = 0.3605 (0.791 sec/step)\n",
            "I0321 21:52:48.146916 140436091496320 learning.py:507] global step 110490: loss = 0.3605 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 110500: loss = 0.4272 (0.781 sec/step)\n",
            "I0321 21:52:56.021957 140436091496320 learning.py:507] global step 110500: loss = 0.4272 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 110510: loss = 0.3646 (0.795 sec/step)\n",
            "I0321 21:53:03.948817 140436091496320 learning.py:507] global step 110510: loss = 0.3646 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 110520: loss = 0.3719 (0.913 sec/step)\n",
            "I0321 21:53:12.173804 140436091496320 learning.py:507] global step 110520: loss = 0.3719 (0.913 sec/step)\n",
            "INFO:tensorflow:global step 110530: loss = 0.4117 (0.790 sec/step)\n",
            "I0321 21:53:20.070409 140436091496320 learning.py:507] global step 110530: loss = 0.4117 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 110540: loss = 0.3765 (0.791 sec/step)\n",
            "I0321 21:53:28.036665 140436091496320 learning.py:507] global step 110540: loss = 0.3765 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 110550: loss = 0.3715 (0.820 sec/step)\n",
            "I0321 21:53:35.989140 140436091496320 learning.py:507] global step 110550: loss = 0.3715 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 110560: loss = 0.3634 (0.779 sec/step)\n",
            "I0321 21:53:44.118543 140436091496320 learning.py:507] global step 110560: loss = 0.3634 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 110570: loss = 0.3543 (0.785 sec/step)\n",
            "I0321 21:53:52.245189 140436091496320 learning.py:507] global step 110570: loss = 0.3543 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110580: loss = 0.3597 (0.792 sec/step)\n",
            "I0321 21:54:00.097678 140436091496320 learning.py:507] global step 110580: loss = 0.3597 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 110590: loss = 0.4005 (0.782 sec/step)\n",
            "I0321 21:54:07.971344 140436091496320 learning.py:507] global step 110590: loss = 0.4005 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110600: loss = 0.3898 (0.780 sec/step)\n",
            "I0321 21:54:16.041117 140436091496320 learning.py:507] global step 110600: loss = 0.3898 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 110610: loss = 0.3745 (0.805 sec/step)\n",
            "I0321 21:54:23.909713 140436091496320 learning.py:507] global step 110610: loss = 0.3745 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 110620: loss = 0.3701 (0.781 sec/step)\n",
            "I0321 21:54:31.849223 140436091496320 learning.py:507] global step 110620: loss = 0.3701 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 110630: loss = 0.3874 (0.783 sec/step)\n",
            "I0321 21:54:39.930078 140436091496320 learning.py:507] global step 110630: loss = 0.3874 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110640: loss = 0.4016 (0.902 sec/step)\n",
            "I0321 21:54:47.997774 140436091496320 learning.py:507] global step 110640: loss = 0.4016 (0.902 sec/step)\n",
            "INFO:tensorflow:global step 110650: loss = 0.3580 (0.804 sec/step)\n",
            "I0321 21:54:55.897371 140436091496320 learning.py:507] global step 110650: loss = 0.3580 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 110660: loss = 0.3648 (0.778 sec/step)\n",
            "I0321 21:55:03.803744 140436091496320 learning.py:507] global step 110660: loss = 0.3648 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 110670: loss = 0.3774 (0.803 sec/step)\n",
            "I0321 21:55:11.724085 140436091496320 learning.py:507] global step 110670: loss = 0.3774 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 110680: loss = 0.3686 (0.786 sec/step)\n",
            "I0321 21:55:19.631936 140436091496320 learning.py:507] global step 110680: loss = 0.3686 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 110690: loss = 0.3882 (0.784 sec/step)\n",
            "I0321 21:55:27.807024 140436091496320 learning.py:507] global step 110690: loss = 0.3882 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 110700: loss = 0.3652 (0.781 sec/step)\n",
            "I0321 21:55:35.758622 140436091496320 learning.py:507] global step 110700: loss = 0.3652 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 110710: loss = 0.3952 (0.791 sec/step)\n",
            "I0321 21:55:44.012153 140436091496320 learning.py:507] global step 110710: loss = 0.3952 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 110720: loss = 0.4177 (0.782 sec/step)\n",
            "I0321 21:55:51.967602 140436091496320 learning.py:507] global step 110720: loss = 0.4177 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110730: loss = 0.3793 (0.801 sec/step)\n",
            "I0321 21:56:00.103108 140436091496320 learning.py:507] global step 110730: loss = 0.3793 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 110740: loss = 0.3966 (0.783 sec/step)\n",
            "I0321 21:56:08.428593 140436091496320 learning.py:507] global step 110740: loss = 0.3966 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110750: loss = 0.3511 (0.787 sec/step)\n",
            "I0321 21:56:16.387288 140436091496320 learning.py:507] global step 110750: loss = 0.3511 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 110760: loss = 0.3727 (0.785 sec/step)\n",
            "I0321 21:56:24.387164 140436091496320 learning.py:507] global step 110760: loss = 0.3727 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110770: loss = 0.3788 (0.788 sec/step)\n",
            "I0321 21:56:32.279336 140436091496320 learning.py:507] global step 110770: loss = 0.3788 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 110780: loss = 0.3561 (0.779 sec/step)\n",
            "I0321 21:56:40.200626 140436091496320 learning.py:507] global step 110780: loss = 0.3561 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 110790: loss = 0.3851 (0.796 sec/step)\n",
            "I0321 21:56:48.179616 140436091496320 learning.py:507] global step 110790: loss = 0.3851 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 110800: loss = 0.3720 (0.782 sec/step)\n",
            "I0321 21:56:56.314695 140436091496320 learning.py:507] global step 110800: loss = 0.3720 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110810: loss = 0.3984 (0.785 sec/step)\n",
            "I0321 21:57:04.302306 140436091496320 learning.py:507] global step 110810: loss = 0.3984 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110820: loss = 0.3725 (0.782 sec/step)\n",
            "I0321 21:57:12.231974 140436091496320 learning.py:507] global step 110820: loss = 0.3725 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110830: loss = 0.3727 (0.783 sec/step)\n",
            "I0321 21:57:20.165316 140436091496320 learning.py:507] global step 110830: loss = 0.3727 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110840: loss = 0.4611 (0.785 sec/step)\n",
            "I0321 21:57:28.079863 140436091496320 learning.py:507] global step 110840: loss = 0.4611 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110850: loss = 0.3439 (0.788 sec/step)\n",
            "I0321 21:57:36.145905 140436091496320 learning.py:507] global step 110850: loss = 0.3439 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 110860: loss = 0.4270 (0.785 sec/step)\n",
            "I0321 21:57:44.060773 140436091496320 learning.py:507] global step 110860: loss = 0.4270 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110870: loss = 0.4413 (0.785 sec/step)\n",
            "I0321 21:57:52.099203 140436091496320 learning.py:507] global step 110870: loss = 0.4413 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110880: loss = 0.3549 (0.782 sec/step)\n",
            "I0321 21:58:00.003697 140436091496320 learning.py:507] global step 110880: loss = 0.3549 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110890: loss = 0.3671 (0.782 sec/step)\n",
            "I0321 21:58:08.050149 140436091496320 learning.py:507] global step 110890: loss = 0.3671 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110900: loss = 0.3748 (0.782 sec/step)\n",
            "I0321 21:58:15.948468 140436091496320 learning.py:507] global step 110900: loss = 0.3748 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 110910: loss = 0.3562 (0.778 sec/step)\n",
            "I0321 21:58:24.038731 140436091496320 learning.py:507] global step 110910: loss = 0.3562 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 110920: loss = 0.3680 (0.783 sec/step)\n",
            "I0321 21:58:31.959042 140436091496320 learning.py:507] global step 110920: loss = 0.3680 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110930: loss = 0.3522 (0.818 sec/step)\n",
            "I0321 21:58:39.921185 140436091496320 learning.py:507] global step 110930: loss = 0.3522 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 110940: loss = 0.3457 (0.785 sec/step)\n",
            "I0321 21:58:48.118391 140436091496320 learning.py:507] global step 110940: loss = 0.3457 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 110950: loss = 0.3749 (0.796 sec/step)\n",
            "I0321 21:58:56.142956 140436091496320 learning.py:507] global step 110950: loss = 0.3749 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 110960: loss = 0.3827 (0.783 sec/step)\n",
            "I0321 21:59:04.212691 140436091496320 learning.py:507] global step 110960: loss = 0.3827 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 110970: loss = 0.4271 (0.924 sec/step)\n",
            "I0321 21:59:12.517825 140436091496320 learning.py:507] global step 110970: loss = 0.4271 (0.924 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 21:59:18.301690 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 110977.\n",
            "I0321 21:59:21.186696 140432184936192 supervisor.py:1050] Recording summary at step 110977.\n",
            "INFO:tensorflow:global_step/sec: 1.24399\n",
            "I0321 21:59:21.251982 140432193328896 supervisor.py:1099] global_step/sec: 1.24399\n",
            "INFO:tensorflow:global step 110980: loss = 0.3528 (0.984 sec/step)\n",
            "I0321 21:59:23.051374 140436091496320 learning.py:507] global step 110980: loss = 0.3528 (0.984 sec/step)\n",
            "INFO:tensorflow:global step 110990: loss = 0.3531 (0.787 sec/step)\n",
            "I0321 21:59:30.964248 140436091496320 learning.py:507] global step 110990: loss = 0.3531 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 111000: loss = 0.4678 (0.788 sec/step)\n",
            "I0321 21:59:38.866113 140436091496320 learning.py:507] global step 111000: loss = 0.4678 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 111010: loss = 0.3774 (0.804 sec/step)\n",
            "I0321 21:59:46.742387 140436091496320 learning.py:507] global step 111010: loss = 0.3774 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 111020: loss = 0.3546 (0.785 sec/step)\n",
            "I0321 21:59:54.755836 140436091496320 learning.py:507] global step 111020: loss = 0.3546 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 111030: loss = 0.3969 (0.781 sec/step)\n",
            "I0321 22:00:02.654900 140436091496320 learning.py:507] global step 111030: loss = 0.3969 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 111040: loss = 0.3785 (0.780 sec/step)\n",
            "I0321 22:00:10.541072 140436091496320 learning.py:507] global step 111040: loss = 0.3785 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111050: loss = 0.3569 (0.806 sec/step)\n",
            "I0321 22:00:18.765672 140436091496320 learning.py:507] global step 111050: loss = 0.3569 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 111060: loss = 0.3654 (0.784 sec/step)\n",
            "I0321 22:00:26.696255 140436091496320 learning.py:507] global step 111060: loss = 0.3654 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111070: loss = 0.3509 (0.815 sec/step)\n",
            "I0321 22:00:34.747899 140436091496320 learning.py:507] global step 111070: loss = 0.3509 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 111080: loss = 0.3767 (0.784 sec/step)\n",
            "I0321 22:00:42.630637 140436091496320 learning.py:507] global step 111080: loss = 0.3767 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111090: loss = 0.3556 (0.783 sec/step)\n",
            "I0321 22:00:50.768481 140436091496320 learning.py:507] global step 111090: loss = 0.3556 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111100: loss = 0.4121 (0.779 sec/step)\n",
            "I0321 22:00:58.721642 140436091496320 learning.py:507] global step 111100: loss = 0.4121 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 111110: loss = 0.3619 (0.889 sec/step)\n",
            "I0321 22:01:06.745426 140436091496320 learning.py:507] global step 111110: loss = 0.3619 (0.889 sec/step)\n",
            "INFO:tensorflow:global step 111120: loss = 0.3653 (0.782 sec/step)\n",
            "I0321 22:01:14.686323 140436091496320 learning.py:507] global step 111120: loss = 0.3653 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 111130: loss = 0.3667 (0.802 sec/step)\n",
            "I0321 22:01:22.758280 140436091496320 learning.py:507] global step 111130: loss = 0.3667 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 111140: loss = 0.4067 (0.805 sec/step)\n",
            "I0321 22:01:30.815852 140436091496320 learning.py:507] global step 111140: loss = 0.4067 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 111150: loss = 0.3438 (0.787 sec/step)\n",
            "I0321 22:01:38.947029 140436091496320 learning.py:507] global step 111150: loss = 0.3438 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 111160: loss = 0.3922 (0.784 sec/step)\n",
            "I0321 22:01:46.995449 140436091496320 learning.py:507] global step 111160: loss = 0.3922 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111170: loss = 0.3988 (0.799 sec/step)\n",
            "I0321 22:01:54.983433 140436091496320 learning.py:507] global step 111170: loss = 0.3988 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 111180: loss = 0.4264 (0.777 sec/step)\n",
            "I0321 22:02:02.884401 140436091496320 learning.py:507] global step 111180: loss = 0.4264 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 111190: loss = 0.3783 (0.786 sec/step)\n",
            "I0321 22:02:10.850305 140436091496320 learning.py:507] global step 111190: loss = 0.3783 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 111200: loss = 0.3822 (0.810 sec/step)\n",
            "I0321 22:02:18.773580 140436091496320 learning.py:507] global step 111200: loss = 0.3822 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 111210: loss = 0.3956 (0.790 sec/step)\n",
            "I0321 22:02:26.725525 140436091496320 learning.py:507] global step 111210: loss = 0.3956 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 111220: loss = 0.3550 (0.787 sec/step)\n",
            "I0321 22:02:34.646979 140436091496320 learning.py:507] global step 111220: loss = 0.3550 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 111230: loss = 0.3767 (0.800 sec/step)\n",
            "I0321 22:02:42.643851 140436091496320 learning.py:507] global step 111230: loss = 0.3767 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 111240: loss = 0.3676 (0.795 sec/step)\n",
            "I0321 22:02:50.651916 140436091496320 learning.py:507] global step 111240: loss = 0.3676 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 111250: loss = 0.3855 (0.782 sec/step)\n",
            "I0321 22:02:58.813677 140436091496320 learning.py:507] global step 111250: loss = 0.3855 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 111260: loss = 0.3634 (0.780 sec/step)\n",
            "I0321 22:03:06.886527 140436091496320 learning.py:507] global step 111260: loss = 0.3634 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111270: loss = 0.3522 (0.781 sec/step)\n",
            "I0321 22:03:14.856899 140436091496320 learning.py:507] global step 111270: loss = 0.3522 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 111280: loss = 0.3646 (0.780 sec/step)\n",
            "I0321 22:03:22.935495 140436091496320 learning.py:507] global step 111280: loss = 0.3646 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111290: loss = 0.3595 (0.845 sec/step)\n",
            "I0321 22:03:30.970796 140436091496320 learning.py:507] global step 111290: loss = 0.3595 (0.845 sec/step)\n",
            "INFO:tensorflow:global step 111300: loss = 0.3857 (0.808 sec/step)\n",
            "I0321 22:03:39.080220 140436091496320 learning.py:507] global step 111300: loss = 0.3857 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 111310: loss = 0.3622 (0.779 sec/step)\n",
            "I0321 22:03:47.098763 140436091496320 learning.py:507] global step 111310: loss = 0.3622 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 111320: loss = 0.4245 (0.974 sec/step)\n",
            "I0321 22:03:55.410968 140436091496320 learning.py:507] global step 111320: loss = 0.4245 (0.974 sec/step)\n",
            "INFO:tensorflow:global step 111330: loss = 0.3474 (0.792 sec/step)\n",
            "I0321 22:04:03.500666 140436091496320 learning.py:507] global step 111330: loss = 0.3474 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 111340: loss = 0.3760 (0.786 sec/step)\n",
            "I0321 22:04:11.368425 140436091496320 learning.py:507] global step 111340: loss = 0.3760 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 111350: loss = 0.3774 (0.824 sec/step)\n",
            "I0321 22:04:19.343969 140436091496320 learning.py:507] global step 111350: loss = 0.3774 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 111360: loss = 0.3649 (0.779 sec/step)\n",
            "I0321 22:04:27.278158 140436091496320 learning.py:507] global step 111360: loss = 0.3649 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 111370: loss = 0.3652 (0.789 sec/step)\n",
            "I0321 22:04:35.291450 140436091496320 learning.py:507] global step 111370: loss = 0.3652 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 111380: loss = 0.3544 (0.820 sec/step)\n",
            "I0321 22:04:43.204683 140436091496320 learning.py:507] global step 111380: loss = 0.3544 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 111390: loss = 0.3979 (0.780 sec/step)\n",
            "I0321 22:04:51.058533 140436091496320 learning.py:507] global step 111390: loss = 0.3979 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111400: loss = 0.3513 (0.794 sec/step)\n",
            "I0321 22:04:59.164033 140436091496320 learning.py:507] global step 111400: loss = 0.3513 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 111410: loss = 0.3447 (0.784 sec/step)\n",
            "I0321 22:05:07.072710 140436091496320 learning.py:507] global step 111410: loss = 0.3447 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111420: loss = 0.3453 (0.781 sec/step)\n",
            "I0321 22:05:15.199511 140436091496320 learning.py:507] global step 111420: loss = 0.3453 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 111430: loss = 0.3630 (0.783 sec/step)\n",
            "I0321 22:05:23.037713 140436091496320 learning.py:507] global step 111430: loss = 0.3630 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111440: loss = 0.3584 (0.806 sec/step)\n",
            "I0321 22:05:30.969270 140436091496320 learning.py:507] global step 111440: loss = 0.3584 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 111450: loss = 0.3715 (0.782 sec/step)\n",
            "I0321 22:05:39.154293 140436091496320 learning.py:507] global step 111450: loss = 0.3715 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 111460: loss = 0.3638 (0.782 sec/step)\n",
            "I0321 22:05:47.296367 140436091496320 learning.py:507] global step 111460: loss = 0.3638 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 111470: loss = 0.3774 (0.783 sec/step)\n",
            "I0321 22:05:55.233932 140436091496320 learning.py:507] global step 111470: loss = 0.3774 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111480: loss = 0.3638 (0.791 sec/step)\n",
            "I0321 22:06:03.394797 140436091496320 learning.py:507] global step 111480: loss = 0.3638 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 111490: loss = 0.3939 (0.802 sec/step)\n",
            "I0321 22:06:11.476893 140436091496320 learning.py:507] global step 111490: loss = 0.3939 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 111500: loss = 0.3508 (0.799 sec/step)\n",
            "I0321 22:06:19.365681 140436091496320 learning.py:507] global step 111500: loss = 0.3508 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 111510: loss = 0.3575 (0.783 sec/step)\n",
            "I0321 22:06:27.556972 140436091496320 learning.py:507] global step 111510: loss = 0.3575 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111520: loss = 0.3679 (0.785 sec/step)\n",
            "I0321 22:06:35.562923 140436091496320 learning.py:507] global step 111520: loss = 0.3679 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 111530: loss = 0.3600 (0.780 sec/step)\n",
            "I0321 22:06:43.704646 140436091496320 learning.py:507] global step 111530: loss = 0.3600 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111540: loss = 0.3752 (0.780 sec/step)\n",
            "I0321 22:06:51.594691 140436091496320 learning.py:507] global step 111540: loss = 0.3752 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111550: loss = 0.3873 (0.781 sec/step)\n",
            "I0321 22:06:59.576805 140436091496320 learning.py:507] global step 111550: loss = 0.3873 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 111560: loss = 0.3887 (0.787 sec/step)\n",
            "I0321 22:07:07.475022 140436091496320 learning.py:507] global step 111560: loss = 0.3887 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 111570: loss = 0.3717 (0.792 sec/step)\n",
            "I0321 22:07:15.574683 140436091496320 learning.py:507] global step 111570: loss = 0.3717 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 111580: loss = 0.3956 (0.777 sec/step)\n",
            "I0321 22:07:23.488927 140436091496320 learning.py:507] global step 111580: loss = 0.3956 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 111590: loss = 0.3875 (0.813 sec/step)\n",
            "I0321 22:07:31.536187 140436091496320 learning.py:507] global step 111590: loss = 0.3875 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 111600: loss = 0.3676 (0.787 sec/step)\n",
            "I0321 22:07:39.628926 140436091496320 learning.py:507] global step 111600: loss = 0.3676 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 111610: loss = 0.3770 (0.782 sec/step)\n",
            "I0321 22:07:47.542953 140436091496320 learning.py:507] global step 111610: loss = 0.3770 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 111620: loss = 0.3811 (0.806 sec/step)\n",
            "I0321 22:07:55.446705 140436091496320 learning.py:507] global step 111620: loss = 0.3811 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 111630: loss = 0.3798 (0.774 sec/step)\n",
            "I0321 22:08:03.514426 140436091496320 learning.py:507] global step 111630: loss = 0.3798 (0.774 sec/step)\n",
            "INFO:tensorflow:global step 111640: loss = 0.3663 (0.783 sec/step)\n",
            "I0321 22:08:11.429528 140436091496320 learning.py:507] global step 111640: loss = 0.3663 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111650: loss = 0.3785 (0.810 sec/step)\n",
            "I0321 22:08:19.358777 140436091496320 learning.py:507] global step 111650: loss = 0.3785 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 111660: loss = 0.3496 (0.781 sec/step)\n",
            "I0321 22:08:27.627545 140436091496320 learning.py:507] global step 111660: loss = 0.3496 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 111670: loss = 0.3696 (0.782 sec/step)\n",
            "I0321 22:08:35.553469 140436091496320 learning.py:507] global step 111670: loss = 0.3696 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 111680: loss = 0.3821 (0.800 sec/step)\n",
            "I0321 22:08:43.507794 140436091496320 learning.py:507] global step 111680: loss = 0.3821 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 111690: loss = 0.3667 (0.793 sec/step)\n",
            "I0321 22:08:51.373930 140436091496320 learning.py:507] global step 111690: loss = 0.3667 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 111700: loss = 0.3599 (0.783 sec/step)\n",
            "I0321 22:08:59.240806 140436091496320 learning.py:507] global step 111700: loss = 0.3599 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111710: loss = 0.4846 (0.809 sec/step)\n",
            "I0321 22:09:07.253161 140436091496320 learning.py:507] global step 111710: loss = 0.4846 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 111720: loss = 0.3599 (0.784 sec/step)\n",
            "I0321 22:09:15.167921 140436091496320 learning.py:507] global step 111720: loss = 0.3599 (0.784 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 111724.\n",
            "I0321 22:09:20.144890 140432184936192 supervisor.py:1050] Recording summary at step 111724.\n",
            "INFO:tensorflow:global_step/sec: 1.24459\n",
            "I0321 22:09:20.648001 140432193328896 supervisor.py:1099] global_step/sec: 1.24459\n",
            "INFO:tensorflow:global step 111730: loss = 0.4413 (0.799 sec/step)\n",
            "I0321 22:09:25.114011 140436091496320 learning.py:507] global step 111730: loss = 0.4413 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 111740: loss = 0.4160 (0.783 sec/step)\n",
            "I0321 22:09:33.021812 140436091496320 learning.py:507] global step 111740: loss = 0.4160 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111750: loss = 0.3944 (0.791 sec/step)\n",
            "I0321 22:09:41.213346 140436091496320 learning.py:507] global step 111750: loss = 0.3944 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 111760: loss = 0.3536 (0.960 sec/step)\n",
            "I0321 22:09:49.426726 140436091496320 learning.py:507] global step 111760: loss = 0.3536 (0.960 sec/step)\n",
            "INFO:tensorflow:global step 111770: loss = 0.3938 (0.783 sec/step)\n",
            "I0321 22:09:57.302242 140436091496320 learning.py:507] global step 111770: loss = 0.3938 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111780: loss = 0.4448 (0.799 sec/step)\n",
            "I0321 22:10:05.208270 140436091496320 learning.py:507] global step 111780: loss = 0.4448 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 111790: loss = 0.4031 (0.784 sec/step)\n",
            "I0321 22:10:13.131992 140436091496320 learning.py:507] global step 111790: loss = 0.4031 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111800: loss = 0.3774 (0.784 sec/step)\n",
            "I0321 22:10:21.328724 140436091496320 learning.py:507] global step 111800: loss = 0.3774 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111810: loss = 0.3845 (0.781 sec/step)\n",
            "I0321 22:10:29.460217 140436091496320 learning.py:507] global step 111810: loss = 0.3845 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 111820: loss = 0.3791 (0.949 sec/step)\n",
            "I0321 22:10:37.533975 140436091496320 learning.py:507] global step 111820: loss = 0.3791 (0.949 sec/step)\n",
            "INFO:tensorflow:global step 111830: loss = 0.3734 (0.795 sec/step)\n",
            "I0321 22:10:45.466302 140436091496320 learning.py:507] global step 111830: loss = 0.3734 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 111840: loss = 0.3624 (0.788 sec/step)\n",
            "I0321 22:10:53.560282 140436091496320 learning.py:507] global step 111840: loss = 0.3624 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 111850: loss = 0.3699 (0.998 sec/step)\n",
            "I0321 22:11:01.956464 140436091496320 learning.py:507] global step 111850: loss = 0.3699 (0.998 sec/step)\n",
            "INFO:tensorflow:global step 111860: loss = 0.3811 (0.802 sec/step)\n",
            "I0321 22:11:10.126940 140436091496320 learning.py:507] global step 111860: loss = 0.3811 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 111870: loss = 0.3825 (0.797 sec/step)\n",
            "I0321 22:11:18.072968 140436091496320 learning.py:507] global step 111870: loss = 0.3825 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 111880: loss = 0.4686 (0.813 sec/step)\n",
            "I0321 22:11:25.995608 140436091496320 learning.py:507] global step 111880: loss = 0.4686 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 111890: loss = 0.3627 (0.783 sec/step)\n",
            "I0321 22:11:33.899910 140436091496320 learning.py:507] global step 111890: loss = 0.3627 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 111900: loss = 0.3653 (0.784 sec/step)\n",
            "I0321 22:11:41.803691 140436091496320 learning.py:507] global step 111900: loss = 0.3653 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111910: loss = 0.3595 (0.785 sec/step)\n",
            "I0321 22:11:49.782760 140436091496320 learning.py:507] global step 111910: loss = 0.3595 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 111920: loss = 0.3884 (0.780 sec/step)\n",
            "I0321 22:11:57.679038 140436091496320 learning.py:507] global step 111920: loss = 0.3884 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111930: loss = 0.4422 (0.784 sec/step)\n",
            "I0321 22:12:05.575939 140436091496320 learning.py:507] global step 111930: loss = 0.4422 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 111940: loss = 0.3728 (0.786 sec/step)\n",
            "I0321 22:12:13.786132 140436091496320 learning.py:507] global step 111940: loss = 0.3728 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 111950: loss = 0.3529 (0.781 sec/step)\n",
            "I0321 22:12:21.638504 140436091496320 learning.py:507] global step 111950: loss = 0.3529 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 111960: loss = 0.3488 (0.786 sec/step)\n",
            "I0321 22:12:29.694489 140436091496320 learning.py:507] global step 111960: loss = 0.3488 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 111970: loss = 0.3681 (0.780 sec/step)\n",
            "I0321 22:12:37.558795 140436091496320 learning.py:507] global step 111970: loss = 0.3681 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 111980: loss = 0.3759 (0.802 sec/step)\n",
            "I0321 22:12:45.712225 140436091496320 learning.py:507] global step 111980: loss = 0.3759 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 111990: loss = 0.4084 (0.779 sec/step)\n",
            "I0321 22:12:53.607588 140436091496320 learning.py:507] global step 111990: loss = 0.4084 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112000: loss = 0.3695 (0.814 sec/step)\n",
            "I0321 22:13:01.708511 140436091496320 learning.py:507] global step 112000: loss = 0.3695 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 112010: loss = 0.3541 (0.779 sec/step)\n",
            "I0321 22:13:09.748036 140436091496320 learning.py:507] global step 112010: loss = 0.3541 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112020: loss = 0.3375 (0.780 sec/step)\n",
            "I0321 22:13:17.665752 140436091496320 learning.py:507] global step 112020: loss = 0.3375 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 112030: loss = 0.3660 (0.782 sec/step)\n",
            "I0321 22:13:25.787726 140436091496320 learning.py:507] global step 112030: loss = 0.3660 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112040: loss = 0.3610 (0.804 sec/step)\n",
            "I0321 22:13:33.923115 140436091496320 learning.py:507] global step 112040: loss = 0.3610 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 112050: loss = 0.3561 (0.785 sec/step)\n",
            "I0321 22:13:41.870761 140436091496320 learning.py:507] global step 112050: loss = 0.3561 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 112060: loss = 0.3556 (0.782 sec/step)\n",
            "I0321 22:13:49.956305 140436091496320 learning.py:507] global step 112060: loss = 0.3556 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112070: loss = 0.3966 (0.792 sec/step)\n",
            "I0321 22:13:57.933947 140436091496320 learning.py:507] global step 112070: loss = 0.3966 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 112080: loss = 0.3815 (0.779 sec/step)\n",
            "I0321 22:14:05.811860 140436091496320 learning.py:507] global step 112080: loss = 0.3815 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112090: loss = 0.3790 (0.972 sec/step)\n",
            "I0321 22:14:14.150430 140436091496320 learning.py:507] global step 112090: loss = 0.3790 (0.972 sec/step)\n",
            "INFO:tensorflow:global step 112100: loss = 0.4017 (0.779 sec/step)\n",
            "I0321 22:14:22.090522 140436091496320 learning.py:507] global step 112100: loss = 0.4017 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112110: loss = 0.4514 (0.780 sec/step)\n",
            "I0321 22:14:29.950705 140436091496320 learning.py:507] global step 112110: loss = 0.4514 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 112120: loss = 0.3610 (0.778 sec/step)\n",
            "I0321 22:14:37.797499 140436091496320 learning.py:507] global step 112120: loss = 0.3610 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 112130: loss = 0.3408 (0.793 sec/step)\n",
            "I0321 22:14:45.694597 140436091496320 learning.py:507] global step 112130: loss = 0.3408 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 112140: loss = 0.3542 (0.784 sec/step)\n",
            "I0321 22:14:53.661061 140436091496320 learning.py:507] global step 112140: loss = 0.3542 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 112150: loss = 0.3609 (0.788 sec/step)\n",
            "I0321 22:15:01.558900 140436091496320 learning.py:507] global step 112150: loss = 0.3609 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 112160: loss = 0.3426 (0.783 sec/step)\n",
            "I0321 22:15:09.624859 140436091496320 learning.py:507] global step 112160: loss = 0.3426 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 112170: loss = 0.4014 (0.787 sec/step)\n",
            "I0321 22:15:17.541363 140436091496320 learning.py:507] global step 112170: loss = 0.4014 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 112180: loss = 0.3806 (0.958 sec/step)\n",
            "I0321 22:15:25.652730 140436091496320 learning.py:507] global step 112180: loss = 0.3806 (0.958 sec/step)\n",
            "INFO:tensorflow:global step 112190: loss = 0.3961 (0.780 sec/step)\n",
            "I0321 22:15:33.714468 140436091496320 learning.py:507] global step 112190: loss = 0.3961 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 112200: loss = 0.3751 (0.796 sec/step)\n",
            "I0321 22:15:41.600738 140436091496320 learning.py:507] global step 112200: loss = 0.3751 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 112210: loss = 0.3809 (0.813 sec/step)\n",
            "I0321 22:15:49.690647 140436091496320 learning.py:507] global step 112210: loss = 0.3809 (0.813 sec/step)\n",
            "INFO:tensorflow:global step 112220: loss = 0.3953 (0.779 sec/step)\n",
            "I0321 22:15:57.680606 140436091496320 learning.py:507] global step 112220: loss = 0.3953 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112230: loss = 0.3422 (0.782 sec/step)\n",
            "I0321 22:16:05.555924 140436091496320 learning.py:507] global step 112230: loss = 0.3422 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112240: loss = 0.3799 (0.801 sec/step)\n",
            "I0321 22:16:13.701688 140436091496320 learning.py:507] global step 112240: loss = 0.3799 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 112250: loss = 0.3700 (0.785 sec/step)\n",
            "I0321 22:16:21.826842 140436091496320 learning.py:507] global step 112250: loss = 0.3700 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 112260: loss = 0.3463 (0.785 sec/step)\n",
            "I0321 22:16:29.684271 140436091496320 learning.py:507] global step 112260: loss = 0.3463 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 112270: loss = 0.3523 (0.888 sec/step)\n",
            "I0321 22:16:37.818492 140436091496320 learning.py:507] global step 112270: loss = 0.3523 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 112280: loss = 0.3685 (0.780 sec/step)\n",
            "I0321 22:16:45.727384 140436091496320 learning.py:507] global step 112280: loss = 0.3685 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 112290: loss = 0.3668 (0.789 sec/step)\n",
            "I0321 22:16:53.900834 140436091496320 learning.py:507] global step 112290: loss = 0.3668 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 112300: loss = 0.3902 (0.793 sec/step)\n",
            "I0321 22:17:01.844367 140436091496320 learning.py:507] global step 112300: loss = 0.3902 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 112310: loss = 0.3763 (0.782 sec/step)\n",
            "I0321 22:17:09.804493 140436091496320 learning.py:507] global step 112310: loss = 0.3763 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112320: loss = 0.3653 (0.795 sec/step)\n",
            "I0321 22:17:17.794988 140436091496320 learning.py:507] global step 112320: loss = 0.3653 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 112330: loss = 0.3867 (0.792 sec/step)\n",
            "I0321 22:17:25.657354 140436091496320 learning.py:507] global step 112330: loss = 0.3867 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 112340: loss = 0.3616 (0.783 sec/step)\n",
            "I0321 22:17:33.581461 140436091496320 learning.py:507] global step 112340: loss = 0.3616 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 112350: loss = 0.3547 (0.778 sec/step)\n",
            "I0321 22:17:41.533849 140436091496320 learning.py:507] global step 112350: loss = 0.3547 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 112360: loss = 0.3859 (0.779 sec/step)\n",
            "I0321 22:17:49.567717 140436091496320 learning.py:507] global step 112360: loss = 0.3859 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112370: loss = 0.3757 (0.789 sec/step)\n",
            "I0321 22:17:57.607549 140436091496320 learning.py:507] global step 112370: loss = 0.3757 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 112380: loss = 0.3610 (0.781 sec/step)\n",
            "I0321 22:18:05.662500 140436091496320 learning.py:507] global step 112380: loss = 0.3610 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 112390: loss = 0.4009 (0.906 sec/step)\n",
            "I0321 22:18:13.942389 140436091496320 learning.py:507] global step 112390: loss = 0.4009 (0.906 sec/step)\n",
            "INFO:tensorflow:global step 112400: loss = 0.3580 (0.778 sec/step)\n",
            "I0321 22:18:21.809949 140436091496320 learning.py:507] global step 112400: loss = 0.3580 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 112410: loss = 0.3412 (0.782 sec/step)\n",
            "I0321 22:18:29.908799 140436091496320 learning.py:507] global step 112410: loss = 0.3412 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112420: loss = 0.3644 (0.786 sec/step)\n",
            "I0321 22:18:37.947561 140436091496320 learning.py:507] global step 112420: loss = 0.3644 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 112430: loss = 0.3610 (0.782 sec/step)\n",
            "I0321 22:18:45.873826 140436091496320 learning.py:507] global step 112430: loss = 0.3610 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112440: loss = 0.3559 (0.793 sec/step)\n",
            "I0321 22:18:53.722383 140436091496320 learning.py:507] global step 112440: loss = 0.3559 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 112450: loss = 0.3571 (0.792 sec/step)\n",
            "I0321 22:19:01.676800 140436091496320 learning.py:507] global step 112450: loss = 0.3571 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 112460: loss = 0.3603 (0.781 sec/step)\n",
            "I0321 22:19:09.608232 140436091496320 learning.py:507] global step 112460: loss = 0.3603 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 112470: loss = 0.3996 (0.780 sec/step)\n",
            "I0321 22:19:17.830880 140436091496320 learning.py:507] global step 112470: loss = 0.3996 (0.780 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 22:19:18.301953 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 112471.\n",
            "I0321 22:19:21.020532 140432184936192 supervisor.py:1050] Recording summary at step 112471.\n",
            "INFO:tensorflow:global step 112480: loss = 0.3643 (0.782 sec/step)\n",
            "I0321 22:19:28.331798 140436091496320 learning.py:507] global step 112480: loss = 0.3643 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112490: loss = 0.4398 (0.782 sec/step)\n",
            "I0321 22:19:36.305996 140436091496320 learning.py:507] global step 112490: loss = 0.4398 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112500: loss = 0.3830 (0.787 sec/step)\n",
            "I0321 22:19:44.234347 140436091496320 learning.py:507] global step 112500: loss = 0.3830 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 112510: loss = 0.3578 (0.784 sec/step)\n",
            "I0321 22:19:52.132634 140436091496320 learning.py:507] global step 112510: loss = 0.3578 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 112520: loss = 0.3598 (0.785 sec/step)\n",
            "I0321 22:20:00.056291 140436091496320 learning.py:507] global step 112520: loss = 0.3598 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 112530: loss = 0.4032 (0.787 sec/step)\n",
            "I0321 22:20:08.145686 140436091496320 learning.py:507] global step 112530: loss = 0.4032 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 112540: loss = 0.3883 (0.786 sec/step)\n",
            "I0321 22:20:16.108317 140436091496320 learning.py:507] global step 112540: loss = 0.3883 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 112550: loss = 0.3531 (0.785 sec/step)\n",
            "I0321 22:20:24.199462 140436091496320 learning.py:507] global step 112550: loss = 0.3531 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 112560: loss = 0.3898 (0.796 sec/step)\n",
            "I0321 22:20:32.097744 140436091496320 learning.py:507] global step 112560: loss = 0.3898 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 112570: loss = 0.3614 (0.807 sec/step)\n",
            "I0321 22:20:40.078379 140436091496320 learning.py:507] global step 112570: loss = 0.3614 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 112580: loss = 0.4188 (0.794 sec/step)\n",
            "I0321 22:20:48.090922 140436091496320 learning.py:507] global step 112580: loss = 0.4188 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 112590: loss = 0.3760 (0.786 sec/step)\n",
            "I0321 22:20:56.007109 140436091496320 learning.py:507] global step 112590: loss = 0.3760 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 112600: loss = 0.3961 (0.803 sec/step)\n",
            "I0321 22:21:03.976713 140436091496320 learning.py:507] global step 112600: loss = 0.3961 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 112610: loss = 0.3773 (0.782 sec/step)\n",
            "I0321 22:21:12.205080 140436091496320 learning.py:507] global step 112610: loss = 0.3773 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112620: loss = 0.4205 (0.846 sec/step)\n",
            "I0321 22:21:20.220687 140436091496320 learning.py:507] global step 112620: loss = 0.4205 (0.846 sec/step)\n",
            "INFO:tensorflow:global step 112630: loss = 0.3573 (0.786 sec/step)\n",
            "I0321 22:21:28.114105 140436091496320 learning.py:507] global step 112630: loss = 0.3573 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 112640: loss = 0.3833 (0.795 sec/step)\n",
            "I0321 22:21:36.079854 140436091496320 learning.py:507] global step 112640: loss = 0.3833 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 112650: loss = 0.3600 (0.793 sec/step)\n",
            "I0321 22:21:44.340888 140436091496320 learning.py:507] global step 112650: loss = 0.3600 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 112660: loss = 0.3623 (0.782 sec/step)\n",
            "I0321 22:21:52.643971 140436091496320 learning.py:507] global step 112660: loss = 0.3623 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112670: loss = 0.3652 (0.787 sec/step)\n",
            "I0321 22:22:00.917707 140436091496320 learning.py:507] global step 112670: loss = 0.3652 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 112680: loss = 0.3817 (0.856 sec/step)\n",
            "I0321 22:22:09.001781 140436091496320 learning.py:507] global step 112680: loss = 0.3817 (0.856 sec/step)\n",
            "INFO:tensorflow:global step 112690: loss = 0.3659 (0.782 sec/step)\n",
            "I0321 22:22:16.961769 140436091496320 learning.py:507] global step 112690: loss = 0.3659 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112700: loss = 0.3820 (0.788 sec/step)\n",
            "I0321 22:22:25.090701 140436091496320 learning.py:507] global step 112700: loss = 0.3820 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 112710: loss = 0.4591 (0.890 sec/step)\n",
            "I0321 22:22:33.425141 140436091496320 learning.py:507] global step 112710: loss = 0.4591 (0.890 sec/step)\n",
            "INFO:tensorflow:global step 112720: loss = 0.3690 (0.779 sec/step)\n",
            "I0321 22:22:41.631613 140436091496320 learning.py:507] global step 112720: loss = 0.3690 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112730: loss = 0.3566 (0.781 sec/step)\n",
            "I0321 22:22:49.652609 140436091496320 learning.py:507] global step 112730: loss = 0.3566 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 112740: loss = 0.3658 (0.811 sec/step)\n",
            "I0321 22:22:57.567921 140436091496320 learning.py:507] global step 112740: loss = 0.3658 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 112750: loss = 0.3565 (0.781 sec/step)\n",
            "I0321 22:23:05.698720 140436091496320 learning.py:507] global step 112750: loss = 0.3565 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 112760: loss = 0.3652 (0.781 sec/step)\n",
            "I0321 22:23:13.796238 140436091496320 learning.py:507] global step 112760: loss = 0.3652 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 112770: loss = 0.3648 (0.839 sec/step)\n",
            "I0321 22:23:21.809775 140436091496320 learning.py:507] global step 112770: loss = 0.3648 (0.839 sec/step)\n",
            "INFO:tensorflow:global step 112780: loss = 0.3894 (0.782 sec/step)\n",
            "I0321 22:23:29.732944 140436091496320 learning.py:507] global step 112780: loss = 0.3894 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112790: loss = 0.3578 (0.783 sec/step)\n",
            "I0321 22:23:37.668472 140436091496320 learning.py:507] global step 112790: loss = 0.3578 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 112800: loss = 0.3748 (0.790 sec/step)\n",
            "I0321 22:23:45.595315 140436091496320 learning.py:507] global step 112800: loss = 0.3748 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 112810: loss = 0.4153 (0.778 sec/step)\n",
            "I0321 22:23:53.695471 140436091496320 learning.py:507] global step 112810: loss = 0.4153 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 112820: loss = 0.4028 (0.802 sec/step)\n",
            "I0321 22:24:01.575273 140436091496320 learning.py:507] global step 112820: loss = 0.4028 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 112830: loss = 0.3707 (0.778 sec/step)\n",
            "I0321 22:24:09.646091 140436091496320 learning.py:507] global step 112830: loss = 0.3707 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 112840: loss = 0.4469 (0.802 sec/step)\n",
            "I0321 22:24:17.546742 140436091496320 learning.py:507] global step 112840: loss = 0.4469 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 112850: loss = 0.3645 (0.790 sec/step)\n",
            "I0321 22:24:25.407105 140436091496320 learning.py:507] global step 112850: loss = 0.3645 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 112860: loss = 0.3731 (0.888 sec/step)\n",
            "I0321 22:24:33.626843 140436091496320 learning.py:507] global step 112860: loss = 0.3731 (0.888 sec/step)\n",
            "INFO:tensorflow:global step 112870: loss = 0.3815 (0.779 sec/step)\n",
            "I0321 22:24:41.560777 140436091496320 learning.py:507] global step 112870: loss = 0.3815 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 112880: loss = 0.3938 (0.782 sec/step)\n",
            "I0321 22:24:49.509523 140436091496320 learning.py:507] global step 112880: loss = 0.3938 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112890: loss = 0.4120 (0.815 sec/step)\n",
            "I0321 22:24:57.448368 140436091496320 learning.py:507] global step 112890: loss = 0.4120 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 112900: loss = 0.3669 (0.790 sec/step)\n",
            "I0321 22:25:05.484839 140436091496320 learning.py:507] global step 112900: loss = 0.3669 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 112910: loss = 0.3628 (0.788 sec/step)\n",
            "I0321 22:25:13.664297 140436091496320 learning.py:507] global step 112910: loss = 0.3628 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 112920: loss = 0.3617 (0.809 sec/step)\n",
            "I0321 22:25:21.589807 140436091496320 learning.py:507] global step 112920: loss = 0.3617 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 112930: loss = 0.3676 (0.783 sec/step)\n",
            "I0321 22:25:29.509898 140436091496320 learning.py:507] global step 112930: loss = 0.3676 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 112940: loss = 0.3518 (0.784 sec/step)\n",
            "I0321 22:25:37.441369 140436091496320 learning.py:507] global step 112940: loss = 0.3518 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 112950: loss = 0.3583 (0.926 sec/step)\n",
            "I0321 22:25:45.524319 140436091496320 learning.py:507] global step 112950: loss = 0.3583 (0.926 sec/step)\n",
            "INFO:tensorflow:global step 112960: loss = 0.3729 (0.798 sec/step)\n",
            "I0321 22:25:53.447786 140436091496320 learning.py:507] global step 112960: loss = 0.3729 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 112970: loss = 0.3648 (0.782 sec/step)\n",
            "I0321 22:26:01.539754 140436091496320 learning.py:507] global step 112970: loss = 0.3648 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 112980: loss = 0.3760 (0.803 sec/step)\n",
            "I0321 22:26:09.619085 140436091496320 learning.py:507] global step 112980: loss = 0.3760 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 112990: loss = 0.3607 (0.790 sec/step)\n",
            "I0321 22:26:17.612953 140436091496320 learning.py:507] global step 112990: loss = 0.3607 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 113000: loss = 0.3803 (0.780 sec/step)\n",
            "I0321 22:26:25.821501 140436091496320 learning.py:507] global step 113000: loss = 0.3803 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 113010: loss = 0.4628 (1.022 sec/step)\n",
            "I0321 22:26:33.957663 140436091496320 learning.py:507] global step 113010: loss = 0.4628 (1.022 sec/step)\n",
            "INFO:tensorflow:global step 113020: loss = 0.3643 (0.780 sec/step)\n",
            "I0321 22:26:41.891932 140436091496320 learning.py:507] global step 113020: loss = 0.3643 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 113030: loss = 0.3754 (0.787 sec/step)\n",
            "I0321 22:26:49.776735 140436091496320 learning.py:507] global step 113030: loss = 0.3754 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 113040: loss = 0.3741 (0.881 sec/step)\n",
            "I0321 22:26:58.048327 140436091496320 learning.py:507] global step 113040: loss = 0.3741 (0.881 sec/step)\n",
            "INFO:tensorflow:global step 113050: loss = 0.3629 (0.784 sec/step)\n",
            "I0321 22:27:05.957728 140436091496320 learning.py:507] global step 113050: loss = 0.3629 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113060: loss = 0.3678 (0.799 sec/step)\n",
            "I0321 22:27:13.891413 140436091496320 learning.py:507] global step 113060: loss = 0.3678 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 113070: loss = 0.4545 (0.801 sec/step)\n",
            "I0321 22:27:21.991325 140436091496320 learning.py:507] global step 113070: loss = 0.4545 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 113080: loss = 0.3630 (0.789 sec/step)\n",
            "I0321 22:27:29.939069 140436091496320 learning.py:507] global step 113080: loss = 0.3630 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 113090: loss = 0.3708 (0.797 sec/step)\n",
            "I0321 22:27:37.870007 140436091496320 learning.py:507] global step 113090: loss = 0.3708 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 113100: loss = 0.3943 (0.790 sec/step)\n",
            "I0321 22:27:45.781748 140436091496320 learning.py:507] global step 113100: loss = 0.3943 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 113110: loss = 0.3687 (0.793 sec/step)\n",
            "I0321 22:27:53.679997 140436091496320 learning.py:507] global step 113110: loss = 0.3687 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 113120: loss = 0.3552 (0.788 sec/step)\n",
            "I0321 22:28:01.781656 140436091496320 learning.py:507] global step 113120: loss = 0.3552 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 113130: loss = 0.3589 (0.790 sec/step)\n",
            "I0321 22:28:09.964260 140436091496320 learning.py:507] global step 113130: loss = 0.3589 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 113140: loss = 0.3457 (0.807 sec/step)\n",
            "I0321 22:28:18.055155 140436091496320 learning.py:507] global step 113140: loss = 0.3457 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 113150: loss = 0.3558 (0.804 sec/step)\n",
            "I0321 22:28:25.970397 140436091496320 learning.py:507] global step 113150: loss = 0.3558 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 113160: loss = 0.3938 (0.954 sec/step)\n",
            "I0321 22:28:34.006094 140436091496320 learning.py:507] global step 113160: loss = 0.3938 (0.954 sec/step)\n",
            "INFO:tensorflow:global step 113170: loss = 0.3915 (0.785 sec/step)\n",
            "I0321 22:28:41.911308 140436091496320 learning.py:507] global step 113170: loss = 0.3915 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 113180: loss = 0.4079 (0.779 sec/step)\n",
            "I0321 22:28:50.065425 140436091496320 learning.py:507] global step 113180: loss = 0.4079 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 113190: loss = 0.3846 (1.014 sec/step)\n",
            "I0321 22:28:58.550647 140436091496320 learning.py:507] global step 113190: loss = 0.3846 (1.014 sec/step)\n",
            "INFO:tensorflow:global step 113200: loss = 0.3648 (0.787 sec/step)\n",
            "I0321 22:29:07.017591 140436091496320 learning.py:507] global step 113200: loss = 0.3648 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 113210: loss = 0.3666 (0.790 sec/step)\n",
            "I0321 22:29:15.206069 140436091496320 learning.py:507] global step 113210: loss = 0.3666 (0.790 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 113214.\n",
            "I0321 22:29:20.068422 140432184936192 supervisor.py:1050] Recording summary at step 113214.\n",
            "INFO:tensorflow:global step 113220: loss = 0.3583 (0.784 sec/step)\n",
            "I0321 22:29:24.488249 140436091496320 learning.py:507] global step 113220: loss = 0.3583 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113230: loss = 0.3423 (0.812 sec/step)\n",
            "I0321 22:29:32.433749 140436091496320 learning.py:507] global step 113230: loss = 0.3423 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 113240: loss = 0.4600 (0.812 sec/step)\n",
            "I0321 22:29:40.427938 140436091496320 learning.py:507] global step 113240: loss = 0.4600 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 113250: loss = 0.3499 (0.784 sec/step)\n",
            "I0321 22:29:48.491498 140436091496320 learning.py:507] global step 113250: loss = 0.3499 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113260: loss = 0.3594 (0.791 sec/step)\n",
            "I0321 22:29:56.588067 140436091496320 learning.py:507] global step 113260: loss = 0.3594 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 113270: loss = 0.3830 (0.803 sec/step)\n",
            "I0321 22:30:04.514311 140436091496320 learning.py:507] global step 113270: loss = 0.3830 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 113280: loss = 0.3605 (0.782 sec/step)\n",
            "I0321 22:30:12.448918 140436091496320 learning.py:507] global step 113280: loss = 0.3605 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 113290: loss = 0.3678 (0.782 sec/step)\n",
            "I0321 22:30:20.398005 140436091496320 learning.py:507] global step 113290: loss = 0.3678 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 113300: loss = 0.3675 (0.804 sec/step)\n",
            "I0321 22:30:28.462705 140436091496320 learning.py:507] global step 113300: loss = 0.3675 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 113310: loss = 0.3851 (0.780 sec/step)\n",
            "I0321 22:30:36.472698 140436091496320 learning.py:507] global step 113310: loss = 0.3851 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 113320: loss = 0.3734 (0.793 sec/step)\n",
            "I0321 22:30:44.401896 140436091496320 learning.py:507] global step 113320: loss = 0.3734 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 113330: loss = 0.3974 (0.781 sec/step)\n",
            "I0321 22:30:52.537375 140436091496320 learning.py:507] global step 113330: loss = 0.3974 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 113340: loss = 0.3751 (0.778 sec/step)\n",
            "I0321 22:31:00.454120 140436091496320 learning.py:507] global step 113340: loss = 0.3751 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 113350: loss = 0.3765 (0.779 sec/step)\n",
            "I0321 22:31:08.328066 140436091496320 learning.py:507] global step 113350: loss = 0.3765 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 113360: loss = 0.3478 (0.785 sec/step)\n",
            "I0321 22:31:16.289705 140436091496320 learning.py:507] global step 113360: loss = 0.3478 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 113370: loss = 0.3538 (0.791 sec/step)\n",
            "I0321 22:31:24.283849 140436091496320 learning.py:507] global step 113370: loss = 0.3538 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 113380: loss = 0.3655 (0.800 sec/step)\n",
            "I0321 22:31:32.234073 140436091496320 learning.py:507] global step 113380: loss = 0.3655 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 113390: loss = 0.3552 (0.968 sec/step)\n",
            "I0321 22:31:40.510162 140436091496320 learning.py:507] global step 113390: loss = 0.3552 (0.968 sec/step)\n",
            "INFO:tensorflow:global step 113400: loss = 0.3532 (0.789 sec/step)\n",
            "I0321 22:31:48.487097 140436091496320 learning.py:507] global step 113400: loss = 0.3532 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 113410: loss = 0.4181 (0.781 sec/step)\n",
            "I0321 22:31:56.703032 140436091496320 learning.py:507] global step 113410: loss = 0.4181 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 113420: loss = 0.3472 (0.797 sec/step)\n",
            "I0321 22:32:04.823702 140436091496320 learning.py:507] global step 113420: loss = 0.3472 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 113430: loss = 0.3537 (0.786 sec/step)\n",
            "I0321 22:32:12.776957 140436091496320 learning.py:507] global step 113430: loss = 0.3537 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 113440: loss = 0.3687 (0.784 sec/step)\n",
            "I0321 22:32:20.883545 140436091496320 learning.py:507] global step 113440: loss = 0.3687 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113450: loss = 0.3637 (0.818 sec/step)\n",
            "I0321 22:32:28.846000 140436091496320 learning.py:507] global step 113450: loss = 0.3637 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 113460: loss = 0.4451 (0.782 sec/step)\n",
            "I0321 22:32:36.734699 140436091496320 learning.py:507] global step 113460: loss = 0.4451 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 113470: loss = 0.3756 (0.782 sec/step)\n",
            "I0321 22:32:44.796303 140436091496320 learning.py:507] global step 113470: loss = 0.3756 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 113480: loss = 0.3687 (0.982 sec/step)\n",
            "I0321 22:32:53.231885 140436091496320 learning.py:507] global step 113480: loss = 0.3687 (0.982 sec/step)\n",
            "INFO:tensorflow:global step 113490: loss = 0.3493 (0.779 sec/step)\n",
            "I0321 22:33:01.113797 140436091496320 learning.py:507] global step 113490: loss = 0.3493 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 113500: loss = 0.3915 (0.783 sec/step)\n",
            "I0321 22:33:09.074941 140436091496320 learning.py:507] global step 113500: loss = 0.3915 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113510: loss = 0.3951 (0.898 sec/step)\n",
            "I0321 22:33:17.104462 140436091496320 learning.py:507] global step 113510: loss = 0.3951 (0.898 sec/step)\n",
            "INFO:tensorflow:global step 113520: loss = 0.4457 (0.781 sec/step)\n",
            "I0321 22:33:25.358876 140436091496320 learning.py:507] global step 113520: loss = 0.4457 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 113530: loss = 0.3566 (0.783 sec/step)\n",
            "I0321 22:33:33.353830 140436091496320 learning.py:507] global step 113530: loss = 0.3566 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113540: loss = 0.3660 (0.793 sec/step)\n",
            "I0321 22:33:41.484611 140436091496320 learning.py:507] global step 113540: loss = 0.3660 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 113550: loss = 0.3524 (0.780 sec/step)\n",
            "I0321 22:33:49.411335 140436091496320 learning.py:507] global step 113550: loss = 0.3524 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 113560: loss = 0.3638 (0.783 sec/step)\n",
            "I0321 22:33:57.417185 140436091496320 learning.py:507] global step 113560: loss = 0.3638 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113570: loss = 0.5253 (0.864 sec/step)\n",
            "I0321 22:34:05.542640 140436091496320 learning.py:507] global step 113570: loss = 0.5253 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 113580: loss = 0.3780 (0.795 sec/step)\n",
            "I0321 22:34:13.468403 140436091496320 learning.py:507] global step 113580: loss = 0.3780 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 113590: loss = 0.3788 (0.785 sec/step)\n",
            "I0321 22:34:21.464909 140436091496320 learning.py:507] global step 113590: loss = 0.3788 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 113600: loss = 0.3677 (0.783 sec/step)\n",
            "I0321 22:34:29.357526 140436091496320 learning.py:507] global step 113600: loss = 0.3677 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113610: loss = 0.3714 (0.802 sec/step)\n",
            "I0321 22:34:37.596774 140436091496320 learning.py:507] global step 113610: loss = 0.3714 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 113620: loss = 0.3698 (0.799 sec/step)\n",
            "I0321 22:34:45.536094 140436091496320 learning.py:507] global step 113620: loss = 0.3698 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 113630: loss = 0.3876 (0.805 sec/step)\n",
            "I0321 22:34:53.489889 140436091496320 learning.py:507] global step 113630: loss = 0.3876 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 113640: loss = 0.3708 (0.785 sec/step)\n",
            "I0321 22:35:01.397054 140436091496320 learning.py:507] global step 113640: loss = 0.3708 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 113650: loss = 0.3713 (0.783 sec/step)\n",
            "I0321 22:35:09.361544 140436091496320 learning.py:507] global step 113650: loss = 0.3713 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113660: loss = 0.3894 (0.783 sec/step)\n",
            "I0321 22:35:17.245482 140436091496320 learning.py:507] global step 113660: loss = 0.3894 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113670: loss = 0.4317 (0.783 sec/step)\n",
            "I0321 22:35:25.182045 140436091496320 learning.py:507] global step 113670: loss = 0.4317 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113680: loss = 0.4215 (0.787 sec/step)\n",
            "I0321 22:35:33.105712 140436091496320 learning.py:507] global step 113680: loss = 0.4215 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 113690: loss = 0.3635 (0.954 sec/step)\n",
            "I0321 22:35:41.420172 140436091496320 learning.py:507] global step 113690: loss = 0.3635 (0.954 sec/step)\n",
            "INFO:tensorflow:global step 113700: loss = 0.3974 (0.779 sec/step)\n",
            "I0321 22:35:49.329886 140436091496320 learning.py:507] global step 113700: loss = 0.3974 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 113710: loss = 0.3740 (0.780 sec/step)\n",
            "I0321 22:35:57.463007 140436091496320 learning.py:507] global step 113710: loss = 0.3740 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 113720: loss = 0.3573 (0.792 sec/step)\n",
            "I0321 22:36:05.572293 140436091496320 learning.py:507] global step 113720: loss = 0.3573 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 113730: loss = 0.3482 (0.790 sec/step)\n",
            "I0321 22:36:13.509329 140436091496320 learning.py:507] global step 113730: loss = 0.3482 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 113740: loss = 0.3922 (0.784 sec/step)\n",
            "I0321 22:36:21.417409 140436091496320 learning.py:507] global step 113740: loss = 0.3922 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113750: loss = 0.3768 (0.784 sec/step)\n",
            "I0321 22:36:29.321101 140436091496320 learning.py:507] global step 113750: loss = 0.3768 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113760: loss = 0.3535 (0.781 sec/step)\n",
            "I0321 22:36:37.288816 140436091496320 learning.py:507] global step 113760: loss = 0.3535 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 113770: loss = 0.3624 (0.785 sec/step)\n",
            "I0321 22:36:45.229649 140436091496320 learning.py:507] global step 113770: loss = 0.3624 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 113780: loss = 0.3765 (0.792 sec/step)\n",
            "I0321 22:36:53.122524 140436091496320 learning.py:507] global step 113780: loss = 0.3765 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 113790: loss = 0.3723 (0.787 sec/step)\n",
            "I0321 22:37:01.022599 140436091496320 learning.py:507] global step 113790: loss = 0.3723 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 113800: loss = 0.3651 (0.780 sec/step)\n",
            "I0321 22:37:08.986126 140436091496320 learning.py:507] global step 113800: loss = 0.3651 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 113810: loss = 0.3801 (0.924 sec/step)\n",
            "I0321 22:37:17.310201 140436091496320 learning.py:507] global step 113810: loss = 0.3801 (0.924 sec/step)\n",
            "INFO:tensorflow:global step 113820: loss = 0.3724 (0.779 sec/step)\n",
            "I0321 22:37:25.254226 140436091496320 learning.py:507] global step 113820: loss = 0.3724 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 113830: loss = 0.3812 (0.784 sec/step)\n",
            "I0321 22:37:33.141000 140436091496320 learning.py:507] global step 113830: loss = 0.3812 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113840: loss = 0.3700 (0.795 sec/step)\n",
            "I0321 22:37:41.120342 140436091496320 learning.py:507] global step 113840: loss = 0.3700 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 113850: loss = 0.3807 (0.793 sec/step)\n",
            "I0321 22:37:49.223796 140436091496320 learning.py:507] global step 113850: loss = 0.3807 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 113860: loss = 0.3609 (0.799 sec/step)\n",
            "I0321 22:37:57.133763 140436091496320 learning.py:507] global step 113860: loss = 0.3609 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 113870: loss = 0.3814 (0.779 sec/step)\n",
            "I0321 22:38:05.024590 140436091496320 learning.py:507] global step 113870: loss = 0.3814 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 113880: loss = 0.3756 (0.779 sec/step)\n",
            "I0321 22:38:12.934885 140436091496320 learning.py:507] global step 113880: loss = 0.3756 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 113890: loss = 0.4058 (0.783 sec/step)\n",
            "I0321 22:38:20.975630 140436091496320 learning.py:507] global step 113890: loss = 0.4058 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113900: loss = 0.3543 (0.902 sec/step)\n",
            "I0321 22:38:29.023489 140436091496320 learning.py:507] global step 113900: loss = 0.3543 (0.902 sec/step)\n",
            "INFO:tensorflow:global step 113910: loss = 0.3727 (0.783 sec/step)\n",
            "I0321 22:38:37.022475 140436091496320 learning.py:507] global step 113910: loss = 0.3727 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113920: loss = 0.3711 (0.793 sec/step)\n",
            "I0321 22:38:45.140760 140436091496320 learning.py:507] global step 113920: loss = 0.3711 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 113930: loss = 0.4189 (0.825 sec/step)\n",
            "I0321 22:38:53.314507 140436091496320 learning.py:507] global step 113930: loss = 0.4189 (0.825 sec/step)\n",
            "INFO:tensorflow:global step 113940: loss = 0.3686 (0.802 sec/step)\n",
            "I0321 22:39:01.600720 140436091496320 learning.py:507] global step 113940: loss = 0.3686 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 113950: loss = 0.3524 (0.783 sec/step)\n",
            "I0321 22:39:09.744387 140436091496320 learning.py:507] global step 113950: loss = 0.3524 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 113960: loss = 0.3412 (0.789 sec/step)\n",
            "I0321 22:39:17.726332 140436091496320 learning.py:507] global step 113960: loss = 0.3412 (0.789 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 22:39:18.300886 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 113961.\n",
            "I0321 22:39:20.160258 140432184936192 supervisor.py:1050] Recording summary at step 113961.\n",
            "INFO:tensorflow:global step 113970: loss = 0.3685 (0.784 sec/step)\n",
            "I0321 22:39:27.922904 140436091496320 learning.py:507] global step 113970: loss = 0.3685 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 113980: loss = 0.3630 (0.795 sec/step)\n",
            "I0321 22:39:35.870295 140436091496320 learning.py:507] global step 113980: loss = 0.3630 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 113990: loss = 0.3754 (0.781 sec/step)\n",
            "I0321 22:39:43.774472 140436091496320 learning.py:507] global step 113990: loss = 0.3754 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114000: loss = 0.3534 (0.798 sec/step)\n",
            "I0321 22:39:51.641301 140436091496320 learning.py:507] global step 114000: loss = 0.3534 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 114010: loss = 0.3561 (0.966 sec/step)\n",
            "I0321 22:39:59.742870 140436091496320 learning.py:507] global step 114010: loss = 0.3561 (0.966 sec/step)\n",
            "INFO:tensorflow:global step 114020: loss = 0.4289 (0.784 sec/step)\n",
            "I0321 22:40:07.639560 140436091496320 learning.py:507] global step 114020: loss = 0.4289 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 114030: loss = 0.3683 (0.780 sec/step)\n",
            "I0321 22:40:15.724492 140436091496320 learning.py:507] global step 114030: loss = 0.3683 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114040: loss = 0.3735 (0.780 sec/step)\n",
            "I0321 22:40:23.651497 140436091496320 learning.py:507] global step 114040: loss = 0.3735 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114050: loss = 0.3604 (0.790 sec/step)\n",
            "I0321 22:40:31.563798 140436091496320 learning.py:507] global step 114050: loss = 0.3604 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 114060: loss = 0.4614 (0.781 sec/step)\n",
            "I0321 22:40:39.845321 140436091496320 learning.py:507] global step 114060: loss = 0.4614 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114070: loss = 0.4023 (0.975 sec/step)\n",
            "I0321 22:40:47.906950 140436091496320 learning.py:507] global step 114070: loss = 0.4023 (0.975 sec/step)\n",
            "INFO:tensorflow:global step 114080: loss = 0.3458 (0.782 sec/step)\n",
            "I0321 22:40:55.970149 140436091496320 learning.py:507] global step 114080: loss = 0.3458 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114090: loss = 0.3472 (0.784 sec/step)\n",
            "I0321 22:41:03.905102 140436091496320 learning.py:507] global step 114090: loss = 0.3472 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 114100: loss = 0.3833 (0.787 sec/step)\n",
            "I0321 22:41:12.001190 140436091496320 learning.py:507] global step 114100: loss = 0.3833 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 114110: loss = 0.3486 (0.780 sec/step)\n",
            "I0321 22:41:20.081326 140436091496320 learning.py:507] global step 114110: loss = 0.3486 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114120: loss = 0.3615 (0.786 sec/step)\n",
            "I0321 22:41:28.037254 140436091496320 learning.py:507] global step 114120: loss = 0.3615 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 114130: loss = 0.3597 (0.820 sec/step)\n",
            "I0321 22:41:36.047927 140436091496320 learning.py:507] global step 114130: loss = 0.3597 (0.820 sec/step)\n",
            "INFO:tensorflow:global step 114140: loss = 0.3497 (0.781 sec/step)\n",
            "I0321 22:41:44.254426 140436091496320 learning.py:507] global step 114140: loss = 0.3497 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114150: loss = 0.3654 (0.781 sec/step)\n",
            "I0321 22:41:52.281476 140436091496320 learning.py:507] global step 114150: loss = 0.3654 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114160: loss = 0.3535 (0.780 sec/step)\n",
            "I0321 22:42:00.496641 140436091496320 learning.py:507] global step 114160: loss = 0.3535 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114170: loss = 0.3574 (0.790 sec/step)\n",
            "I0321 22:42:08.688974 140436091496320 learning.py:507] global step 114170: loss = 0.3574 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 114180: loss = 0.3761 (0.782 sec/step)\n",
            "I0321 22:42:16.572728 140436091496320 learning.py:507] global step 114180: loss = 0.3761 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114190: loss = 0.4056 (0.788 sec/step)\n",
            "I0321 22:42:24.463654 140436091496320 learning.py:507] global step 114190: loss = 0.4056 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 114200: loss = 0.3658 (0.783 sec/step)\n",
            "I0321 22:42:32.790190 140436091496320 learning.py:507] global step 114200: loss = 0.3658 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 114210: loss = 0.3804 (0.792 sec/step)\n",
            "I0321 22:42:40.837141 140436091496320 learning.py:507] global step 114210: loss = 0.3804 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 114220: loss = 0.3523 (0.808 sec/step)\n",
            "I0321 22:42:48.813933 140436091496320 learning.py:507] global step 114220: loss = 0.3523 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 114230: loss = 0.3619 (0.781 sec/step)\n",
            "I0321 22:42:56.728703 140436091496320 learning.py:507] global step 114230: loss = 0.3619 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114240: loss = 0.3594 (0.789 sec/step)\n",
            "I0321 22:43:04.621314 140436091496320 learning.py:507] global step 114240: loss = 0.3594 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 114250: loss = 0.3896 (0.803 sec/step)\n",
            "I0321 22:43:12.532823 140436091496320 learning.py:507] global step 114250: loss = 0.3896 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 114260: loss = 0.4534 (0.795 sec/step)\n",
            "I0321 22:43:20.481812 140436091496320 learning.py:507] global step 114260: loss = 0.4534 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 114270: loss = 0.3842 (0.798 sec/step)\n",
            "I0321 22:43:28.386209 140436091496320 learning.py:507] global step 114270: loss = 0.3842 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 114280: loss = 0.3748 (0.799 sec/step)\n",
            "I0321 22:43:36.476176 140436091496320 learning.py:507] global step 114280: loss = 0.3748 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 114290: loss = 0.3687 (0.784 sec/step)\n",
            "I0321 22:43:44.622393 140436091496320 learning.py:507] global step 114290: loss = 0.3687 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 114300: loss = 0.3773 (0.805 sec/step)\n",
            "I0321 22:43:52.528674 140436091496320 learning.py:507] global step 114300: loss = 0.3773 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 114310: loss = 0.3647 (0.778 sec/step)\n",
            "I0321 22:44:00.479733 140436091496320 learning.py:507] global step 114310: loss = 0.3647 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 114320: loss = 0.3695 (0.781 sec/step)\n",
            "I0321 22:44:08.351421 140436091496320 learning.py:507] global step 114320: loss = 0.3695 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114330: loss = 0.3718 (0.787 sec/step)\n",
            "I0321 22:44:16.500378 140436091496320 learning.py:507] global step 114330: loss = 0.3718 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 114340: loss = 0.4124 (0.803 sec/step)\n",
            "I0321 22:44:24.536859 140436091496320 learning.py:507] global step 114340: loss = 0.4124 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 114350: loss = 0.3609 (0.781 sec/step)\n",
            "I0321 22:44:32.469746 140436091496320 learning.py:507] global step 114350: loss = 0.3609 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114360: loss = 0.3681 (0.781 sec/step)\n",
            "I0321 22:44:40.420258 140436091496320 learning.py:507] global step 114360: loss = 0.3681 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114370: loss = 0.3660 (0.992 sec/step)\n",
            "I0321 22:44:48.559850 140436091496320 learning.py:507] global step 114370: loss = 0.3660 (0.992 sec/step)\n",
            "INFO:tensorflow:global step 114380: loss = 0.3585 (0.780 sec/step)\n",
            "I0321 22:44:56.496690 140436091496320 learning.py:507] global step 114380: loss = 0.3585 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114390: loss = 0.3750 (0.780 sec/step)\n",
            "I0321 22:45:04.414638 140436091496320 learning.py:507] global step 114390: loss = 0.3750 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114400: loss = 0.3448 (0.831 sec/step)\n",
            "I0321 22:45:12.369840 140436091496320 learning.py:507] global step 114400: loss = 0.3448 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 114410: loss = 0.3810 (0.781 sec/step)\n",
            "I0321 22:45:20.267442 140436091496320 learning.py:507] global step 114410: loss = 0.3810 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114420: loss = 0.3583 (0.793 sec/step)\n",
            "I0321 22:45:28.276476 140436091496320 learning.py:507] global step 114420: loss = 0.3583 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 114430: loss = 0.3702 (0.777 sec/step)\n",
            "I0321 22:45:36.158277 140436091496320 learning.py:507] global step 114430: loss = 0.3702 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 114440: loss = 0.3592 (0.785 sec/step)\n",
            "I0321 22:45:44.117576 140436091496320 learning.py:507] global step 114440: loss = 0.3592 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 114450: loss = 0.3503 (0.782 sec/step)\n",
            "I0321 22:45:52.011811 140436091496320 learning.py:507] global step 114450: loss = 0.3503 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114460: loss = 0.3884 (0.818 sec/step)\n",
            "I0321 22:46:00.405963 140436091496320 learning.py:507] global step 114460: loss = 0.3884 (0.818 sec/step)\n",
            "INFO:tensorflow:global step 114470: loss = 0.3618 (0.793 sec/step)\n",
            "I0321 22:46:08.438518 140436091496320 learning.py:507] global step 114470: loss = 0.3618 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 114480: loss = 0.4080 (0.785 sec/step)\n",
            "I0321 22:46:16.415600 140436091496320 learning.py:507] global step 114480: loss = 0.4080 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 114490: loss = 0.4129 (0.795 sec/step)\n",
            "I0321 22:46:24.342127 140436091496320 learning.py:507] global step 114490: loss = 0.4129 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 114500: loss = 0.3609 (0.802 sec/step)\n",
            "I0321 22:46:32.330496 140436091496320 learning.py:507] global step 114500: loss = 0.3609 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 114510: loss = 0.3534 (0.782 sec/step)\n",
            "I0321 22:46:40.235673 140436091496320 learning.py:507] global step 114510: loss = 0.3534 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114520: loss = 0.3802 (0.914 sec/step)\n",
            "I0321 22:46:48.500400 140436091496320 learning.py:507] global step 114520: loss = 0.3802 (0.914 sec/step)\n",
            "INFO:tensorflow:global step 114530: loss = 0.3679 (0.780 sec/step)\n",
            "I0321 22:46:56.363344 140436091496320 learning.py:507] global step 114530: loss = 0.3679 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114540: loss = 0.4586 (0.781 sec/step)\n",
            "I0321 22:47:04.246020 140436091496320 learning.py:507] global step 114540: loss = 0.4586 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114550: loss = 0.3623 (0.789 sec/step)\n",
            "I0321 22:47:12.376814 140436091496320 learning.py:507] global step 114550: loss = 0.3623 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 114560: loss = 0.3652 (0.784 sec/step)\n",
            "I0321 22:47:20.305570 140436091496320 learning.py:507] global step 114560: loss = 0.3652 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 114570: loss = 0.3590 (0.786 sec/step)\n",
            "I0321 22:47:28.538539 140436091496320 learning.py:507] global step 114570: loss = 0.3590 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 114580: loss = 0.3654 (0.782 sec/step)\n",
            "I0321 22:47:36.571785 140436091496320 learning.py:507] global step 114580: loss = 0.3654 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114590: loss = 0.3633 (0.780 sec/step)\n",
            "I0321 22:47:44.445878 140436091496320 learning.py:507] global step 114590: loss = 0.3633 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 114600: loss = 0.3905 (0.799 sec/step)\n",
            "I0321 22:47:52.780086 140436091496320 learning.py:507] global step 114600: loss = 0.3905 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 114610: loss = 0.3868 (0.828 sec/step)\n",
            "I0321 22:48:00.937813 140436091496320 learning.py:507] global step 114610: loss = 0.3868 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 114620: loss = 0.3526 (0.802 sec/step)\n",
            "I0321 22:48:08.963308 140436091496320 learning.py:507] global step 114620: loss = 0.3526 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 114630: loss = 0.3657 (0.787 sec/step)\n",
            "I0321 22:48:17.198411 140436091496320 learning.py:507] global step 114630: loss = 0.3657 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 114640: loss = 0.3587 (0.815 sec/step)\n",
            "I0321 22:48:25.225056 140436091496320 learning.py:507] global step 114640: loss = 0.3587 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 114650: loss = 0.3611 (0.782 sec/step)\n",
            "I0321 22:48:33.194444 140436091496320 learning.py:507] global step 114650: loss = 0.3611 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114660: loss = 0.3790 (0.785 sec/step)\n",
            "I0321 22:48:41.502997 140436091496320 learning.py:507] global step 114660: loss = 0.3790 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 114670: loss = 0.3786 (0.849 sec/step)\n",
            "I0321 22:48:49.454599 140436091496320 learning.py:507] global step 114670: loss = 0.3786 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 114680: loss = 0.4326 (0.797 sec/step)\n",
            "I0321 22:48:57.416785 140436091496320 learning.py:507] global step 114680: loss = 0.4326 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 114690: loss = 0.4050 (0.778 sec/step)\n",
            "I0321 22:49:05.429943 140436091496320 learning.py:507] global step 114690: loss = 0.4050 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 114700: loss = 0.3651 (0.920 sec/step)\n",
            "I0321 22:49:13.449619 140436091496320 learning.py:507] global step 114700: loss = 0.3651 (0.920 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 114706.\n",
            "I0321 22:49:20.352450 140432184936192 supervisor.py:1050] Recording summary at step 114706.\n",
            "INFO:tensorflow:global step 114710: loss = 0.3508 (0.795 sec/step)\n",
            "I0321 22:49:23.184589 140436091496320 learning.py:507] global step 114710: loss = 0.3508 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 114720: loss = 0.3715 (0.814 sec/step)\n",
            "I0321 22:49:31.110751 140436091496320 learning.py:507] global step 114720: loss = 0.3715 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 114730: loss = 0.4517 (0.786 sec/step)\n",
            "I0321 22:49:38.979431 140436091496320 learning.py:507] global step 114730: loss = 0.4517 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 114740: loss = 0.3675 (0.783 sec/step)\n",
            "I0321 22:49:46.963431 140436091496320 learning.py:507] global step 114740: loss = 0.3675 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 114750: loss = 0.3527 (0.781 sec/step)\n",
            "I0321 22:49:54.847782 140436091496320 learning.py:507] global step 114750: loss = 0.3527 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 114760: loss = 0.3633 (0.793 sec/step)\n",
            "I0321 22:50:02.760673 140436091496320 learning.py:507] global step 114760: loss = 0.3633 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 114770: loss = 0.3473 (0.789 sec/step)\n",
            "I0321 22:50:11.139866 140436091496320 learning.py:507] global step 114770: loss = 0.3473 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 114780: loss = 0.3960 (0.802 sec/step)\n",
            "I0321 22:50:19.168261 140436091496320 learning.py:507] global step 114780: loss = 0.3960 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 114790: loss = 0.3720 (0.786 sec/step)\n",
            "I0321 22:50:27.075646 140436091496320 learning.py:507] global step 114790: loss = 0.3720 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 114800: loss = 0.3702 (0.778 sec/step)\n",
            "I0321 22:50:35.029445 140436091496320 learning.py:507] global step 114800: loss = 0.3702 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 114810: loss = 0.3784 (0.802 sec/step)\n",
            "I0321 22:50:42.979724 140436091496320 learning.py:507] global step 114810: loss = 0.3784 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 114820: loss = 0.4100 (0.786 sec/step)\n",
            "I0321 22:50:50.907684 140436091496320 learning.py:507] global step 114820: loss = 0.4100 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 114830: loss = 0.3746 (0.782 sec/step)\n",
            "I0321 22:50:58.766640 140436091496320 learning.py:507] global step 114830: loss = 0.3746 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114840: loss = 0.3660 (0.806 sec/step)\n",
            "I0321 22:51:07.019578 140436091496320 learning.py:507] global step 114840: loss = 0.3660 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 114850: loss = 0.3759 (0.802 sec/step)\n",
            "I0321 22:51:14.957271 140436091496320 learning.py:507] global step 114850: loss = 0.3759 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 114860: loss = 0.3743 (0.784 sec/step)\n",
            "I0321 22:51:22.861441 140436091496320 learning.py:507] global step 114860: loss = 0.3743 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 114870: loss = 0.3522 (0.838 sec/step)\n",
            "I0321 22:51:30.937122 140436091496320 learning.py:507] global step 114870: loss = 0.3522 (0.838 sec/step)\n",
            "INFO:tensorflow:global step 114880: loss = 0.4031 (0.784 sec/step)\n",
            "I0321 22:51:38.889940 140436091496320 learning.py:507] global step 114880: loss = 0.4031 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 114890: loss = 0.4147 (0.786 sec/step)\n",
            "I0321 22:51:46.837974 140436091496320 learning.py:507] global step 114890: loss = 0.4147 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 114900: loss = 0.4362 (1.018 sec/step)\n",
            "I0321 22:51:54.984004 140436091496320 learning.py:507] global step 114900: loss = 0.4362 (1.018 sec/step)\n",
            "INFO:tensorflow:global step 114910: loss = 0.3692 (0.786 sec/step)\n",
            "I0321 22:52:02.868638 140436091496320 learning.py:507] global step 114910: loss = 0.3692 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 114920: loss = 0.3760 (0.810 sec/step)\n",
            "I0321 22:52:10.968811 140436091496320 learning.py:507] global step 114920: loss = 0.3760 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 114930: loss = 0.3512 (1.029 sec/step)\n",
            "I0321 22:52:19.086362 140436091496320 learning.py:507] global step 114930: loss = 0.3512 (1.029 sec/step)\n",
            "INFO:tensorflow:global step 114940: loss = 0.3661 (0.804 sec/step)\n",
            "I0321 22:52:27.272298 140436091496320 learning.py:507] global step 114940: loss = 0.3661 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 114950: loss = 0.3506 (0.785 sec/step)\n",
            "I0321 22:52:35.351972 140436091496320 learning.py:507] global step 114950: loss = 0.3506 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 114960: loss = 0.3863 (0.801 sec/step)\n",
            "I0321 22:52:43.320652 140436091496320 learning.py:507] global step 114960: loss = 0.3863 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 114970: loss = 0.4012 (0.782 sec/step)\n",
            "I0321 22:52:51.282762 140436091496320 learning.py:507] global step 114970: loss = 0.4012 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 114980: loss = 0.4673 (0.783 sec/step)\n",
            "I0321 22:52:59.168673 140436091496320 learning.py:507] global step 114980: loss = 0.4673 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 114990: loss = 0.3501 (0.971 sec/step)\n",
            "I0321 22:53:07.359925 140436091496320 learning.py:507] global step 114990: loss = 0.3501 (0.971 sec/step)\n",
            "INFO:tensorflow:global step 115000: loss = 0.3884 (0.781 sec/step)\n",
            "I0321 22:53:15.411548 140436091496320 learning.py:507] global step 115000: loss = 0.3884 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 115010: loss = 0.3501 (0.782 sec/step)\n",
            "I0321 22:53:23.340089 140436091496320 learning.py:507] global step 115010: loss = 0.3501 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 115020: loss = 0.3512 (0.814 sec/step)\n",
            "I0321 22:53:31.243836 140436091496320 learning.py:507] global step 115020: loss = 0.3512 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 115030: loss = 0.3510 (0.783 sec/step)\n",
            "I0321 22:53:39.260941 140436091496320 learning.py:507] global step 115030: loss = 0.3510 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115040: loss = 0.3587 (0.799 sec/step)\n",
            "I0321 22:53:47.181657 140436091496320 learning.py:507] global step 115040: loss = 0.3587 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 115050: loss = 0.3574 (0.936 sec/step)\n",
            "I0321 22:53:55.252636 140436091496320 learning.py:507] global step 115050: loss = 0.3574 (0.936 sec/step)\n",
            "INFO:tensorflow:global step 115060: loss = 0.3553 (0.787 sec/step)\n",
            "I0321 22:54:03.165030 140436091496320 learning.py:507] global step 115060: loss = 0.3553 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 115070: loss = 0.3849 (0.801 sec/step)\n",
            "I0321 22:54:11.089341 140436091496320 learning.py:507] global step 115070: loss = 0.3849 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 115080: loss = 0.3639 (0.878 sec/step)\n",
            "I0321 22:54:19.480465 140436091496320 learning.py:507] global step 115080: loss = 0.3639 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 115090: loss = 0.3838 (0.785 sec/step)\n",
            "I0321 22:54:27.392936 140436091496320 learning.py:507] global step 115090: loss = 0.3838 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 115100: loss = 0.3535 (0.795 sec/step)\n",
            "I0321 22:54:35.382844 140436091496320 learning.py:507] global step 115100: loss = 0.3535 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 115110: loss = 0.3736 (0.783 sec/step)\n",
            "I0321 22:54:43.264140 140436091496320 learning.py:507] global step 115110: loss = 0.3736 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115120: loss = 0.3790 (0.797 sec/step)\n",
            "I0321 22:54:51.647182 140436091496320 learning.py:507] global step 115120: loss = 0.3790 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 115130: loss = 0.3576 (0.793 sec/step)\n",
            "I0321 22:54:59.553743 140436091496320 learning.py:507] global step 115130: loss = 0.3576 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 115140: loss = 0.3543 (0.804 sec/step)\n",
            "I0321 22:55:07.483096 140436091496320 learning.py:507] global step 115140: loss = 0.3543 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 115150: loss = 0.4646 (0.781 sec/step)\n",
            "I0321 22:55:15.419029 140436091496320 learning.py:507] global step 115150: loss = 0.4646 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 115160: loss = 0.3705 (0.782 sec/step)\n",
            "I0321 22:55:23.342448 140436091496320 learning.py:507] global step 115160: loss = 0.3705 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 115170: loss = 0.4198 (0.855 sec/step)\n",
            "I0321 22:55:31.404093 140436091496320 learning.py:507] global step 115170: loss = 0.4198 (0.855 sec/step)\n",
            "INFO:tensorflow:global step 115180: loss = 0.3673 (0.804 sec/step)\n",
            "I0321 22:55:39.328862 140436091496320 learning.py:507] global step 115180: loss = 0.3673 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 115190: loss = 0.3648 (0.785 sec/step)\n",
            "I0321 22:55:47.211163 140436091496320 learning.py:507] global step 115190: loss = 0.3648 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 115200: loss = 0.3812 (0.807 sec/step)\n",
            "I0321 22:55:55.124089 140436091496320 learning.py:507] global step 115200: loss = 0.3812 (0.807 sec/step)\n",
            "INFO:tensorflow:global step 115210: loss = 0.3684 (0.781 sec/step)\n",
            "I0321 22:56:03.176603 140436091496320 learning.py:507] global step 115210: loss = 0.3684 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 115220: loss = 0.3629 (0.783 sec/step)\n",
            "I0321 22:56:11.319678 140436091496320 learning.py:507] global step 115220: loss = 0.3629 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115230: loss = 0.3514 (0.795 sec/step)\n",
            "I0321 22:56:19.508665 140436091496320 learning.py:507] global step 115230: loss = 0.3514 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 115240: loss = 0.3793 (0.782 sec/step)\n",
            "I0321 22:56:27.419496 140436091496320 learning.py:507] global step 115240: loss = 0.3793 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 115250: loss = 0.4021 (0.780 sec/step)\n",
            "I0321 22:56:35.455296 140436091496320 learning.py:507] global step 115250: loss = 0.4021 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 115260: loss = 0.3519 (0.777 sec/step)\n",
            "I0321 22:56:43.362717 140436091496320 learning.py:507] global step 115260: loss = 0.3519 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 115270: loss = 0.3545 (0.796 sec/step)\n",
            "I0321 22:56:51.639069 140436091496320 learning.py:507] global step 115270: loss = 0.3545 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 115280: loss = 0.3500 (0.779 sec/step)\n",
            "I0321 22:56:59.838507 140436091496320 learning.py:507] global step 115280: loss = 0.3500 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 115290: loss = 0.3660 (0.816 sec/step)\n",
            "I0321 22:57:07.775525 140436091496320 learning.py:507] global step 115290: loss = 0.3660 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 115300: loss = 0.3563 (0.784 sec/step)\n",
            "I0321 22:57:16.028808 140436091496320 learning.py:507] global step 115300: loss = 0.3563 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 115310: loss = 0.4253 (0.797 sec/step)\n",
            "I0321 22:57:23.907069 140436091496320 learning.py:507] global step 115310: loss = 0.4253 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 115320: loss = 0.3536 (0.791 sec/step)\n",
            "I0321 22:57:31.874354 140436091496320 learning.py:507] global step 115320: loss = 0.3536 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 115330: loss = 0.3748 (0.783 sec/step)\n",
            "I0321 22:57:39.785710 140436091496320 learning.py:507] global step 115330: loss = 0.3748 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115340: loss = 0.3752 (0.781 sec/step)\n",
            "I0321 22:57:47.687993 140436091496320 learning.py:507] global step 115340: loss = 0.3752 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 115350: loss = 0.3813 (0.941 sec/step)\n",
            "I0321 22:57:55.981795 140436091496320 learning.py:507] global step 115350: loss = 0.3813 (0.941 sec/step)\n",
            "INFO:tensorflow:global step 115360: loss = 0.3472 (0.805 sec/step)\n",
            "I0321 22:58:03.910169 140436091496320 learning.py:507] global step 115360: loss = 0.3472 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 115370: loss = 0.3711 (0.780 sec/step)\n",
            "I0321 22:58:11.824366 140436091496320 learning.py:507] global step 115370: loss = 0.3711 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 115380: loss = 0.3593 (0.778 sec/step)\n",
            "I0321 22:58:20.012693 140436091496320 learning.py:507] global step 115380: loss = 0.3593 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 115390: loss = 0.3652 (0.784 sec/step)\n",
            "I0321 22:58:27.924775 140436091496320 learning.py:507] global step 115390: loss = 0.3652 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 115400: loss = 0.3642 (0.792 sec/step)\n",
            "I0321 22:58:36.009636 140436091496320 learning.py:507] global step 115400: loss = 0.3642 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 115410: loss = 0.3733 (0.781 sec/step)\n",
            "I0321 22:58:44.105401 140436091496320 learning.py:507] global step 115410: loss = 0.3733 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 115420: loss = 0.3342 (0.794 sec/step)\n",
            "I0321 22:58:52.021265 140436091496320 learning.py:507] global step 115420: loss = 0.3342 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 115430: loss = 0.3707 (0.790 sec/step)\n",
            "I0321 22:59:00.311034 140436091496320 learning.py:507] global step 115430: loss = 0.3707 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 115440: loss = 0.3523 (0.804 sec/step)\n",
            "I0321 22:59:08.469896 140436091496320 learning.py:507] global step 115440: loss = 0.3523 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 115450: loss = 0.4217 (0.781 sec/step)\n",
            "I0321 22:59:16.434401 140436091496320 learning.py:507] global step 115450: loss = 0.4217 (0.781 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 22:59:18.302314 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 115453.\n",
            "I0321 22:59:20.635979 140432184936192 supervisor.py:1050] Recording summary at step 115453.\n",
            "INFO:tensorflow:global step 115460: loss = 0.3762 (0.791 sec/step)\n",
            "I0321 22:59:26.582926 140436091496320 learning.py:507] global step 115460: loss = 0.3762 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 115470: loss = 0.3546 (0.780 sec/step)\n",
            "I0321 22:59:34.747647 140436091496320 learning.py:507] global step 115470: loss = 0.3546 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 115480: loss = 0.3534 (0.782 sec/step)\n",
            "I0321 22:59:42.772414 140436091496320 learning.py:507] global step 115480: loss = 0.3534 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 115490: loss = 0.3705 (0.824 sec/step)\n",
            "I0321 22:59:50.688429 140436091496320 learning.py:507] global step 115490: loss = 0.3705 (0.824 sec/step)\n",
            "INFO:tensorflow:global step 115500: loss = 0.3522 (0.790 sec/step)\n",
            "I0321 22:59:58.691344 140436091496320 learning.py:507] global step 115500: loss = 0.3522 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 115510: loss = 0.3636 (0.783 sec/step)\n",
            "I0321 23:00:06.842041 140436091496320 learning.py:507] global step 115510: loss = 0.3636 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115520: loss = 0.3870 (0.802 sec/step)\n",
            "I0321 23:00:14.827221 140436091496320 learning.py:507] global step 115520: loss = 0.3870 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 115530: loss = 0.4105 (0.798 sec/step)\n",
            "I0321 23:00:22.943786 140436091496320 learning.py:507] global step 115530: loss = 0.4105 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 115540: loss = 0.3845 (0.793 sec/step)\n",
            "I0321 23:00:31.106618 140436091496320 learning.py:507] global step 115540: loss = 0.3845 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 115550: loss = 0.3567 (0.815 sec/step)\n",
            "I0321 23:00:39.037807 140436091496320 learning.py:507] global step 115550: loss = 0.3567 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 115560: loss = 0.3599 (0.799 sec/step)\n",
            "I0321 23:00:47.151314 140436091496320 learning.py:507] global step 115560: loss = 0.3599 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 115570: loss = 0.3596 (0.802 sec/step)\n",
            "I0321 23:00:55.271916 140436091496320 learning.py:507] global step 115570: loss = 0.3596 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 115580: loss = 0.3906 (0.954 sec/step)\n",
            "I0321 23:01:03.553898 140436091496320 learning.py:507] global step 115580: loss = 0.3906 (0.954 sec/step)\n",
            "INFO:tensorflow:global step 115590: loss = 0.3413 (0.786 sec/step)\n",
            "I0321 23:01:11.427670 140436091496320 learning.py:507] global step 115590: loss = 0.3413 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 115600: loss = 0.3694 (0.789 sec/step)\n",
            "I0321 23:01:19.325247 140436091496320 learning.py:507] global step 115600: loss = 0.3694 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 115610: loss = 0.4344 (0.802 sec/step)\n",
            "I0321 23:01:27.205229 140436091496320 learning.py:507] global step 115610: loss = 0.4344 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 115620: loss = 0.3650 (0.783 sec/step)\n",
            "I0321 23:01:35.068883 140436091496320 learning.py:507] global step 115620: loss = 0.3650 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115630: loss = 0.3620 (0.783 sec/step)\n",
            "I0321 23:01:43.065511 140436091496320 learning.py:507] global step 115630: loss = 0.3620 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115640: loss = 0.3561 (0.802 sec/step)\n",
            "I0321 23:01:50.998176 140436091496320 learning.py:507] global step 115640: loss = 0.3561 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 115650: loss = 0.3461 (0.784 sec/step)\n",
            "I0321 23:01:59.121517 140436091496320 learning.py:507] global step 115650: loss = 0.3461 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 115660: loss = 0.3407 (0.785 sec/step)\n",
            "I0321 23:02:07.069744 140436091496320 learning.py:507] global step 115660: loss = 0.3407 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 115670: loss = 0.3562 (0.810 sec/step)\n",
            "I0321 23:02:15.020866 140436091496320 learning.py:507] global step 115670: loss = 0.3562 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 115680: loss = 0.3651 (0.795 sec/step)\n",
            "I0321 23:02:22.991427 140436091496320 learning.py:507] global step 115680: loss = 0.3651 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 115690: loss = 0.3620 (0.779 sec/step)\n",
            "I0321 23:02:31.154644 140436091496320 learning.py:507] global step 115690: loss = 0.3620 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 115700: loss = 0.3775 (1.019 sec/step)\n",
            "I0321 23:02:39.316351 140436091496320 learning.py:507] global step 115700: loss = 0.3775 (1.019 sec/step)\n",
            "INFO:tensorflow:global step 115710: loss = 0.3401 (0.785 sec/step)\n",
            "I0321 23:02:47.236345 140436091496320 learning.py:507] global step 115710: loss = 0.3401 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 115720: loss = 0.3693 (0.783 sec/step)\n",
            "I0321 23:02:55.168275 140436091496320 learning.py:507] global step 115720: loss = 0.3693 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115730: loss = 0.3311 (0.837 sec/step)\n",
            "I0321 23:03:03.108294 140436091496320 learning.py:507] global step 115730: loss = 0.3311 (0.837 sec/step)\n",
            "INFO:tensorflow:global step 115740: loss = 0.3832 (0.780 sec/step)\n",
            "I0321 23:03:11.002789 140436091496320 learning.py:507] global step 115740: loss = 0.3832 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 115750: loss = 0.3590 (0.816 sec/step)\n",
            "I0321 23:03:18.986511 140436091496320 learning.py:507] global step 115750: loss = 0.3590 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 115760: loss = 0.3413 (0.802 sec/step)\n",
            "I0321 23:03:26.991807 140436091496320 learning.py:507] global step 115760: loss = 0.3413 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 115770: loss = 0.3547 (0.793 sec/step)\n",
            "I0321 23:03:34.940594 140436091496320 learning.py:507] global step 115770: loss = 0.3547 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 115780: loss = 0.4112 (0.781 sec/step)\n",
            "I0321 23:03:42.864391 140436091496320 learning.py:507] global step 115780: loss = 0.4112 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 115790: loss = 0.3516 (0.808 sec/step)\n",
            "I0321 23:03:51.126242 140436091496320 learning.py:507] global step 115790: loss = 0.3516 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 115800: loss = 0.3745 (0.780 sec/step)\n",
            "I0321 23:03:59.035694 140436091496320 learning.py:507] global step 115800: loss = 0.3745 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 115810: loss = 0.3609 (0.794 sec/step)\n",
            "I0321 23:04:07.121155 140436091496320 learning.py:507] global step 115810: loss = 0.3609 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 115820: loss = 0.3319 (0.793 sec/step)\n",
            "I0321 23:04:15.113397 140436091496320 learning.py:507] global step 115820: loss = 0.3319 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 115830: loss = 0.3650 (0.787 sec/step)\n",
            "I0321 23:04:23.050511 140436091496320 learning.py:507] global step 115830: loss = 0.3650 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 115840: loss = 0.3616 (0.785 sec/step)\n",
            "I0321 23:04:31.057193 140436091496320 learning.py:507] global step 115840: loss = 0.3616 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 115850: loss = 0.4738 (0.817 sec/step)\n",
            "I0321 23:04:39.048989 140436091496320 learning.py:507] global step 115850: loss = 0.4738 (0.817 sec/step)\n",
            "INFO:tensorflow:global step 115860: loss = 0.3919 (0.777 sec/step)\n",
            "I0321 23:04:46.987075 140436091496320 learning.py:507] global step 115860: loss = 0.3919 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 115870: loss = 0.3564 (0.798 sec/step)\n",
            "I0321 23:04:54.910748 140436091496320 learning.py:507] global step 115870: loss = 0.3564 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 115880: loss = 0.3722 (0.923 sec/step)\n",
            "I0321 23:05:03.166430 140436091496320 learning.py:507] global step 115880: loss = 0.3722 (0.923 sec/step)\n",
            "INFO:tensorflow:global step 115890: loss = 0.3710 (0.799 sec/step)\n",
            "I0321 23:05:11.465853 140436091496320 learning.py:507] global step 115890: loss = 0.3710 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 115900: loss = 0.3793 (0.781 sec/step)\n",
            "I0321 23:05:19.496520 140436091496320 learning.py:507] global step 115900: loss = 0.3793 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 115910: loss = 0.3923 (0.786 sec/step)\n",
            "I0321 23:05:27.406373 140436091496320 learning.py:507] global step 115910: loss = 0.3923 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 115920: loss = 0.3852 (0.782 sec/step)\n",
            "I0321 23:05:35.575525 140436091496320 learning.py:507] global step 115920: loss = 0.3852 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 115930: loss = 0.3898 (0.783 sec/step)\n",
            "I0321 23:05:43.466761 140436091496320 learning.py:507] global step 115930: loss = 0.3898 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 115940: loss = 0.3725 (0.806 sec/step)\n",
            "I0321 23:05:51.699873 140436091496320 learning.py:507] global step 115940: loss = 0.3725 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 115950: loss = 0.3638 (0.812 sec/step)\n",
            "I0321 23:05:59.617984 140436091496320 learning.py:507] global step 115950: loss = 0.3638 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 115960: loss = 0.3685 (0.797 sec/step)\n",
            "I0321 23:06:07.489973 140436091496320 learning.py:507] global step 115960: loss = 0.3685 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 115970: loss = 0.3466 (0.809 sec/step)\n",
            "I0321 23:06:15.425518 140436091496320 learning.py:507] global step 115970: loss = 0.3466 (0.809 sec/step)\n",
            "INFO:tensorflow:global step 115980: loss = 0.3813 (0.793 sec/step)\n",
            "I0321 23:06:23.384527 140436091496320 learning.py:507] global step 115980: loss = 0.3813 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 115990: loss = 0.3647 (0.783 sec/step)\n",
            "I0321 23:06:31.858941 140436091496320 learning.py:507] global step 115990: loss = 0.3647 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116000: loss = 0.3725 (0.800 sec/step)\n",
            "I0321 23:06:39.919533 140436091496320 learning.py:507] global step 116000: loss = 0.3725 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 116010: loss = 0.4347 (0.789 sec/step)\n",
            "I0321 23:06:47.892398 140436091496320 learning.py:507] global step 116010: loss = 0.4347 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 116020: loss = 0.3899 (0.781 sec/step)\n",
            "I0321 23:06:55.821045 140436091496320 learning.py:507] global step 116020: loss = 0.3899 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 116030: loss = 0.3626 (0.778 sec/step)\n",
            "I0321 23:07:03.911437 140436091496320 learning.py:507] global step 116030: loss = 0.3626 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 116040: loss = 0.3708 (0.794 sec/step)\n",
            "I0321 23:07:11.876818 140436091496320 learning.py:507] global step 116040: loss = 0.3708 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 116050: loss = 0.3585 (0.789 sec/step)\n",
            "I0321 23:07:19.790998 140436091496320 learning.py:507] global step 116050: loss = 0.3585 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 116060: loss = 0.3784 (0.804 sec/step)\n",
            "I0321 23:07:27.727876 140436091496320 learning.py:507] global step 116060: loss = 0.3784 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 116070: loss = 0.3660 (0.777 sec/step)\n",
            "I0321 23:07:35.658285 140436091496320 learning.py:507] global step 116070: loss = 0.3660 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 116080: loss = 0.3759 (0.783 sec/step)\n",
            "I0321 23:07:43.581863 140436091496320 learning.py:507] global step 116080: loss = 0.3759 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116090: loss = 0.3631 (1.079 sec/step)\n",
            "I0321 23:07:51.839945 140436091496320 learning.py:507] global step 116090: loss = 0.3631 (1.079 sec/step)\n",
            "INFO:tensorflow:global step 116100: loss = 0.3559 (0.810 sec/step)\n",
            "I0321 23:07:59.755666 140436091496320 learning.py:507] global step 116100: loss = 0.3559 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 116110: loss = 0.3720 (0.783 sec/step)\n",
            "I0321 23:08:07.647694 140436091496320 learning.py:507] global step 116110: loss = 0.3720 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116120: loss = 0.3587 (1.030 sec/step)\n",
            "I0321 23:08:16.034932 140436091496320 learning.py:507] global step 116120: loss = 0.3587 (1.030 sec/step)\n",
            "INFO:tensorflow:global step 116130: loss = 0.3878 (0.796 sec/step)\n",
            "I0321 23:08:23.980652 140436091496320 learning.py:507] global step 116130: loss = 0.3878 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 116140: loss = 0.3641 (0.782 sec/step)\n",
            "I0321 23:08:31.861286 140436091496320 learning.py:507] global step 116140: loss = 0.3641 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116150: loss = 0.3722 (0.786 sec/step)\n",
            "I0321 23:08:39.722730 140436091496320 learning.py:507] global step 116150: loss = 0.3722 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 116160: loss = 0.3590 (0.781 sec/step)\n",
            "I0321 23:08:47.640471 140436091496320 learning.py:507] global step 116160: loss = 0.3590 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 116170: loss = 0.3965 (0.795 sec/step)\n",
            "I0321 23:08:55.665129 140436091496320 learning.py:507] global step 116170: loss = 0.3965 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 116180: loss = 0.3582 (0.802 sec/step)\n",
            "I0321 23:09:03.617464 140436091496320 learning.py:507] global step 116180: loss = 0.3582 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 116190: loss = 0.3794 (0.799 sec/step)\n",
            "I0321 23:09:11.688386 140436091496320 learning.py:507] global step 116190: loss = 0.3794 (0.799 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 116199.\n",
            "I0321 23:09:20.356681 140432184936192 supervisor.py:1050] Recording summary at step 116199.\n",
            "INFO:tensorflow:global step 116200: loss = 0.3907 (1.293 sec/step)\n",
            "I0321 23:09:21.216732 140436091496320 learning.py:507] global step 116200: loss = 0.3907 (1.293 sec/step)\n",
            "INFO:tensorflow:global step 116210: loss = 0.3471 (0.786 sec/step)\n",
            "I0321 23:09:29.415116 140436091496320 learning.py:507] global step 116210: loss = 0.3471 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 116220: loss = 0.3772 (0.782 sec/step)\n",
            "I0321 23:09:37.532725 140436091496320 learning.py:507] global step 116220: loss = 0.3772 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116230: loss = 0.3634 (0.816 sec/step)\n",
            "I0321 23:09:45.684223 140436091496320 learning.py:507] global step 116230: loss = 0.3634 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 116240: loss = 0.3941 (0.783 sec/step)\n",
            "I0321 23:09:53.816838 140436091496320 learning.py:507] global step 116240: loss = 0.3941 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116250: loss = 0.3620 (0.799 sec/step)\n",
            "I0321 23:10:02.004177 140436091496320 learning.py:507] global step 116250: loss = 0.3620 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 116260: loss = 0.3510 (0.793 sec/step)\n",
            "I0321 23:10:09.938200 140436091496320 learning.py:507] global step 116260: loss = 0.3510 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 116270: loss = 0.3908 (0.782 sec/step)\n",
            "I0321 23:10:18.028928 140436091496320 learning.py:507] global step 116270: loss = 0.3908 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116280: loss = 0.3458 (0.782 sec/step)\n",
            "I0321 23:10:25.961139 140436091496320 learning.py:507] global step 116280: loss = 0.3458 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116290: loss = 0.3690 (0.971 sec/step)\n",
            "I0321 23:10:34.114742 140436091496320 learning.py:507] global step 116290: loss = 0.3690 (0.971 sec/step)\n",
            "INFO:tensorflow:global step 116300: loss = 0.3686 (0.781 sec/step)\n",
            "I0321 23:10:41.995813 140436091496320 learning.py:507] global step 116300: loss = 0.3686 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 116310: loss = 0.3755 (0.796 sec/step)\n",
            "I0321 23:10:50.043464 140436091496320 learning.py:507] global step 116310: loss = 0.3755 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 116320: loss = 0.3703 (0.799 sec/step)\n",
            "I0321 23:10:57.993532 140436091496320 learning.py:507] global step 116320: loss = 0.3703 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 116330: loss = 0.3601 (0.790 sec/step)\n",
            "I0321 23:11:06.366122 140436091496320 learning.py:507] global step 116330: loss = 0.3601 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 116340: loss = 0.3688 (0.783 sec/step)\n",
            "I0321 23:11:14.514209 140436091496320 learning.py:507] global step 116340: loss = 0.3688 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116350: loss = 0.3985 (0.782 sec/step)\n",
            "I0321 23:11:22.583196 140436091496320 learning.py:507] global step 116350: loss = 0.3985 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116360: loss = 0.3657 (0.785 sec/step)\n",
            "I0321 23:11:30.470029 140436091496320 learning.py:507] global step 116360: loss = 0.3657 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 116370: loss = 0.3447 (0.788 sec/step)\n",
            "I0321 23:11:38.476422 140436091496320 learning.py:507] global step 116370: loss = 0.3447 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 116380: loss = 0.3514 (0.802 sec/step)\n",
            "I0321 23:11:46.614509 140436091496320 learning.py:507] global step 116380: loss = 0.3514 (0.802 sec/step)\n",
            "INFO:tensorflow:global step 116390: loss = 0.3892 (0.791 sec/step)\n",
            "I0321 23:11:54.505870 140436091496320 learning.py:507] global step 116390: loss = 0.3892 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 116400: loss = 0.3697 (0.791 sec/step)\n",
            "I0321 23:12:02.734269 140436091496320 learning.py:507] global step 116400: loss = 0.3697 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 116410: loss = 0.3603 (0.935 sec/step)\n",
            "I0321 23:12:10.798452 140436091496320 learning.py:507] global step 116410: loss = 0.3603 (0.935 sec/step)\n",
            "INFO:tensorflow:global step 116420: loss = 0.3682 (0.782 sec/step)\n",
            "I0321 23:12:18.653860 140436091496320 learning.py:507] global step 116420: loss = 0.3682 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116430: loss = 0.3682 (0.786 sec/step)\n",
            "I0321 23:12:26.643009 140436091496320 learning.py:507] global step 116430: loss = 0.3682 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 116440: loss = 0.3665 (0.867 sec/step)\n",
            "I0321 23:12:34.788326 140436091496320 learning.py:507] global step 116440: loss = 0.3665 (0.867 sec/step)\n",
            "INFO:tensorflow:global step 116450: loss = 0.3529 (0.789 sec/step)\n",
            "I0321 23:12:42.718779 140436091496320 learning.py:507] global step 116450: loss = 0.3529 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 116460: loss = 0.3849 (0.793 sec/step)\n",
            "I0321 23:12:50.646211 140436091496320 learning.py:507] global step 116460: loss = 0.3849 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 116470: loss = 0.3685 (0.787 sec/step)\n",
            "I0321 23:12:58.574469 140436091496320 learning.py:507] global step 116470: loss = 0.3685 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 116480: loss = 0.3607 (0.780 sec/step)\n",
            "I0321 23:13:06.507548 140436091496320 learning.py:507] global step 116480: loss = 0.3607 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 116490: loss = 0.3823 (0.790 sec/step)\n",
            "I0321 23:13:14.743073 140436091496320 learning.py:507] global step 116490: loss = 0.3823 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 116500: loss = 0.3772 (0.912 sec/step)\n",
            "I0321 23:13:23.020796 140436091496320 learning.py:507] global step 116500: loss = 0.3772 (0.912 sec/step)\n",
            "INFO:tensorflow:global step 116510: loss = 0.3607 (0.798 sec/step)\n",
            "I0321 23:13:31.297095 140436091496320 learning.py:507] global step 116510: loss = 0.3607 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 116520: loss = 0.3637 (0.785 sec/step)\n",
            "I0321 23:13:39.482709 140436091496320 learning.py:507] global step 116520: loss = 0.3637 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 116530: loss = 0.3579 (0.983 sec/step)\n",
            "I0321 23:13:47.737012 140436091496320 learning.py:507] global step 116530: loss = 0.3579 (0.983 sec/step)\n",
            "INFO:tensorflow:global step 116540: loss = 0.3453 (0.782 sec/step)\n",
            "I0321 23:13:55.693529 140436091496320 learning.py:507] global step 116540: loss = 0.3453 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116550: loss = 0.3913 (0.786 sec/step)\n",
            "I0321 23:14:03.844258 140436091496320 learning.py:507] global step 116550: loss = 0.3913 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 116560: loss = 0.3727 (0.791 sec/step)\n",
            "I0321 23:14:11.976068 140436091496320 learning.py:507] global step 116560: loss = 0.3727 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 116570: loss = 0.3570 (0.786 sec/step)\n",
            "I0321 23:14:19.921196 140436091496320 learning.py:507] global step 116570: loss = 0.3570 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 116580: loss = 0.3653 (0.784 sec/step)\n",
            "I0321 23:14:27.829808 140436091496320 learning.py:507] global step 116580: loss = 0.3653 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 116590: loss = 0.3573 (0.789 sec/step)\n",
            "I0321 23:14:35.809072 140436091496320 learning.py:507] global step 116590: loss = 0.3573 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 116600: loss = 0.3502 (0.791 sec/step)\n",
            "I0321 23:14:43.809699 140436091496320 learning.py:507] global step 116600: loss = 0.3502 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 116610: loss = 0.3584 (0.796 sec/step)\n",
            "I0321 23:14:51.660995 140436091496320 learning.py:507] global step 116610: loss = 0.3584 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 116620: loss = 0.3972 (0.916 sec/step)\n",
            "I0321 23:14:59.771428 140436091496320 learning.py:507] global step 116620: loss = 0.3972 (0.916 sec/step)\n",
            "INFO:tensorflow:global step 116630: loss = 0.3852 (0.785 sec/step)\n",
            "I0321 23:15:07.785463 140436091496320 learning.py:507] global step 116630: loss = 0.3852 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 116640: loss = 0.4004 (0.780 sec/step)\n",
            "I0321 23:15:15.685714 140436091496320 learning.py:507] global step 116640: loss = 0.4004 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 116650: loss = 0.3522 (0.806 sec/step)\n",
            "I0321 23:15:23.597497 140436091496320 learning.py:507] global step 116650: loss = 0.3522 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 116660: loss = 0.3687 (0.791 sec/step)\n",
            "I0321 23:15:31.668036 140436091496320 learning.py:507] global step 116660: loss = 0.3687 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 116670: loss = 0.3548 (0.781 sec/step)\n",
            "I0321 23:15:39.541026 140436091496320 learning.py:507] global step 116670: loss = 0.3548 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 116680: loss = 0.4077 (0.833 sec/step)\n",
            "I0321 23:15:47.535099 140436091496320 learning.py:507] global step 116680: loss = 0.4077 (0.833 sec/step)\n",
            "INFO:tensorflow:global step 116690: loss = 0.3627 (0.788 sec/step)\n",
            "I0321 23:15:55.455095 140436091496320 learning.py:507] global step 116690: loss = 0.3627 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 116700: loss = 0.4377 (0.783 sec/step)\n",
            "I0321 23:16:03.562249 140436091496320 learning.py:507] global step 116700: loss = 0.4377 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116710: loss = 0.4725 (0.956 sec/step)\n",
            "I0321 23:16:11.612044 140436091496320 learning.py:507] global step 116710: loss = 0.4725 (0.956 sec/step)\n",
            "INFO:tensorflow:global step 116720: loss = 0.4048 (0.783 sec/step)\n",
            "I0321 23:16:19.684916 140436091496320 learning.py:507] global step 116720: loss = 0.4048 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116730: loss = 0.3830 (0.784 sec/step)\n",
            "I0321 23:16:27.715305 140436091496320 learning.py:507] global step 116730: loss = 0.3830 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 116740: loss = 0.3759 (0.803 sec/step)\n",
            "I0321 23:16:35.667361 140436091496320 learning.py:507] global step 116740: loss = 0.3759 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 116750: loss = 0.4022 (0.801 sec/step)\n",
            "I0321 23:16:43.773542 140436091496320 learning.py:507] global step 116750: loss = 0.4022 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 116760: loss = 0.3837 (0.783 sec/step)\n",
            "I0321 23:16:51.706264 140436091496320 learning.py:507] global step 116760: loss = 0.3837 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116770: loss = 0.3662 (0.791 sec/step)\n",
            "I0321 23:16:59.600923 140436091496320 learning.py:507] global step 116770: loss = 0.3662 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 116780: loss = 0.3943 (0.786 sec/step)\n",
            "I0321 23:17:07.510140 140436091496320 learning.py:507] global step 116780: loss = 0.3943 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 116790: loss = 0.3722 (0.782 sec/step)\n",
            "I0321 23:17:15.573842 140436091496320 learning.py:507] global step 116790: loss = 0.3722 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 116800: loss = 0.3695 (0.797 sec/step)\n",
            "I0321 23:17:23.549351 140436091496320 learning.py:507] global step 116800: loss = 0.3695 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 116810: loss = 0.3573 (0.784 sec/step)\n",
            "I0321 23:17:31.580557 140436091496320 learning.py:507] global step 116810: loss = 0.3573 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 116820: loss = 0.3493 (0.781 sec/step)\n",
            "I0321 23:17:39.600826 140436091496320 learning.py:507] global step 116820: loss = 0.3493 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 116830: loss = 0.3653 (0.781 sec/step)\n",
            "I0321 23:17:47.544756 140436091496320 learning.py:507] global step 116830: loss = 0.3653 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 116840: loss = 0.3669 (0.784 sec/step)\n",
            "I0321 23:17:55.690669 140436091496320 learning.py:507] global step 116840: loss = 0.3669 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 116850: loss = 0.3865 (0.797 sec/step)\n",
            "I0321 23:18:03.668566 140436091496320 learning.py:507] global step 116850: loss = 0.3865 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 116860: loss = 0.3785 (0.790 sec/step)\n",
            "I0321 23:18:11.594695 140436091496320 learning.py:507] global step 116860: loss = 0.3785 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 116870: loss = 0.3498 (0.784 sec/step)\n",
            "I0321 23:18:19.553354 140436091496320 learning.py:507] global step 116870: loss = 0.3498 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 116880: loss = 0.3537 (0.779 sec/step)\n",
            "I0321 23:18:27.451297 140436091496320 learning.py:507] global step 116880: loss = 0.3537 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 116890: loss = 0.3815 (0.784 sec/step)\n",
            "I0321 23:18:35.463667 140436091496320 learning.py:507] global step 116890: loss = 0.3815 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 116900: loss = 0.3640 (0.784 sec/step)\n",
            "I0321 23:18:43.394436 140436091496320 learning.py:507] global step 116900: loss = 0.3640 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 116910: loss = 0.3485 (0.781 sec/step)\n",
            "I0321 23:18:51.465026 140436091496320 learning.py:507] global step 116910: loss = 0.3485 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 116920: loss = 0.3606 (0.785 sec/step)\n",
            "I0321 23:18:59.477471 140436091496320 learning.py:507] global step 116920: loss = 0.3606 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 116930: loss = 0.3673 (0.783 sec/step)\n",
            "I0321 23:19:07.392434 140436091496320 learning.py:507] global step 116930: loss = 0.3673 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 116940: loss = 0.3462 (0.783 sec/step)\n",
            "I0321 23:19:15.442423 140436091496320 learning.py:507] global step 116940: loss = 0.3462 (0.783 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 23:19:18.300886 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 116944.\n",
            "I0321 23:19:20.715353 140432184936192 supervisor.py:1050] Recording summary at step 116944.\n",
            "INFO:tensorflow:global step 116950: loss = 0.3662 (0.798 sec/step)\n",
            "I0321 23:19:25.053465 140436091496320 learning.py:507] global step 116950: loss = 0.3662 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 116960: loss = 0.4183 (0.787 sec/step)\n",
            "I0321 23:19:33.166515 140436091496320 learning.py:507] global step 116960: loss = 0.4183 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 116970: loss = 0.3636 (0.987 sec/step)\n",
            "I0321 23:19:41.264210 140436091496320 learning.py:507] global step 116970: loss = 0.3636 (0.987 sec/step)\n",
            "INFO:tensorflow:global step 116980: loss = 0.3768 (0.790 sec/step)\n",
            "I0321 23:19:49.465652 140436091496320 learning.py:507] global step 116980: loss = 0.3768 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 116990: loss = 0.3545 (0.794 sec/step)\n",
            "I0321 23:19:57.394223 140436091496320 learning.py:507] global step 116990: loss = 0.3545 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 117000: loss = 0.3732 (0.790 sec/step)\n",
            "I0321 23:20:05.309454 140436091496320 learning.py:507] global step 117000: loss = 0.3732 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 117010: loss = 0.4042 (0.786 sec/step)\n",
            "I0321 23:20:13.186004 140436091496320 learning.py:507] global step 117010: loss = 0.4042 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 117020: loss = 0.3577 (0.782 sec/step)\n",
            "I0321 23:20:21.139692 140436091496320 learning.py:507] global step 117020: loss = 0.3577 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 117030: loss = 0.4162 (1.014 sec/step)\n",
            "I0321 23:20:29.281935 140436091496320 learning.py:507] global step 117030: loss = 0.4162 (1.014 sec/step)\n",
            "INFO:tensorflow:global step 117040: loss = 0.3722 (0.788 sec/step)\n",
            "I0321 23:20:37.449998 140436091496320 learning.py:507] global step 117040: loss = 0.3722 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 117050: loss = 0.3731 (0.783 sec/step)\n",
            "I0321 23:20:45.355275 140436091496320 learning.py:507] global step 117050: loss = 0.3731 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 117060: loss = 0.3617 (0.793 sec/step)\n",
            "I0321 23:20:53.245401 140436091496320 learning.py:507] global step 117060: loss = 0.3617 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 117070: loss = 0.3712 (0.784 sec/step)\n",
            "I0321 23:21:01.340330 140436091496320 learning.py:507] global step 117070: loss = 0.3712 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117080: loss = 0.4054 (0.797 sec/step)\n",
            "I0321 23:21:09.254540 140436091496320 learning.py:507] global step 117080: loss = 0.4054 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 117090: loss = 0.3695 (0.789 sec/step)\n",
            "I0321 23:21:17.220073 140436091496320 learning.py:507] global step 117090: loss = 0.3695 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 117100: loss = 0.3723 (0.779 sec/step)\n",
            "I0321 23:21:25.142743 140436091496320 learning.py:507] global step 117100: loss = 0.3723 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 117110: loss = 0.3900 (0.781 sec/step)\n",
            "I0321 23:21:33.094186 140436091496320 learning.py:507] global step 117110: loss = 0.3900 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 117120: loss = 0.3718 (0.792 sec/step)\n",
            "I0321 23:21:41.407371 140436091496320 learning.py:507] global step 117120: loss = 0.3718 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 117130: loss = 0.4225 (0.781 sec/step)\n",
            "I0321 23:21:49.452001 140436091496320 learning.py:507] global step 117130: loss = 0.4225 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 117140: loss = 0.3716 (0.791 sec/step)\n",
            "I0321 23:21:57.500307 140436091496320 learning.py:507] global step 117140: loss = 0.3716 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 117150: loss = 0.3617 (0.793 sec/step)\n",
            "I0321 23:22:05.401145 140436091496320 learning.py:507] global step 117150: loss = 0.3617 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 117160: loss = 0.3600 (0.795 sec/step)\n",
            "I0321 23:22:13.508375 140436091496320 learning.py:507] global step 117160: loss = 0.3600 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 117170: loss = 0.3578 (0.797 sec/step)\n",
            "I0321 23:22:21.635113 140436091496320 learning.py:507] global step 117170: loss = 0.3578 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 117180: loss = 0.3669 (0.799 sec/step)\n",
            "I0321 23:22:29.699671 140436091496320 learning.py:507] global step 117180: loss = 0.3669 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 117190: loss = 0.3885 (0.789 sec/step)\n",
            "I0321 23:22:37.609754 140436091496320 learning.py:507] global step 117190: loss = 0.3885 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 117200: loss = 0.3571 (0.787 sec/step)\n",
            "I0321 23:22:45.543015 140436091496320 learning.py:507] global step 117200: loss = 0.3571 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 117210: loss = 0.4354 (0.929 sec/step)\n",
            "I0321 23:22:53.859331 140436091496320 learning.py:507] global step 117210: loss = 0.4354 (0.929 sec/step)\n",
            "INFO:tensorflow:global step 117220: loss = 0.3577 (0.801 sec/step)\n",
            "I0321 23:23:01.798236 140436091496320 learning.py:507] global step 117220: loss = 0.3577 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 117230: loss = 0.4128 (0.784 sec/step)\n",
            "I0321 23:23:09.728029 140436091496320 learning.py:507] global step 117230: loss = 0.4128 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117240: loss = 0.3674 (0.787 sec/step)\n",
            "I0321 23:23:17.644720 140436091496320 learning.py:507] global step 117240: loss = 0.3674 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 117250: loss = 0.3775 (0.784 sec/step)\n",
            "I0321 23:23:25.673654 140436091496320 learning.py:507] global step 117250: loss = 0.3775 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117260: loss = 0.4155 (0.784 sec/step)\n",
            "I0321 23:23:33.596895 140436091496320 learning.py:507] global step 117260: loss = 0.4155 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117270: loss = 0.3869 (0.785 sec/step)\n",
            "I0321 23:23:41.508343 140436091496320 learning.py:507] global step 117270: loss = 0.3869 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 117280: loss = 0.3768 (0.799 sec/step)\n",
            "I0321 23:23:49.428423 140436091496320 learning.py:507] global step 117280: loss = 0.3768 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 117290: loss = 0.3484 (0.784 sec/step)\n",
            "I0321 23:23:57.347060 140436091496320 learning.py:507] global step 117290: loss = 0.3484 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117300: loss = 0.4017 (0.788 sec/step)\n",
            "I0321 23:24:05.315695 140436091496320 learning.py:507] global step 117300: loss = 0.4017 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 117310: loss = 0.3475 (0.782 sec/step)\n",
            "I0321 23:24:13.210586 140436091496320 learning.py:507] global step 117310: loss = 0.3475 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 117320: loss = 0.3913 (0.785 sec/step)\n",
            "I0321 23:24:21.405736 140436091496320 learning.py:507] global step 117320: loss = 0.3913 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 117330: loss = 0.3559 (0.804 sec/step)\n",
            "I0321 23:24:29.325816 140436091496320 learning.py:507] global step 117330: loss = 0.3559 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 117340: loss = 0.3578 (0.791 sec/step)\n",
            "I0321 23:24:37.250817 140436091496320 learning.py:507] global step 117340: loss = 0.3578 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 117350: loss = 0.3702 (0.779 sec/step)\n",
            "I0321 23:24:45.232352 140436091496320 learning.py:507] global step 117350: loss = 0.3702 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 117360: loss = 0.3530 (1.012 sec/step)\n",
            "I0321 23:24:53.423985 140436091496320 learning.py:507] global step 117360: loss = 0.3530 (1.012 sec/step)\n",
            "INFO:tensorflow:global step 117370: loss = 0.3475 (0.786 sec/step)\n",
            "I0321 23:25:01.514277 140436091496320 learning.py:507] global step 117370: loss = 0.3475 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 117380: loss = 0.3724 (0.791 sec/step)\n",
            "I0321 23:25:09.427943 140436091496320 learning.py:507] global step 117380: loss = 0.3724 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 117390: loss = 0.3818 (0.843 sec/step)\n",
            "I0321 23:25:17.359346 140436091496320 learning.py:507] global step 117390: loss = 0.3818 (0.843 sec/step)\n",
            "INFO:tensorflow:global step 117400: loss = 0.3773 (0.778 sec/step)\n",
            "I0321 23:25:25.289457 140436091496320 learning.py:507] global step 117400: loss = 0.3773 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 117410: loss = 0.3603 (0.784 sec/step)\n",
            "I0321 23:25:33.213131 140436091496320 learning.py:507] global step 117410: loss = 0.3603 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117420: loss = 0.3668 (0.810 sec/step)\n",
            "I0321 23:25:41.124550 140436091496320 learning.py:507] global step 117420: loss = 0.3668 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 117430: loss = 0.3564 (0.781 sec/step)\n",
            "I0321 23:25:49.064816 140436091496320 learning.py:507] global step 117430: loss = 0.3564 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 117440: loss = 0.3450 (0.812 sec/step)\n",
            "I0321 23:25:57.040718 140436091496320 learning.py:507] global step 117440: loss = 0.3450 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 117450: loss = 0.3854 (0.785 sec/step)\n",
            "I0321 23:26:05.014518 140436091496320 learning.py:507] global step 117450: loss = 0.3854 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 117460: loss = 0.3723 (0.795 sec/step)\n",
            "I0321 23:26:13.377731 140436091496320 learning.py:507] global step 117460: loss = 0.3723 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 117470: loss = 0.3734 (0.786 sec/step)\n",
            "I0321 23:26:21.440729 140436091496320 learning.py:507] global step 117470: loss = 0.3734 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 117480: loss = 0.3780 (0.788 sec/step)\n",
            "I0321 23:26:29.345930 140436091496320 learning.py:507] global step 117480: loss = 0.3780 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 117490: loss = 0.3494 (0.794 sec/step)\n",
            "I0321 23:26:37.343395 140436091496320 learning.py:507] global step 117490: loss = 0.3494 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 117500: loss = 0.3631 (0.782 sec/step)\n",
            "I0321 23:26:45.430669 140436091496320 learning.py:507] global step 117500: loss = 0.3631 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 117510: loss = 0.3505 (0.937 sec/step)\n",
            "I0321 23:26:53.501758 140436091496320 learning.py:507] global step 117510: loss = 0.3505 (0.937 sec/step)\n",
            "INFO:tensorflow:global step 117520: loss = 0.3660 (0.785 sec/step)\n",
            "I0321 23:27:01.426042 140436091496320 learning.py:507] global step 117520: loss = 0.3660 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 117530: loss = 0.3492 (0.783 sec/step)\n",
            "I0321 23:27:09.327459 140436091496320 learning.py:507] global step 117530: loss = 0.3492 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 117540: loss = 0.3576 (0.814 sec/step)\n",
            "I0321 23:27:17.545337 140436091496320 learning.py:507] global step 117540: loss = 0.3576 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 117550: loss = 0.3870 (0.780 sec/step)\n",
            "I0321 23:27:25.566452 140436091496320 learning.py:507] global step 117550: loss = 0.3870 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 117560: loss = 0.3973 (0.780 sec/step)\n",
            "I0321 23:27:33.541085 140436091496320 learning.py:507] global step 117560: loss = 0.3973 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 117570: loss = 0.3455 (0.783 sec/step)\n",
            "I0321 23:27:41.520024 140436091496320 learning.py:507] global step 117570: loss = 0.3455 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 117580: loss = 0.3564 (0.788 sec/step)\n",
            "I0321 23:27:49.444895 140436091496320 learning.py:507] global step 117580: loss = 0.3564 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 117590: loss = 0.3592 (0.783 sec/step)\n",
            "I0321 23:27:57.375473 140436091496320 learning.py:507] global step 117590: loss = 0.3592 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 117600: loss = 0.3841 (0.781 sec/step)\n",
            "I0321 23:28:05.294352 140436091496320 learning.py:507] global step 117600: loss = 0.3841 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 117610: loss = 0.3569 (0.790 sec/step)\n",
            "I0321 23:28:13.187063 140436091496320 learning.py:507] global step 117610: loss = 0.3569 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 117620: loss = 0.3841 (0.796 sec/step)\n",
            "I0321 23:28:21.112331 140436091496320 learning.py:507] global step 117620: loss = 0.3841 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 117630: loss = 0.3670 (0.874 sec/step)\n",
            "I0321 23:28:29.290180 140436091496320 learning.py:507] global step 117630: loss = 0.3670 (0.874 sec/step)\n",
            "INFO:tensorflow:global step 117640: loss = 0.3729 (0.781 sec/step)\n",
            "I0321 23:28:37.199508 140436091496320 learning.py:507] global step 117640: loss = 0.3729 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 117650: loss = 0.3755 (0.791 sec/step)\n",
            "I0321 23:28:45.355907 140436091496320 learning.py:507] global step 117650: loss = 0.3755 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 117660: loss = 0.3705 (0.812 sec/step)\n",
            "I0321 23:28:53.296863 140436091496320 learning.py:507] global step 117660: loss = 0.3705 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 117670: loss = 0.3595 (0.790 sec/step)\n",
            "I0321 23:29:01.387985 140436091496320 learning.py:507] global step 117670: loss = 0.3595 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 117680: loss = 0.3732 (0.789 sec/step)\n",
            "I0321 23:29:09.347941 140436091496320 learning.py:507] global step 117680: loss = 0.3732 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 117690: loss = 0.4021 (0.806 sec/step)\n",
            "I0321 23:29:17.302160 140436091496320 learning.py:507] global step 117690: loss = 0.4021 (0.806 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 117692.\n",
            "I0321 23:29:20.518989 140432184936192 supervisor.py:1050] Recording summary at step 117692.\n",
            "INFO:tensorflow:global step 117700: loss = 0.3554 (0.780 sec/step)\n",
            "I0321 23:29:26.747842 140436091496320 learning.py:507] global step 117700: loss = 0.3554 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 117710: loss = 0.3697 (0.795 sec/step)\n",
            "I0321 23:29:34.711177 140436091496320 learning.py:507] global step 117710: loss = 0.3697 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 117720: loss = 0.3532 (0.797 sec/step)\n",
            "I0321 23:29:42.765450 140436091496320 learning.py:507] global step 117720: loss = 0.3532 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 117730: loss = 0.3985 (0.782 sec/step)\n",
            "I0321 23:29:50.765388 140436091496320 learning.py:507] global step 117730: loss = 0.3985 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 117740: loss = 0.3614 (0.786 sec/step)\n",
            "I0321 23:29:58.668273 140436091496320 learning.py:507] global step 117740: loss = 0.3614 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 117750: loss = 0.3675 (0.783 sec/step)\n",
            "I0321 23:30:06.540609 140436091496320 learning.py:507] global step 117750: loss = 0.3675 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 117760: loss = 0.3621 (0.782 sec/step)\n",
            "I0321 23:30:14.737278 140436091496320 learning.py:507] global step 117760: loss = 0.3621 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 117770: loss = 0.4771 (0.795 sec/step)\n",
            "I0321 23:30:22.742002 140436091496320 learning.py:507] global step 117770: loss = 0.4771 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 117780: loss = 0.3619 (0.794 sec/step)\n",
            "I0321 23:30:30.676882 140436091496320 learning.py:507] global step 117780: loss = 0.3619 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 117790: loss = 0.3709 (0.782 sec/step)\n",
            "I0321 23:30:38.793351 140436091496320 learning.py:507] global step 117790: loss = 0.3709 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 117800: loss = 0.3670 (0.797 sec/step)\n",
            "I0321 23:30:46.703629 140436091496320 learning.py:507] global step 117800: loss = 0.3670 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 117810: loss = 0.3555 (0.779 sec/step)\n",
            "I0321 23:30:54.711926 140436091496320 learning.py:507] global step 117810: loss = 0.3555 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 117820: loss = 0.3451 (0.789 sec/step)\n",
            "I0321 23:31:02.665992 140436091496320 learning.py:507] global step 117820: loss = 0.3451 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 117830: loss = 0.3789 (0.828 sec/step)\n",
            "I0321 23:31:10.750509 140436091496320 learning.py:507] global step 117830: loss = 0.3789 (0.828 sec/step)\n",
            "INFO:tensorflow:global step 117840: loss = 0.3649 (0.784 sec/step)\n",
            "I0321 23:31:19.048299 140436091496320 learning.py:507] global step 117840: loss = 0.3649 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117850: loss = 0.3530 (0.803 sec/step)\n",
            "I0321 23:31:27.179500 140436091496320 learning.py:507] global step 117850: loss = 0.3530 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 117860: loss = 0.3575 (0.806 sec/step)\n",
            "I0321 23:31:35.346651 140436091496320 learning.py:507] global step 117860: loss = 0.3575 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 117870: loss = 0.3668 (0.787 sec/step)\n",
            "I0321 23:31:43.218302 140436091496320 learning.py:507] global step 117870: loss = 0.3668 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 117880: loss = 0.3717 (0.796 sec/step)\n",
            "I0321 23:31:51.240674 140436091496320 learning.py:507] global step 117880: loss = 0.3717 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 117890: loss = 0.3754 (0.896 sec/step)\n",
            "I0321 23:31:59.271776 140436091496320 learning.py:507] global step 117890: loss = 0.3754 (0.896 sec/step)\n",
            "INFO:tensorflow:global step 117900: loss = 0.3666 (0.793 sec/step)\n",
            "I0321 23:32:07.165895 140436091496320 learning.py:507] global step 117900: loss = 0.3666 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 117910: loss = 0.3293 (0.776 sec/step)\n",
            "I0321 23:32:15.081310 140436091496320 learning.py:507] global step 117910: loss = 0.3293 (0.776 sec/step)\n",
            "INFO:tensorflow:global step 117920: loss = 0.3399 (0.787 sec/step)\n",
            "I0321 23:32:23.114986 140436091496320 learning.py:507] global step 117920: loss = 0.3399 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 117930: loss = 0.3528 (0.779 sec/step)\n",
            "I0321 23:32:31.139606 140436091496320 learning.py:507] global step 117930: loss = 0.3528 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 117940: loss = 0.3420 (0.791 sec/step)\n",
            "I0321 23:32:39.169052 140436091496320 learning.py:507] global step 117940: loss = 0.3420 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 117950: loss = 0.3468 (0.782 sec/step)\n",
            "I0321 23:32:47.269605 140436091496320 learning.py:507] global step 117950: loss = 0.3468 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 117960: loss = 0.3682 (0.788 sec/step)\n",
            "I0321 23:32:55.486747 140436091496320 learning.py:507] global step 117960: loss = 0.3682 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 117970: loss = 0.3542 (0.784 sec/step)\n",
            "I0321 23:33:03.530189 140436091496320 learning.py:507] global step 117970: loss = 0.3542 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 117980: loss = 0.3688 (0.972 sec/step)\n",
            "I0321 23:33:11.834960 140436091496320 learning.py:507] global step 117980: loss = 0.3688 (0.972 sec/step)\n",
            "INFO:tensorflow:global step 117990: loss = 0.3509 (0.794 sec/step)\n",
            "I0321 23:33:19.845685 140436091496320 learning.py:507] global step 117990: loss = 0.3509 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 118000: loss = 0.3583 (0.782 sec/step)\n",
            "I0321 23:33:27.754194 140436091496320 learning.py:507] global step 118000: loss = 0.3583 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118010: loss = 0.3606 (0.799 sec/step)\n",
            "I0321 23:33:35.659100 140436091496320 learning.py:507] global step 118010: loss = 0.3606 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 118020: loss = 0.3668 (0.785 sec/step)\n",
            "I0321 23:33:43.977892 140436091496320 learning.py:507] global step 118020: loss = 0.3668 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 118030: loss = 0.3629 (0.782 sec/step)\n",
            "I0321 23:33:51.898538 140436091496320 learning.py:507] global step 118030: loss = 0.3629 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118040: loss = 0.3666 (0.821 sec/step)\n",
            "I0321 23:33:59.834726 140436091496320 learning.py:507] global step 118040: loss = 0.3666 (0.821 sec/step)\n",
            "INFO:tensorflow:global step 118050: loss = 0.3637 (0.783 sec/step)\n",
            "I0321 23:34:07.743018 140436091496320 learning.py:507] global step 118050: loss = 0.3637 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118060: loss = 0.3258 (0.793 sec/step)\n",
            "I0321 23:34:15.647525 140436091496320 learning.py:507] global step 118060: loss = 0.3258 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 118070: loss = 0.3621 (0.830 sec/step)\n",
            "I0321 23:34:23.573055 140436091496320 learning.py:507] global step 118070: loss = 0.3621 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 118080: loss = 0.3665 (0.779 sec/step)\n",
            "I0321 23:34:31.595024 140436091496320 learning.py:507] global step 118080: loss = 0.3665 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 118090: loss = 0.3525 (0.784 sec/step)\n",
            "I0321 23:34:39.471545 140436091496320 learning.py:507] global step 118090: loss = 0.3525 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118100: loss = 0.3741 (0.782 sec/step)\n",
            "I0321 23:34:47.409864 140436091496320 learning.py:507] global step 118100: loss = 0.3741 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118110: loss = 0.4308 (0.783 sec/step)\n",
            "I0321 23:34:55.576896 140436091496320 learning.py:507] global step 118110: loss = 0.4308 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118120: loss = 0.3476 (0.784 sec/step)\n",
            "I0321 23:35:03.475814 140436091496320 learning.py:507] global step 118120: loss = 0.3476 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118130: loss = 0.3552 (0.778 sec/step)\n",
            "I0321 23:35:11.390410 140436091496320 learning.py:507] global step 118130: loss = 0.3552 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 118140: loss = 0.3569 (0.783 sec/step)\n",
            "I0321 23:35:19.386839 140436091496320 learning.py:507] global step 118140: loss = 0.3569 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118150: loss = 0.3846 (0.798 sec/step)\n",
            "I0321 23:35:27.405297 140436091496320 learning.py:507] global step 118150: loss = 0.3846 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 118160: loss = 0.3586 (0.814 sec/step)\n",
            "I0321 23:35:35.335576 140436091496320 learning.py:507] global step 118160: loss = 0.3586 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 118170: loss = 0.3638 (0.783 sec/step)\n",
            "I0321 23:35:43.230022 140436091496320 learning.py:507] global step 118170: loss = 0.3638 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118180: loss = 0.3667 (0.798 sec/step)\n",
            "I0321 23:35:51.220346 140436091496320 learning.py:507] global step 118180: loss = 0.3667 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 118190: loss = 0.3646 (0.791 sec/step)\n",
            "I0321 23:35:59.269657 140436091496320 learning.py:507] global step 118190: loss = 0.3646 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 118200: loss = 0.3776 (0.788 sec/step)\n",
            "I0321 23:36:07.353997 140436091496320 learning.py:507] global step 118200: loss = 0.3776 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 118210: loss = 0.3826 (0.783 sec/step)\n",
            "I0321 23:36:15.263391 140436091496320 learning.py:507] global step 118210: loss = 0.3826 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118220: loss = 0.3732 (0.785 sec/step)\n",
            "I0321 23:36:23.142379 140436091496320 learning.py:507] global step 118220: loss = 0.3732 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 118230: loss = 0.3883 (0.795 sec/step)\n",
            "I0321 23:36:31.264138 140436091496320 learning.py:507] global step 118230: loss = 0.3883 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 118240: loss = 0.3602 (0.797 sec/step)\n",
            "I0321 23:36:39.201042 140436091496320 learning.py:507] global step 118240: loss = 0.3602 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 118250: loss = 0.4261 (0.788 sec/step)\n",
            "I0321 23:36:47.076636 140436091496320 learning.py:507] global step 118250: loss = 0.4261 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 118260: loss = 0.3522 (0.795 sec/step)\n",
            "I0321 23:36:55.012356 140436091496320 learning.py:507] global step 118260: loss = 0.3522 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 118270: loss = 0.3623 (0.793 sec/step)\n",
            "I0321 23:37:02.912307 140436091496320 learning.py:507] global step 118270: loss = 0.3623 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 118280: loss = 0.3666 (0.783 sec/step)\n",
            "I0321 23:37:11.041130 140436091496320 learning.py:507] global step 118280: loss = 0.3666 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118290: loss = 0.3881 (0.784 sec/step)\n",
            "I0321 23:37:18.916584 140436091496320 learning.py:507] global step 118290: loss = 0.3881 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118300: loss = 0.3680 (0.799 sec/step)\n",
            "I0321 23:37:26.900816 140436091496320 learning.py:507] global step 118300: loss = 0.3680 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 118310: loss = 0.3626 (0.815 sec/step)\n",
            "I0321 23:37:34.852011 140436091496320 learning.py:507] global step 118310: loss = 0.3626 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 118320: loss = 0.3470 (0.785 sec/step)\n",
            "I0321 23:37:42.807058 140436091496320 learning.py:507] global step 118320: loss = 0.3470 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 118330: loss = 0.3589 (0.800 sec/step)\n",
            "I0321 23:37:51.135879 140436091496320 learning.py:507] global step 118330: loss = 0.3589 (0.800 sec/step)\n",
            "INFO:tensorflow:global step 118340: loss = 0.3639 (0.814 sec/step)\n",
            "I0321 23:37:59.068104 140436091496320 learning.py:507] global step 118340: loss = 0.3639 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 118350: loss = 0.3533 (0.782 sec/step)\n",
            "I0321 23:38:07.070897 140436091496320 learning.py:507] global step 118350: loss = 0.3533 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118360: loss = 0.3768 (0.794 sec/step)\n",
            "I0321 23:38:15.020384 140436091496320 learning.py:507] global step 118360: loss = 0.3768 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 118370: loss = 0.3725 (0.815 sec/step)\n",
            "I0321 23:38:22.922544 140436091496320 learning.py:507] global step 118370: loss = 0.3725 (0.815 sec/step)\n",
            "INFO:tensorflow:global step 118380: loss = 0.4047 (0.810 sec/step)\n",
            "I0321 23:38:30.930149 140436091496320 learning.py:507] global step 118380: loss = 0.4047 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 118390: loss = 0.3893 (0.798 sec/step)\n",
            "I0321 23:38:38.858072 140436091496320 learning.py:507] global step 118390: loss = 0.3893 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 118400: loss = 0.4058 (0.806 sec/step)\n",
            "I0321 23:38:46.973926 140436091496320 learning.py:507] global step 118400: loss = 0.4058 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 118410: loss = 0.3816 (0.781 sec/step)\n",
            "I0321 23:38:55.038529 140436091496320 learning.py:507] global step 118410: loss = 0.3816 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 118420: loss = 0.3773 (0.787 sec/step)\n",
            "I0321 23:39:03.028301 140436091496320 learning.py:507] global step 118420: loss = 0.3773 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 118430: loss = 0.3515 (0.799 sec/step)\n",
            "I0321 23:39:10.947884 140436091496320 learning.py:507] global step 118430: loss = 0.3515 (0.799 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 23:39:18.300928 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 118439.\n",
            "I0321 23:39:20.559233 140432184936192 supervisor.py:1050] Recording summary at step 118439.\n",
            "INFO:tensorflow:global step 118440: loss = 0.3604 (2.520 sec/step)\n",
            "I0321 23:39:20.578743 140436091496320 learning.py:507] global step 118440: loss = 0.3604 (2.520 sec/step)\n",
            "INFO:tensorflow:global step 118450: loss = 0.3646 (0.804 sec/step)\n",
            "I0321 23:39:28.974379 140436091496320 learning.py:507] global step 118450: loss = 0.3646 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 118460: loss = 0.4201 (0.794 sec/step)\n",
            "I0321 23:39:37.075977 140436091496320 learning.py:507] global step 118460: loss = 0.4201 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 118470: loss = 0.3902 (0.781 sec/step)\n",
            "I0321 23:39:45.083125 140436091496320 learning.py:507] global step 118470: loss = 0.3902 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 118480: loss = 0.3669 (0.852 sec/step)\n",
            "I0321 23:39:53.415450 140436091496320 learning.py:507] global step 118480: loss = 0.3669 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 118490: loss = 0.3618 (0.784 sec/step)\n",
            "I0321 23:40:01.323693 140436091496320 learning.py:507] global step 118490: loss = 0.3618 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118500: loss = 0.3444 (0.784 sec/step)\n",
            "I0321 23:40:09.633351 140436091496320 learning.py:507] global step 118500: loss = 0.3444 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118510: loss = 0.4002 (0.799 sec/step)\n",
            "I0321 23:40:17.745823 140436091496320 learning.py:507] global step 118510: loss = 0.4002 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 118520: loss = 0.3613 (0.795 sec/step)\n",
            "I0321 23:40:25.679195 140436091496320 learning.py:507] global step 118520: loss = 0.3613 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 118530: loss = 0.3666 (0.781 sec/step)\n",
            "I0321 23:40:33.592579 140436091496320 learning.py:507] global step 118530: loss = 0.3666 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 118540: loss = 0.3670 (0.805 sec/step)\n",
            "I0321 23:40:41.682392 140436091496320 learning.py:507] global step 118540: loss = 0.3670 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 118550: loss = 0.3886 (0.784 sec/step)\n",
            "I0321 23:40:49.703032 140436091496320 learning.py:507] global step 118550: loss = 0.3886 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118560: loss = 0.3476 (0.778 sec/step)\n",
            "I0321 23:40:57.621647 140436091496320 learning.py:507] global step 118560: loss = 0.3476 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 118570: loss = 0.3899 (0.814 sec/step)\n",
            "I0321 23:41:05.569336 140436091496320 learning.py:507] global step 118570: loss = 0.3899 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 118580: loss = 0.3862 (0.783 sec/step)\n",
            "I0321 23:41:13.445012 140436091496320 learning.py:507] global step 118580: loss = 0.3862 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118590: loss = 0.3592 (0.781 sec/step)\n",
            "I0321 23:41:21.382220 140436091496320 learning.py:507] global step 118590: loss = 0.3592 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 118600: loss = 0.3491 (0.862 sec/step)\n",
            "I0321 23:41:29.399004 140436091496320 learning.py:507] global step 118600: loss = 0.3491 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 118610: loss = 0.3940 (0.812 sec/step)\n",
            "I0321 23:41:37.552825 140436091496320 learning.py:507] global step 118610: loss = 0.3940 (0.812 sec/step)\n",
            "INFO:tensorflow:global step 118620: loss = 0.3465 (0.781 sec/step)\n",
            "I0321 23:41:45.696207 140436091496320 learning.py:507] global step 118620: loss = 0.3465 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 118630: loss = 0.3994 (0.797 sec/step)\n",
            "I0321 23:41:53.800763 140436091496320 learning.py:507] global step 118630: loss = 0.3994 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 118640: loss = 0.3820 (0.781 sec/step)\n",
            "I0321 23:42:01.700051 140436091496320 learning.py:507] global step 118640: loss = 0.3820 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 118650: loss = 0.3857 (0.785 sec/step)\n",
            "I0321 23:42:09.773212 140436091496320 learning.py:507] global step 118650: loss = 0.3857 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 118660: loss = 0.3518 (0.784 sec/step)\n",
            "I0321 23:42:17.647180 140436091496320 learning.py:507] global step 118660: loss = 0.3518 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118670: loss = 0.3761 (0.784 sec/step)\n",
            "I0321 23:42:25.871484 140436091496320 learning.py:507] global step 118670: loss = 0.3761 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118680: loss = 0.3628 (0.780 sec/step)\n",
            "I0321 23:42:33.890167 140436091496320 learning.py:507] global step 118680: loss = 0.3628 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 118690: loss = 0.3642 (0.914 sec/step)\n",
            "I0321 23:42:42.120511 140436091496320 learning.py:507] global step 118690: loss = 0.3642 (0.914 sec/step)\n",
            "INFO:tensorflow:global step 118700: loss = 0.3734 (0.785 sec/step)\n",
            "I0321 23:42:50.135838 140436091496320 learning.py:507] global step 118700: loss = 0.3734 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 118710: loss = 0.3427 (0.782 sec/step)\n",
            "I0321 23:42:57.997358 140436091496320 learning.py:507] global step 118710: loss = 0.3427 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118720: loss = 0.3620 (0.810 sec/step)\n",
            "I0321 23:43:06.016938 140436091496320 learning.py:507] global step 118720: loss = 0.3620 (0.810 sec/step)\n",
            "INFO:tensorflow:global step 118730: loss = 0.3469 (0.791 sec/step)\n",
            "I0321 23:43:13.944700 140436091496320 learning.py:507] global step 118730: loss = 0.3469 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 118740: loss = 0.3868 (0.782 sec/step)\n",
            "I0321 23:43:21.957600 140436091496320 learning.py:507] global step 118740: loss = 0.3868 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118750: loss = 0.3743 (0.786 sec/step)\n",
            "I0321 23:43:29.855622 140436091496320 learning.py:507] global step 118750: loss = 0.3743 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 118760: loss = 0.3645 (0.787 sec/step)\n",
            "I0321 23:43:37.951886 140436091496320 learning.py:507] global step 118760: loss = 0.3645 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 118770: loss = 0.3551 (0.783 sec/step)\n",
            "I0321 23:43:46.089301 140436091496320 learning.py:507] global step 118770: loss = 0.3551 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118780: loss = 0.3649 (0.806 sec/step)\n",
            "I0321 23:43:54.084782 140436091496320 learning.py:507] global step 118780: loss = 0.3649 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 118790: loss = 0.3638 (0.782 sec/step)\n",
            "I0321 23:44:02.387095 140436091496320 learning.py:507] global step 118790: loss = 0.3638 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118800: loss = 0.3666 (0.784 sec/step)\n",
            "I0321 23:44:10.332406 140436091496320 learning.py:507] global step 118800: loss = 0.3666 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 118810: loss = 0.3673 (0.805 sec/step)\n",
            "I0321 23:44:18.439069 140436091496320 learning.py:507] global step 118810: loss = 0.3673 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 118820: loss = 0.3363 (0.808 sec/step)\n",
            "I0321 23:44:26.460318 140436091496320 learning.py:507] global step 118820: loss = 0.3363 (0.808 sec/step)\n",
            "INFO:tensorflow:global step 118830: loss = 0.3532 (0.783 sec/step)\n",
            "I0321 23:44:34.375186 140436091496320 learning.py:507] global step 118830: loss = 0.3532 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 118840: loss = 0.4413 (0.782 sec/step)\n",
            "I0321 23:44:42.538420 140436091496320 learning.py:507] global step 118840: loss = 0.4413 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118850: loss = 0.3702 (0.801 sec/step)\n",
            "I0321 23:44:50.438741 140436091496320 learning.py:507] global step 118850: loss = 0.3702 (0.801 sec/step)\n",
            "INFO:tensorflow:global step 118860: loss = 0.3762 (0.795 sec/step)\n",
            "I0321 23:44:58.565621 140436091496320 learning.py:507] global step 118860: loss = 0.3762 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 118870: loss = 0.3773 (0.780 sec/step)\n",
            "I0321 23:45:06.594089 140436091496320 learning.py:507] global step 118870: loss = 0.3773 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 118880: loss = 0.3598 (0.785 sec/step)\n",
            "I0321 23:45:14.482693 140436091496320 learning.py:507] global step 118880: loss = 0.3598 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 118890: loss = 0.3595 (0.785 sec/step)\n",
            "I0321 23:45:22.383750 140436091496320 learning.py:507] global step 118890: loss = 0.3595 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 118900: loss = 0.3586 (0.786 sec/step)\n",
            "I0321 23:45:30.549396 140436091496320 learning.py:507] global step 118900: loss = 0.3586 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 118910: loss = 0.3414 (0.782 sec/step)\n",
            "I0321 23:45:38.678529 140436091496320 learning.py:507] global step 118910: loss = 0.3414 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118920: loss = 0.3429 (0.780 sec/step)\n",
            "I0321 23:45:46.753484 140436091496320 learning.py:507] global step 118920: loss = 0.3429 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 118930: loss = 0.3638 (0.823 sec/step)\n",
            "I0321 23:45:54.811554 140436091496320 learning.py:507] global step 118930: loss = 0.3638 (0.823 sec/step)\n",
            "INFO:tensorflow:global step 118940: loss = 0.3804 (0.782 sec/step)\n",
            "I0321 23:46:02.683251 140436091496320 learning.py:507] global step 118940: loss = 0.3804 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 118950: loss = 0.3689 (0.787 sec/step)\n",
            "I0321 23:46:10.575458 140436091496320 learning.py:507] global step 118950: loss = 0.3689 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 118960: loss = 0.3640 (0.795 sec/step)\n",
            "I0321 23:46:18.768493 140436091496320 learning.py:507] global step 118960: loss = 0.3640 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 118970: loss = 0.3583 (0.796 sec/step)\n",
            "I0321 23:46:26.957691 140436091496320 learning.py:507] global step 118970: loss = 0.3583 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 118980: loss = 0.3647 (0.796 sec/step)\n",
            "I0321 23:46:34.981679 140436091496320 learning.py:507] global step 118980: loss = 0.3647 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 118990: loss = 0.3761 (0.806 sec/step)\n",
            "I0321 23:46:42.954700 140436091496320 learning.py:507] global step 118990: loss = 0.3761 (0.806 sec/step)\n",
            "INFO:tensorflow:global step 119000: loss = 0.3564 (0.782 sec/step)\n",
            "I0321 23:46:50.896502 140436091496320 learning.py:507] global step 119000: loss = 0.3564 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119010: loss = 0.3625 (0.784 sec/step)\n",
            "I0321 23:46:58.858967 140436091496320 learning.py:507] global step 119010: loss = 0.3625 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 119020: loss = 0.3682 (0.822 sec/step)\n",
            "I0321 23:47:06.826660 140436091496320 learning.py:507] global step 119020: loss = 0.3682 (0.822 sec/step)\n",
            "INFO:tensorflow:global step 119030: loss = 0.3494 (0.792 sec/step)\n",
            "I0321 23:47:14.737297 140436091496320 learning.py:507] global step 119030: loss = 0.3494 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 119040: loss = 0.3444 (0.782 sec/step)\n",
            "I0321 23:47:22.620809 140436091496320 learning.py:507] global step 119040: loss = 0.3444 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119050: loss = 0.3774 (0.787 sec/step)\n",
            "I0321 23:47:30.589305 140436091496320 learning.py:507] global step 119050: loss = 0.3774 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 119060: loss = 0.3613 (0.794 sec/step)\n",
            "I0321 23:47:38.660909 140436091496320 learning.py:507] global step 119060: loss = 0.3613 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 119070: loss = 0.3590 (0.780 sec/step)\n",
            "I0321 23:47:46.550481 140436091496320 learning.py:507] global step 119070: loss = 0.3590 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 119080: loss = 0.3802 (0.819 sec/step)\n",
            "I0321 23:47:54.484597 140436091496320 learning.py:507] global step 119080: loss = 0.3802 (0.819 sec/step)\n",
            "INFO:tensorflow:global step 119090: loss = 0.3519 (0.799 sec/step)\n",
            "I0321 23:48:02.406317 140436091496320 learning.py:507] global step 119090: loss = 0.3519 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 119100: loss = 0.3632 (0.779 sec/step)\n",
            "I0321 23:48:10.523672 140436091496320 learning.py:507] global step 119100: loss = 0.3632 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 119110: loss = 0.3655 (0.782 sec/step)\n",
            "I0321 23:48:18.584303 140436091496320 learning.py:507] global step 119110: loss = 0.3655 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119120: loss = 0.3502 (0.781 sec/step)\n",
            "I0321 23:48:26.504670 140436091496320 learning.py:507] global step 119120: loss = 0.3502 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119130: loss = 0.3632 (0.778 sec/step)\n",
            "I0321 23:48:34.571205 140436091496320 learning.py:507] global step 119130: loss = 0.3632 (0.778 sec/step)\n",
            "INFO:tensorflow:global step 119140: loss = 0.3458 (0.795 sec/step)\n",
            "I0321 23:48:42.491690 140436091496320 learning.py:507] global step 119140: loss = 0.3458 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 119150: loss = 0.4000 (0.790 sec/step)\n",
            "I0321 23:48:50.575535 140436091496320 learning.py:507] global step 119150: loss = 0.4000 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 119160: loss = 0.3710 (0.799 sec/step)\n",
            "I0321 23:48:58.646743 140436091496320 learning.py:507] global step 119160: loss = 0.3710 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 119170: loss = 0.3812 (0.805 sec/step)\n",
            "I0321 23:49:06.705051 140436091496320 learning.py:507] global step 119170: loss = 0.3812 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 119180: loss = 0.3475 (0.805 sec/step)\n",
            "I0321 23:49:14.745512 140436091496320 learning.py:507] global step 119180: loss = 0.3475 (0.805 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 119185.\n",
            "I0321 23:49:20.406233 140432184936192 supervisor.py:1050] Recording summary at step 119185.\n",
            "INFO:tensorflow:global step 119190: loss = 0.3447 (0.793 sec/step)\n",
            "I0321 23:49:24.518214 140436091496320 learning.py:507] global step 119190: loss = 0.3447 (0.793 sec/step)\n",
            "INFO:tensorflow:global step 119200: loss = 0.3730 (0.788 sec/step)\n",
            "I0321 23:49:32.435847 140436091496320 learning.py:507] global step 119200: loss = 0.3730 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 119210: loss = 0.3613 (0.787 sec/step)\n",
            "I0321 23:49:40.543653 140436091496320 learning.py:507] global step 119210: loss = 0.3613 (0.787 sec/step)\n",
            "INFO:tensorflow:global step 119220: loss = 0.3409 (0.789 sec/step)\n",
            "I0321 23:49:48.877102 140436091496320 learning.py:507] global step 119220: loss = 0.3409 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 119230: loss = 0.3380 (0.803 sec/step)\n",
            "I0321 23:49:56.888790 140436091496320 learning.py:507] global step 119230: loss = 0.3380 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 119240: loss = 0.3757 (0.790 sec/step)\n",
            "I0321 23:50:04.864573 140436091496320 learning.py:507] global step 119240: loss = 0.3757 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 119250: loss = 0.3703 (0.903 sec/step)\n",
            "I0321 23:50:13.127920 140436091496320 learning.py:507] global step 119250: loss = 0.3703 (0.903 sec/step)\n",
            "INFO:tensorflow:global step 119260: loss = 0.3616 (0.790 sec/step)\n",
            "I0321 23:50:21.293145 140436091496320 learning.py:507] global step 119260: loss = 0.3616 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 119270: loss = 0.4099 (0.781 sec/step)\n",
            "I0321 23:50:29.597234 140436091496320 learning.py:507] global step 119270: loss = 0.4099 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119280: loss = 0.3397 (0.877 sec/step)\n",
            "I0321 23:50:37.646873 140436091496320 learning.py:507] global step 119280: loss = 0.3397 (0.877 sec/step)\n",
            "INFO:tensorflow:global step 119290: loss = 0.3512 (0.798 sec/step)\n",
            "I0321 23:50:45.531956 140436091496320 learning.py:507] global step 119290: loss = 0.3512 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 119300: loss = 0.3608 (0.779 sec/step)\n",
            "I0321 23:50:53.652470 140436091496320 learning.py:507] global step 119300: loss = 0.3608 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 119310: loss = 0.3638 (0.784 sec/step)\n",
            "I0321 23:51:01.728887 140436091496320 learning.py:507] global step 119310: loss = 0.3638 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 119320: loss = 0.3692 (0.779 sec/step)\n",
            "I0321 23:51:09.769061 140436091496320 learning.py:507] global step 119320: loss = 0.3692 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 119330: loss = 0.3568 (0.799 sec/step)\n",
            "I0321 23:51:17.864063 140436091496320 learning.py:507] global step 119330: loss = 0.3568 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 119340: loss = 0.4519 (0.779 sec/step)\n",
            "I0321 23:51:25.812674 140436091496320 learning.py:507] global step 119340: loss = 0.4519 (0.779 sec/step)\n",
            "INFO:tensorflow:global step 119350: loss = 0.3673 (0.781 sec/step)\n",
            "I0321 23:51:33.886293 140436091496320 learning.py:507] global step 119350: loss = 0.3673 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119360: loss = 0.3761 (0.786 sec/step)\n",
            "I0321 23:51:41.983804 140436091496320 learning.py:507] global step 119360: loss = 0.3761 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 119370: loss = 0.3790 (0.934 sec/step)\n",
            "I0321 23:51:50.345221 140436091496320 learning.py:507] global step 119370: loss = 0.3790 (0.934 sec/step)\n",
            "INFO:tensorflow:global step 119380: loss = 0.3878 (0.797 sec/step)\n",
            "I0321 23:51:58.321863 140436091496320 learning.py:507] global step 119380: loss = 0.3878 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 119390: loss = 0.3647 (0.794 sec/step)\n",
            "I0321 23:52:06.242532 140436091496320 learning.py:507] global step 119390: loss = 0.3647 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 119400: loss = 0.3758 (0.788 sec/step)\n",
            "I0321 23:52:14.176891 140436091496320 learning.py:507] global step 119400: loss = 0.3758 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 119410: loss = 0.3504 (0.784 sec/step)\n",
            "I0321 23:52:22.184735 140436091496320 learning.py:507] global step 119410: loss = 0.3504 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 119420: loss = 0.3513 (0.783 sec/step)\n",
            "I0321 23:52:30.070455 140436091496320 learning.py:507] global step 119420: loss = 0.3513 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 119430: loss = 0.4232 (0.789 sec/step)\n",
            "I0321 23:52:38.011426 140436091496320 learning.py:507] global step 119430: loss = 0.4232 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 119440: loss = 0.3479 (0.782 sec/step)\n",
            "I0321 23:52:45.935064 140436091496320 learning.py:507] global step 119440: loss = 0.3479 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119450: loss = 0.3563 (0.782 sec/step)\n",
            "I0321 23:52:53.851504 140436091496320 learning.py:507] global step 119450: loss = 0.3563 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119460: loss = 0.3489 (0.965 sec/step)\n",
            "I0321 23:53:02.095516 140436091496320 learning.py:507] global step 119460: loss = 0.3489 (0.965 sec/step)\n",
            "INFO:tensorflow:global step 119470: loss = 0.3582 (0.788 sec/step)\n",
            "I0321 23:53:10.039047 140436091496320 learning.py:507] global step 119470: loss = 0.3582 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 119480: loss = 0.3597 (0.789 sec/step)\n",
            "I0321 23:53:17.934544 140436091496320 learning.py:507] global step 119480: loss = 0.3597 (0.789 sec/step)\n",
            "INFO:tensorflow:global step 119490: loss = 0.3511 (0.811 sec/step)\n",
            "I0321 23:53:25.859953 140436091496320 learning.py:507] global step 119490: loss = 0.3511 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 119500: loss = 0.3661 (0.796 sec/step)\n",
            "I0321 23:53:33.766102 140436091496320 learning.py:507] global step 119500: loss = 0.3661 (0.796 sec/step)\n",
            "INFO:tensorflow:global step 119510: loss = 0.3606 (0.794 sec/step)\n",
            "I0321 23:53:41.667919 140436091496320 learning.py:507] global step 119510: loss = 0.3606 (0.794 sec/step)\n",
            "INFO:tensorflow:global step 119520: loss = 0.4649 (0.783 sec/step)\n",
            "I0321 23:53:49.557936 140436091496320 learning.py:507] global step 119520: loss = 0.4649 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 119530: loss = 0.3705 (0.783 sec/step)\n",
            "I0321 23:53:57.494224 140436091496320 learning.py:507] global step 119530: loss = 0.3705 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 119540: loss = 0.3521 (0.785 sec/step)\n",
            "I0321 23:54:05.367114 140436091496320 learning.py:507] global step 119540: loss = 0.3521 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 119550: loss = 0.3587 (0.786 sec/step)\n",
            "I0321 23:54:13.448677 140436091496320 learning.py:507] global step 119550: loss = 0.3587 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 119560: loss = 0.3497 (0.782 sec/step)\n",
            "I0321 23:54:21.562637 140436091496320 learning.py:507] global step 119560: loss = 0.3497 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119570: loss = 0.3599 (0.798 sec/step)\n",
            "I0321 23:54:29.494803 140436091496320 learning.py:507] global step 119570: loss = 0.3599 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 119580: loss = 0.3570 (0.792 sec/step)\n",
            "I0321 23:54:37.823108 140436091496320 learning.py:507] global step 119580: loss = 0.3570 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 119590: loss = 0.3731 (0.788 sec/step)\n",
            "I0321 23:54:45.952458 140436091496320 learning.py:507] global step 119590: loss = 0.3731 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 119600: loss = 0.4130 (0.781 sec/step)\n",
            "I0321 23:54:54.097881 140436091496320 learning.py:507] global step 119600: loss = 0.4130 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119610: loss = 0.3957 (0.805 sec/step)\n",
            "I0321 23:55:02.005823 140436091496320 learning.py:507] global step 119610: loss = 0.3957 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 119620: loss = 0.3494 (0.797 sec/step)\n",
            "I0321 23:55:10.129870 140436091496320 learning.py:507] global step 119620: loss = 0.3494 (0.797 sec/step)\n",
            "INFO:tensorflow:global step 119630: loss = 0.3870 (0.791 sec/step)\n",
            "I0321 23:55:18.018460 140436091496320 learning.py:507] global step 119630: loss = 0.3870 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 119640: loss = 0.3619 (0.788 sec/step)\n",
            "I0321 23:55:26.127589 140436091496320 learning.py:507] global step 119640: loss = 0.3619 (0.788 sec/step)\n",
            "INFO:tensorflow:global step 119650: loss = 0.3443 (0.792 sec/step)\n",
            "I0321 23:55:34.474908 140436091496320 learning.py:507] global step 119650: loss = 0.3443 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 119660: loss = 0.3558 (0.804 sec/step)\n",
            "I0321 23:55:42.538993 140436091496320 learning.py:507] global step 119660: loss = 0.3558 (0.804 sec/step)\n",
            "INFO:tensorflow:global step 119670: loss = 0.3641 (0.830 sec/step)\n",
            "I0321 23:55:51.113233 140436091496320 learning.py:507] global step 119670: loss = 0.3641 (0.830 sec/step)\n",
            "INFO:tensorflow:global step 119680: loss = 0.3635 (0.803 sec/step)\n",
            "I0321 23:55:59.244429 140436091496320 learning.py:507] global step 119680: loss = 0.3635 (0.803 sec/step)\n",
            "INFO:tensorflow:global step 119690: loss = 0.4214 (0.781 sec/step)\n",
            "I0321 23:56:07.103014 140436091496320 learning.py:507] global step 119690: loss = 0.4214 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119700: loss = 0.3646 (0.781 sec/step)\n",
            "I0321 23:56:15.053093 140436091496320 learning.py:507] global step 119700: loss = 0.3646 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119710: loss = 0.3671 (0.780 sec/step)\n",
            "I0321 23:56:22.985360 140436091496320 learning.py:507] global step 119710: loss = 0.3671 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 119720: loss = 0.3566 (0.786 sec/step)\n",
            "I0321 23:56:31.043564 140436091496320 learning.py:507] global step 119720: loss = 0.3566 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 119730: loss = 0.3581 (0.795 sec/step)\n",
            "I0321 23:56:38.988247 140436091496320 learning.py:507] global step 119730: loss = 0.3581 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 119740: loss = 0.3982 (0.783 sec/step)\n",
            "I0321 23:56:46.964829 140436091496320 learning.py:507] global step 119740: loss = 0.3982 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 119750: loss = 0.4059 (0.783 sec/step)\n",
            "I0321 23:56:55.120095 140436091496320 learning.py:507] global step 119750: loss = 0.4059 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 119760: loss = 0.3547 (0.781 sec/step)\n",
            "I0321 23:57:03.041940 140436091496320 learning.py:507] global step 119760: loss = 0.3547 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119770: loss = 0.3652 (0.786 sec/step)\n",
            "I0321 23:57:10.952780 140436091496320 learning.py:507] global step 119770: loss = 0.3652 (0.786 sec/step)\n",
            "INFO:tensorflow:global step 119780: loss = 0.3484 (0.791 sec/step)\n",
            "I0321 23:57:18.879706 140436091496320 learning.py:507] global step 119780: loss = 0.3484 (0.791 sec/step)\n",
            "INFO:tensorflow:global step 119790: loss = 0.3675 (0.816 sec/step)\n",
            "I0321 23:57:26.832471 140436091496320 learning.py:507] global step 119790: loss = 0.3675 (0.816 sec/step)\n",
            "INFO:tensorflow:global step 119800: loss = 0.4043 (0.799 sec/step)\n",
            "I0321 23:57:34.756506 140436091496320 learning.py:507] global step 119800: loss = 0.4043 (0.799 sec/step)\n",
            "INFO:tensorflow:global step 119810: loss = 0.4408 (0.792 sec/step)\n",
            "I0321 23:57:42.661685 140436091496320 learning.py:507] global step 119810: loss = 0.4408 (0.792 sec/step)\n",
            "INFO:tensorflow:global step 119820: loss = 0.3647 (0.811 sec/step)\n",
            "I0321 23:57:50.832185 140436091496320 learning.py:507] global step 119820: loss = 0.3647 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 119830: loss = 0.4303 (0.785 sec/step)\n",
            "I0321 23:57:58.909482 140436091496320 learning.py:507] global step 119830: loss = 0.4303 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 119840: loss = 0.3610 (0.782 sec/step)\n",
            "I0321 23:58:06.985959 140436091496320 learning.py:507] global step 119840: loss = 0.3610 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119850: loss = 0.3596 (0.780 sec/step)\n",
            "I0321 23:58:14.943851 140436091496320 learning.py:507] global step 119850: loss = 0.3596 (0.780 sec/step)\n",
            "INFO:tensorflow:global step 119860: loss = 0.3478 (0.798 sec/step)\n",
            "I0321 23:58:23.038788 140436091496320 learning.py:507] global step 119860: loss = 0.3478 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 119870: loss = 0.3689 (0.785 sec/step)\n",
            "I0321 23:58:30.963583 140436091496320 learning.py:507] global step 119870: loss = 0.3689 (0.785 sec/step)\n",
            "INFO:tensorflow:global step 119880: loss = 0.3474 (0.781 sec/step)\n",
            "I0321 23:58:38.973284 140436091496320 learning.py:507] global step 119880: loss = 0.3474 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119890: loss = 0.3880 (0.781 sec/step)\n",
            "I0321 23:58:47.034555 140436091496320 learning.py:507] global step 119890: loss = 0.3880 (0.781 sec/step)\n",
            "INFO:tensorflow:global step 119900: loss = 0.3930 (0.783 sec/step)\n",
            "I0321 23:58:54.928495 140436091496320 learning.py:507] global step 119900: loss = 0.3930 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 119910: loss = 0.3694 (0.845 sec/step)\n",
            "I0321 23:59:03.164327 140436091496320 learning.py:507] global step 119910: loss = 0.3694 (0.845 sec/step)\n",
            "INFO:tensorflow:global step 119920: loss = 0.3691 (0.802 sec/step)\n",
            "I0321 23:59:11.109413 140436091496320 learning.py:507] global step 119920: loss = 0.3691 (0.802 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "I0321 23:59:18.300928 140432201721600 supervisor.py:1117] Saving checkpoint to path /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 119929.\n",
            "I0321 23:59:20.995845 140432184936192 supervisor.py:1050] Recording summary at step 119929.\n",
            "INFO:tensorflow:global step 119930: loss = 0.3822 (2.982 sec/step)\n",
            "I0321 23:59:21.269919 140436091496320 learning.py:507] global step 119930: loss = 0.3822 (2.982 sec/step)\n",
            "INFO:tensorflow:global step 119940: loss = 0.3545 (0.784 sec/step)\n",
            "I0321 23:59:29.639126 140436091496320 learning.py:507] global step 119940: loss = 0.3545 (0.784 sec/step)\n",
            "INFO:tensorflow:global step 119950: loss = 0.3715 (0.782 sec/step)\n",
            "I0321 23:59:37.581747 140436091496320 learning.py:507] global step 119950: loss = 0.3715 (0.782 sec/step)\n",
            "INFO:tensorflow:global step 119960: loss = 0.3914 (0.805 sec/step)\n",
            "I0321 23:59:45.690997 140436091496320 learning.py:507] global step 119960: loss = 0.3914 (0.805 sec/step)\n",
            "INFO:tensorflow:global step 119970: loss = 0.3724 (0.795 sec/step)\n",
            "I0321 23:59:53.588961 140436091496320 learning.py:507] global step 119970: loss = 0.3724 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 119980: loss = 0.3587 (0.783 sec/step)\n",
            "I0322 00:00:01.544667 140436091496320 learning.py:507] global step 119980: loss = 0.3587 (0.783 sec/step)\n",
            "INFO:tensorflow:global step 119990: loss = 0.3630 (0.795 sec/step)\n",
            "I0322 00:00:09.731361 140436091496320 learning.py:507] global step 119990: loss = 0.3630 (0.795 sec/step)\n",
            "INFO:tensorflow:global step 120000: loss = 0.3704 (0.805 sec/step)\n",
            "I0322 00:00:17.707173 140436091496320 learning.py:507] global step 120000: loss = 0.3704 (0.805 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I0322 00:00:17.707910 140436091496320 learning.py:777] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I0322 00:00:17.708183 140436091496320 learning.py:785] Finished training! Saving model to disk.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b89cXPSRqkqH"
      },
      "source": [
        " #--tf_initial_checkpoint=\"${INIT_FOLDER}/model.ckpt-8000\" \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHMNj5M99Ket",
        "outputId": "f8376a17-6c5c-470c-f142-befe2baf5950"
      },
      "source": [
        "!sh /content/models/research/export_model-pqr.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/deeplab/core/conv2d_ws.py:40: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:201: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:117: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0322 00:07:07.721393 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:117: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:117: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0322 00:07:07.721647 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:117: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:118: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0322 00:07:07.721864 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:118: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Prepare to export model to: /content/models/research/deeplab/datasets/PQR/exp/output_model/frozen_inference_graph.pb\n",
            "I0322 00:07:07.722017 140363851339648 export_model.py:118] Prepare to export model to: /content/models/research/deeplab/datasets/PQR/exp/output_model/frozen_inference_graph.pb\n",
            "WARNING:tensorflow:From deeplab/export_model.py:91: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0322 00:07:07.722759 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:91: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "INFO:tensorflow:Exported model performs single-scale inference.\n",
            "I0322 00:07:07.773747 140363851339648 export_model.py:130] Exported model performs single-scale inference.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0322 00:07:07.774086 140363851339648 module_wrapper.py:139] From /content/models/research/deeplab/model.py:320: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0322 00:07:07.774597 140363851339648 deprecation.py:323] From /content/models/research/deeplab/core/feature_extractor.py:490: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/xception.py:469: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0322 00:07:07.777027 140363851339648 module_wrapper.py:139] From /content/models/research/deeplab/core/xception.py:469: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0322 00:07:07.779654 140363851339648 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "W0322 00:07:12.286378 140363851339648 module_wrapper.py:139] From /content/models/research/deeplab/core/utils.py:41: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:162: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0322 00:07:12.820266 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:162: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:178: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0322 00:07:12.824538 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:178: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:178: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Please use tf.global_variables instead.\n",
            "W0322 00:07:12.824831 140363851339648 deprecation.py:323] From deeplab/export_model.py:178: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Please use tf.global_variables instead.\n",
            "WARNING:tensorflow:From deeplab/export_model.py:181: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0322 00:07:13.630313 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:181: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From deeplab/export_model.py:182: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0322 00:07:13.630734 140363851339648 module_wrapper.py:139] From deeplab/export_model.py:182: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0322 00:07:13.872611 140363851339648 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-03-22 00:07:14.681929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-03-22 00:07:14.687886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.688689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-22 00:07:14.688975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-22 00:07:14.690378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-22 00:07:14.692029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-22 00:07:14.692491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-22 00:07:14.694591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-22 00:07:14.695909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-22 00:07:14.700439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-22 00:07:14.700577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.701363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.702014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-22 00:07:14.702381: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-03-22 00:07:14.708069: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-03-22 00:07:14.708313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a94001af40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-22 00:07:14.708359: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-03-22 00:07:14.810374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.811462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a94001ad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-03-22 00:07:14.811526: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-03-22 00:07:14.811812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.812536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-03-22 00:07:14.812653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-22 00:07:14.812697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-03-22 00:07:14.812739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-03-22 00:07:14.812786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-03-22 00:07:14.812825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-03-22 00:07:14.812862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-03-22 00:07:14.812901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-03-22 00:07:14.812990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.813743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.814324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-03-22 00:07:14.814405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-03-22 00:07:14.815962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-03-22 00:07:14.815995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-03-22 00:07:14.816011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-03-22 00:07:14.816174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.817060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-03-22 00:07:14.817863: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-03-22 00:07:14.817929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11309 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt-120000\n",
            "I0322 00:07:14.820189 140363851339648 saver.py:1284] Restoring parameters from /content/models/research/deeplab/datasets/PQR/exp/train_on_trainval_set/train/model.ckpt-120000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0322 00:07:16.654076 140363851339648 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0322 00:07:16.654452 140363851339648 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 732 variables.\n",
            "I0322 00:07:17.472925 140363851339648 graph_util_impl.py:334] Froze 732 variables.\n",
            "INFO:tensorflow:Converted 732 variables to const ops.\n",
            "I0322 00:07:17.778488 140363851339648 graph_util_impl.py:394] Converted 732 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "s6nY88C6FBBK",
        "outputId": "e9c1b1c2-82ca-4e95-8a31-f21bd68a1247"
      },
      "source": [
        "import os\n",
        "from io import BytesIO\n",
        "import tarfile\n",
        "import tempfile\n",
        "from six.moves import urllib\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "class DeepLabModel(object):\n",
        "  \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
        "\n",
        "  INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "  INPUT_SIZE = 287\n",
        "  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
        "\n",
        "  def __init__(self, tarball_path):\n",
        "    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
        "\n",
        "    ##\n",
        "    with tf.gfile.FastGFile(tarball_path, \"rb\") as f:\n",
        "      graph_def = tf.GraphDef()\n",
        "      graph_def.ParseFromString(f.read())\n",
        "      # g_in = tf.import_graph_def(graph_def, name=\"\")\n",
        "    # sess = tf.Session(graph=g_in)\n",
        "\n",
        "    ##\n",
        "    self.graph = tf.Graph()\n",
        "\n",
        "    # graph_def = None\n",
        "    # # Extract frozen graph from tar archive.\n",
        "\n",
        "    # graph_def = tf.GraphDef.FromString(tarball_path.)\n",
        "\n",
        "    if graph_def is None:\n",
        "      raise RuntimeError('Cannot find inference graph in tar archive.')\n",
        "\n",
        "    with self.graph.as_default():\n",
        "      tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "    self.sess = tf.Session(graph=self.graph)\n",
        "\n",
        "  def run(self, image):\n",
        "    \"\"\"Runs inference on a single image.\n",
        "\n",
        "    Args:\n",
        "      image: A PIL.Image object, raw input image.\n",
        "\n",
        "    Returns:\n",
        "      resized_image: RGB image resized from original input image.\n",
        "      seg_map: Segmentation map of `resized_image`.\n",
        "    \"\"\"\n",
        "    width, height = image.size\n",
        "    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
        "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "    batch_seg_map = self.sess.run(\n",
        "        self.OUTPUT_TENSOR_NAME,\n",
        "        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
        "    seg_map = batch_seg_map[0]\n",
        "    return resized_image, seg_map\n",
        "\n",
        "\n",
        "def create_pascal_label_colormap():\n",
        "  \"\"\"Creates a label colormap used in PASCAL VOC segmentation benchmark.\n",
        "\n",
        "  Returns:\n",
        "    A Colormap for visualizing segmentation results.\n",
        "  \"\"\"\n",
        "  colormap = np.zeros((256, 3), dtype=int)\n",
        "  ind = np.arange(256, dtype=int)\n",
        "\n",
        "  for shift in reversed(range(8)):\n",
        "    for channel in range(3):\n",
        "      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
        "    ind >>= 3\n",
        "\n",
        "  return colormap\n",
        "\n",
        "\n",
        "def label_to_color_image(label):\n",
        "  \"\"\"Adds color defined by the dataset colormap to the label.\n",
        "\n",
        "  Args:\n",
        "    label: A 2D array with integer type, storing the segmentation label.\n",
        "\n",
        "  Returns:\n",
        "    result: A 2D array with floating type. The element of the array\n",
        "      is the color indexed by the corresponding element in the input label\n",
        "      to the PASCAL color map.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If label is not of rank 2 or its value is larger than color\n",
        "      map maximum entry.\n",
        "  \"\"\"\n",
        "  if label.ndim != 2:\n",
        "    raise ValueError('Expect 2-D input label')\n",
        "\n",
        "  colormap = create_pascal_label_colormap()\n",
        "\n",
        "  if np.max(label) >= len(colormap):\n",
        "    raise ValueError('label value too large.')\n",
        "\n",
        "  return colormap[label]\n",
        "\n",
        "\n",
        "def vis_segmentation(image, seg_map):\n",
        "  \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n",
        "  plt.figure(figsize=(15, 5))\n",
        "  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
        "\n",
        "  plt.subplot(grid_spec[0])\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.title('input image')\n",
        "\n",
        "  plt.subplot(grid_spec[1])\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "  plt.imshow(seg_image)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation map')\n",
        "\n",
        "  plt.subplot(grid_spec[2])\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(seg_image, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation overlay')\n",
        "\n",
        "  unique_labels = np.unique(seg_map)\n",
        "  ax = plt.subplot(grid_spec[3])\n",
        "  plt.imshow(\n",
        "      FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "  ax.yaxis.tick_right()\n",
        "  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
        "  plt.xticks([], [])\n",
        "  ax.tick_params(width=0.0)\n",
        "  plt.grid('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "LABEL_NAMES = np.asarray([\n",
        "    'background', 'roads', 'water' \n",
        "])\n",
        "\n",
        "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
        "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)\n",
        "\n",
        "download_path=\"/content/models/research/deeplab/datasets/PQR/exp/output_model/frozen_inference_graph.pb\"\n",
        "MODEL = DeepLabModel(download_path)\n",
        "print('model loaded successfully!')\n",
        "\n",
        "im=Image.open('/content/models/research/deeplab/datasets/PQR/JPEGImages/image_part_009.jpg')\n",
        "\n",
        "image,segmap=MODEL.run(im)\n",
        "seg=Image.fromarray(segmap)\n",
        "#seg.save('/content/models/research/deeplab/datasets/PQR/exp/test_output/test.png')\n",
        "vis_segmentation(image,segmap)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model loaded successfully!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3QuqCZHjUCZ"
      },
      "source": [
        "  --label_weights=0.9 \\\n",
        "  --label_weights=0.1 \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZst78N-4OKO"
      },
      "source": [
        "## Run on sample images\n",
        "\n",
        "Select one of sample images (leave `IMAGE_URL` empty) or feed any internet image\n",
        "url for inference.\n",
        "\n",
        "Note that this colab uses single scale inference for fast computation,\n",
        "so the results may slightly differ from the visualizations in the\n",
        "[README](https://github.com/tensorflow/models/blob/master/research/deeplab/README.md) file,\n",
        "which uses multi-scale and left-right flipped inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6a9qm6OFEZW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "edGukUHXyymr"
      },
      "source": [
        "\n",
        "SAMPLE_IMAGE = 'image2'  # @param ['image1', 'image2', 'image3']\n",
        "IMAGE_URL = '/content/models/research/deeplab/datasets/PQR/JPEGImages/image_part_001.jpg'  #@param {type:\"string\"}\n",
        "\n",
        "_SAMPLE_URL = ('https://github.com/tensorflow/models/blob/master/research/'\n",
        "               'deeplab/g3doc/img/%s.jpg?raw=true')\n",
        "\n",
        "\n",
        "def run_visualization(url):\n",
        "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
        "  try:\n",
        "    f = urllib.request.urlopen(url)\n",
        "    jpeg_str = f.read()\n",
        "    original_im = Image.open(BytesIO(jpeg_str))\n",
        "  except IOError:\n",
        "    print('Cannot retrieve image. Please check url: ' + url)\n",
        "    return\n",
        "\n",
        "  print('running deeplab on image %s...' % url)\n",
        "  resized_im, seg_map = MODEL.run(original_im)\n",
        "\n",
        "  vis_segmentation(resized_im, seg_map)\n",
        "\n",
        "\n",
        "image_url = IMAGE_URL or _SAMPLE_URL % SAMPLE_IMAGE\n",
        "run_visualization(image_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv2kSzbgFG_8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9QgXtAuwliL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUbVoHScTJYe"
      },
      "source": [
        "## What's next\n",
        "\n",
        "* Learn about [Cloud TPUs](https://cloud.google.com/tpu/docs) that Google designed and optimized specifically to speed up and scale up ML workloads for training and inference and to enable ML engineers and researchers to iterate more quickly.\n",
        "* Explore the range of [Cloud TPU tutorials and Colabs](https://cloud.google.com/tpu/docs/tutorials) to find other examples that can be used when implementing your ML project.\n",
        "* For more information on running the DeepLab model on Cloud TPUs, see the [DeepLab tutorial](https://cloud.google.com/tpu/docs/tutorials/deeplab).\n"
      ]
    }
  ]
}